var tipuesearch = {"pages": [{'title': 'About', 'text': 'å°ˆé¡Œé¡Œç›®:\xa0 \n å¼·åŒ–å­¸ç¿’åœ¨æ©Ÿé›»ç³»çµ±è¨­è¨ˆèˆ‡æ§åˆ¶ä¸­ä¹‹æ‡‰ç”¨\xa0 \n Application of reinforcement learning in design and control of mechatronic systems \n è¨è«–å€:\xa0 https://github.com/mdecourse/4072pj1/discussions \n çµ„å“¡: \n 40723110 \n 40723115 \n 40723138 \n 40723148 \n 40723150 \n', 'tags': '', 'url': 'About.html'}, {'title': 'å°ˆé¡Œå®šä½', 'text': '2021/01/08 \n Adagrad:  2011_Adaptive Subgradient Methods for Online Learning and Stochastic Optimization.pdf \n 2012_ADADELTA AN ADAPTIVE LEARNING RATE METHOD.pdf \n Adam:  2015_ADAM A METHOD FORSTOCHASTICOPTIMIZATION.pdf \n 2017_An overview of gradient descent optimizationalgorithms.pdf \n 2018_A Comparative Analysis of Gradient Descent-Based Optimization Algorithms on Convolutional Neural Networks.pdf \n ç¬¬ä¸€çµ„çš„ç†è«–èˆ‡ç¨‹å¼æ‡‰ç”¨åˆ°ç¬¬ä¸‰çµ„å¹³é¢æ©Ÿæ§‹åˆæˆ: \n 2015_Dimensional synthesis of mechanical linkages usingartificial neural networks and Fourier descriptors.pdf \n 2017_Four-Bar Linkage Synthesis Using Non-ConvexOptimization.pdf \n 2018_Synthesis of a novel planar linkage to visit up to eight poses.pdf \n \n åˆ©ç”¨  Webots  èˆ‡\xa0 https://github.com/mdecourse/deepbots, \xa0é€é  https://github.com/mdecourse/deepbots-tutorials \xa0èˆ‡  https://github.com/mdecourse/deepworlds \xa0é€²ä¸€æ­¥äº†è§£ deepbots å¦‚ä½•æ‡‰ç”¨åœ¨ Webots ä¸­çš„å—æ§ç³»çµ±. \n å°ˆé¡Œç›®çš„åœ¨æ¢è¨èˆ‡  http://mde.tw/airhockey \xa0( https://github.com/mdecourse/airhockey  )ä¸­è™›å¯¦æ•´åˆç³»çµ±è¨­è¨ˆèˆ‡æ§åˆ¶æœ‰é—œçš„æ©Ÿå™¨å­¸ç¿’æ‡‰ç”¨. \n ä¸‹è¼‰  Webots_R2020brev1_portable.7z \n åƒè€ƒè³‡æ–™: \n https://github.com/mdecourse/RL_Webots \xa0 \n Deep Reinforcement Learning.pdf \xa0(2019) \n 2020_Book_DeepReinforcementLearning.pdf \n 2019_Learning to Walk via Deep Reinforcement Learning \n 2016_3d_simulated_robot_manipulation_using_deep_reinforcement_learning.pdf \n 2002_Book_HandbookOfMarkovDecisionProces.pdf \n Deepbots: A Webots-Based Deep Reinforcement Learning Framework for Robotics \n', 'tags': '', 'url': 'å°ˆé¡Œå®šä½.html'}, {'title': 'LaTeX', 'text': 'https://github.com/sppmg/TW_Thesis_Template/wiki/ç„¡è…¦æ‰‹å†Š \n https://github.com/wengan-li/ncku-thesis-template-latex \n https://github.com/HW-Lee/nthu-thesis-template \n     Features & Benefits\n    Templates\n    Plans & Pricing\n    Help\n    Register\n    Log In\n\nNTUST Thesis template 1.7.1 (Chinese Version)\nAuthor\nDing-Jie Huang, Chien-Chun Ni\nLicense\nCreative Commons CC BY 4.0\nAbstract\n\nThis is the Chinese Version of NTUST thesis template v1.7.1, please check "NTUST Thesis template Overleaf English Version" if you need the English one.\n\næœ¬ç¯„æœ¬æ˜¯ç‚ºå°ç£ç§‘æŠ€å¤§å­¸åŒå­¸å€‘æ‰€ç·¨å¯«çš„ç¢©åšå£«è«–æ–‡Latexæ¨¡æ¿ï¼Œ ä¸»è¦ç”±å…ƒæ™ºå¤§å­¸ç¢©åšå£«è«–æ–‡latexç¯„æœ¬æ”¹ç·¨è€Œä¾†ï¼Œ æœŸæœ›åŠ å¿«å„ä½åŒå­¸æ’°å¯«è«–æ–‡çš„é€Ÿåº¦ã€‚\n\nP.S åŸå§‹é™³å¿µæ³¢è€å¸«çš„å…ƒæ™ºå¤§å­¸è«–æ–‡ç¯„æœ¬ç‚º http://exciton.eo.yzu.edu.tw/~lab/latex/latex_note.html\n\nSupport 14pt font for this version\nTags\nFind More Templates\nNTUST Thesis template 1.7.1 (Chinese Version)\n\n    Â© 2020 OverleafPrivacy and TermsSecurityContact UsAboutBlog\n\n    Overleaf on TwitterOverleaf on FacebookOverleaf on LinkedIn\n\nSource\n\n% this file is encoded in utf-8\n% v1.7\n\n\\documentclass[12pt, a4paper]{ntust_report} \n\n\\usepackage{fontspec}   %åŠ é€™å€‹å°±å¯ä»¥è¨­å®šå­—é«” \n\\usepackage{xeCJK}       %è®“ä¸­è‹±æ–‡å­—é«”åˆ†é–‹è¨­ç½® \n\n%è¨­å®šä¸»è¦å­—å‹ï¼Œä¹Ÿå°±æ˜¯è‹±æ–‡å­—å‹\n\\setmainfont[Mapping=tex-text]{Times New Roman}            \n\n%è¨­å®šä¸­æ–‡å­—å‹\n%åƒè€ƒ https://www.overleaf.com/learn/latex/Questions/What_OTF/TTF_fonts_are_supported_via_fontspec%3F#Chinese\n\\setCJKmainfont{cwTeXKai}      \n\n\\XeTeXlinebreaklocale "zh"                %é€™å…©è¡Œä¸€å®šè¦åŠ ï¼Œä¸­æ–‡æ‰èƒ½è‡ªå‹•æ›è¡Œ \n\\XeTeXlinebreakskip = 0pt plus 1pt       %é€™å…©è¡Œä¸€å®šè¦åŠ ï¼Œä¸­æ–‡æ‰èƒ½è‡ªå‹•æ›è¡Œ\n\n\\input{common_env}  %åŸºæœ¬çš„ç’°å¢ƒè¨­å®š  ç„¡éœ€æ”¹è®Š  \n\n\\begin{document}\n\n\n\t\\input{chinese_trans} %åœ¨æ­¤æª”æ¡ˆè™•å®šç¾©æ–‡ç« ä¸­çš„ä¸­æ–‡åè©\n\n\t%----------------------------------------------------------------------------------------------------------------------------------------------------------\n\t%%% ä»¥ä¸‹æ˜¯è¼‰å…¥å‰é ã€æœ¬æ–‡ã€å¾Œé \n\t% æ­¤è¡Œè«‹å‹¿æ›´å‹•\n\n\t%----------------------------------------------------------------------------------------------------------------------------------------------------------\n\t% front matter å‰é \n\t% åŒ…æ‹¬å°é¢ã€æ›¸åé ã€ä¸­æ–‡æ‘˜è¦ã€è‹±æ–‡æ‘˜è¦ã€èªŒè¬ã€ç›®éŒ„ã€è¡¨ç›®éŒ„ã€åœ–ç›®éŒ„ã€ç¬¦è™Ÿèªªæ˜\n\t% åœ¨æ’°å¯«å„ç« è‰ç¨¿æ™‚ï¼Œå¯ä»¥æŠŠæ­¤éƒ¨ä»½ã€Œé—œæ‰ã€ï¼Œä»¥ç¯€çœç„¡è¬‚çš„ç·¨è­¯æ™‚é–“ã€‚\n\t% å¯¦éš›å…§å®¹ç”±\n\t%    my_names.tex, my_cabstract.tex, my_eabstract.tex, my_ackn.tex, my_symbols.tex\n\t% æ±ºå®š\n\t% ntust_frontpages.tex æ­¤æª”åªæä¾›æ•´é«”æ¶æ§‹çš„å®šç¾©ï¼Œä¸éœ€æ›´å‹•\n\t% åœ¨æ’°å¯«å„ç« è‰ç¨¿æ™‚ï¼Œå¯ä»¥æŠŠæ­¤éƒ¨ä»½ã€Œé—œæ‰ã€ï¼Œä»¥ç¯€çœç„¡è¬‚çš„ç·¨è­¯æ™‚é–“ã€‚\n\t\n\t\\input{frontpages/ntust_frontpages.tex} \n\n\n\n\n\t%----------------------------------------------------------------------------------------------------------------------------------------------------------\n\t% main body è«–æ–‡ä¸»é«”ã€‚å»ºè­°ä»¥ã€Œç« ã€ç‚ºæª”æ¡ˆåˆ†å‰²çš„ä¾æ“šã€‚\n\t% ä»¥ä¸‹ç‚ºå»ºè­°çš„å‘½ååˆ†é¡\n\t%   introduction.tex   related_work.tex  protocol.tex  evaluation.tex  conclusion.tex\n\t% åšç‚ºé€™å¹¾å€‹ã€Œç« ã€çš„æª”æ¡ˆåç¨±ï¼Œä¸¦å°‡æª”æ¡ˆå­˜æ”¾æ–¼è³‡æ–™å¤¾ sections/ ä¸‹\n\t% å¯¦éš›å‘½åæ–¹å¼å¯ä»¥éš¨ä½ æ„\n\t% åœ¨æ’°å¯«å„ç« è‰ç¨¿æ™‚ï¼Œå¯ä»¥æŠŠå…¶ä»–ç« ç¯€é—œæ‰ (è¡Œé¦–åŠ ç™¾åˆ†è™Ÿ)\n\t%\\input{example/example_body.tex}  % æ‰€é™„çš„ç¯„ä¾‹\n\n\t\\input{sections/introduction.tex}\n\t\\input{sections/relative-work.tex}\n\t\\input{sections/method.tex}\n\t\\input{sections/Design.tex}\n\t\\input{sections/evaluation.tex}\n\t\\input{sections/Conclusion.tex}\n\n\t%----------------------------------------------------------------------------------------------------------------------------------------------------------\n\t% back pages å¾Œé \n\t% åŒ…æ‹¬åƒè€ƒæ–‡ç»ã€é™„éŒ„ã€è‡ªå‚³\n\t% å¯¦éš›å…§å®¹ç”±\n\t%    my_bib.bib, my_appendix.tex, my_vita.tex\n\t% æ±ºå®š\n\t% ntust_backpages.tex æ­¤æª”åªæä¾›æ•´é«”æ¶æ§‹çš„å®šç¾©ï¼Œä¸éœ€æ›´å‹•\n\t% åœ¨æ’°å¯«å„ç« è‰ç¨¿æ™‚ï¼Œå¯ä»¥æŠŠæ­¤éƒ¨ä»½ã€Œé—œæ‰ã€ï¼Œä»¥ç¯€çœç„¡è¬‚çš„ç·¨è­¯æ™‚é–“ã€‚\n\t%\\bibliographystyle{unsrt} \n\t\\input{backpages/ntust_backpages.tex}\n\t%\\bibliographystyle{unsrt} \n\n\n\n\\end{document} \n \n\n \n \n', 'tags': '', 'url': 'LaTeX.html'}, {'title': 'åƒè€ƒè³‡æ–™', 'text': '\n https://easyai.tech/en/blog/reinforcement-learning-with-python/ \n https://github.com/openai/gym \n https://github.com/bhyang/gym-vrep \n https://arxiv.org/pdf/1608.05742.pdf \n https://github.com/stepjam/PyRep \n https://arxiv.org/abs/1906.11176 \n https://github.com/ycps/vrep-env \n https://towardsdatascience.com/learning-to-drive-smoothly-in-minutes-450a7cdb35f4 \n https://github.com/araffin/learning-to-drive-in-5-minutes \n https://www.learndatasci.com/tutorials/reinforcement-q-learning-scratch-python-openai-gym/ \n https://upcommons.upc.edu/bitstream/handle/2117/133279/tfm-alex-cabaneros.pdf \n \n', 'tags': '', 'url': 'åƒè€ƒè³‡æ–™.html'}, {'title': 'ç ”ç©¶ç”Ÿè€ƒè©¦', 'text': 'csme ç ”ç©¶ç”Ÿè€ƒè©¦ç§‘ç›®èˆ‡é¡Œå‹:  è€ƒè©¦å…§å®¹ åŠ è€ƒå¤é¡Œ \n', 'tags': '', 'url': 'ç ”ç©¶ç”Ÿè€ƒè©¦.html'}, {'title': 'å‹•æ…‹ç¶²ç«™', 'text': 'è¨­å®šæ­¥é©Ÿè«‹åƒè€ƒ: \n https://github.com/mdecourse/project2020-1/issues/4 \n CMSiMDE åŸ·è¡Œæ‰€éœ€æ¨¡çµ„ \n sudo pip3 install flask flask_cors bs4 lxml \n uwsgi æ‰€éœ€æ¨¡çµ„ \n sudo apt install uwsgi uwsgi-plugin-python3 \n sudo pip3 install uwsgi \n /etc/nginx/sites-available/default é™„åŠ  server è¨­å®š  \n server {\n \n    listen 9443 ssl;\n    listen [::]:9443 ssl;\n \n    # æŒ‡å®š static æ‰€åœ¨ä½ç½®\n    location /static {\n\talias /home/yen/cad1_site/cmsimde/static/;\n    }\n \n    location / {\n\t# å°å…¥ uwsgi_params è¨­å®šåƒæ•¸\n\tinclude uwsgi_params;\n\t# æ ¹ç›®éŒ„è¨­ç‚ºè¿‘ç«¯çš„ 8080 port \n\tuwsgi_pass  127.0.0.1:8080;\n    }\n \n    ssl_certificate /home/yen/localhost.crt;\n    ssl_certificate_key /home/yen/localhost.key;\n    #ssl_certificate /etc/letsencrypt/live/cad1.kmol.info/fullchain.pem;\n    #ssl_certificate_key /etc/letsencrypt/live/cad1.kmol.info/privkey.pem;\n    ssl_session_timeout 5m;\n    ssl_protocols SSLv3 TLSv1 TLSv1.1 TLSv1.2;\n    ssl_ciphers "HIGH:!aNULL:!MD5 or HIGH:!aNULL:!MD5:!3DES";\n    ssl_prefer_server_ciphers on;\n    try_files $uri $uri/ =404;\n} \n å»ºç«‹ self-signed key sudo openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout localhost.key -out localhost.crt /home/yen/uwsgi_ini/uwsgi.ini \n [uwsgi]\nsocket = :8080\nuid = yen\ngid = yen\nplugins-dir = /usr/lib/uwsgi/plugins/\nplugin = python3\nmaster = true\nprocess = 4\nthreads = 2\nchdir = /home/yen/cad1_site/cmsimde\nwsgi-file = /home/yen/cad1_site/cmsimde/wsgi.py \n uwsgi emperor æ‰‹å‹•æ¸¬è©¦ \n /usr/bin/uwsgi --emperor /home/yen/uwsgi_ini é˜²ç«ç‰†è¨­å®š \n å…ˆæš«æ™‚é—œé–‰ ufw \n ufw disable \n å…è¨±è¨­è¨ˆç³» IP v6 ç¶²æ®µé€£ç·š 9443 port \n ufw allow from 2001:288:6004:17::/32 to any port 9443 \n å…¶ä»–ç¶²æ®µä¸»æ©Ÿä¸€å¾‹]ä¸å‡†é€£ç·š \n ufw deny 9443 \n é‡æ–°é–‹å•Ÿ ufw é˜²ç«ç‰† \n ufw enable \n /etc/systemd/system ç›®éŒ„ä¸­å»ºç«‹ cmsimde.service æª”æ¡ˆ \n \n [Unit]\nDescription=uWSGI to serve CMSiMDE \nAfter=network.target\n \n[Service]\nUser=yen\nGroup=yen\nWorkingDirectory=/home/yen/uwsgi_ini\nExecStart=/usr/bin/uwsgi --emperor /home/yen/uwsgi_ini\n \n[Install]\nWantedBy=multi-user.target \n \n æ¥è‘—å°‡ cmsimde æœå‹™è¨­ç‚ºéš¨ç³»çµ±é–‹æ©Ÿå•Ÿå‹•: \n sudo systemctl enable cmsimde\n \n è‹¥è¦å–æ¶ˆ cmsimde æœå‹™éš¨ç³»çµ±é–‹æ©Ÿå•Ÿå‹•: \n sudo systemctl disable cmsimde\n \n æ‰‹å‹•å•Ÿå‹• cmsimde.service æœå‹™ \n sudo systemctl start cmsimde\n \n æ‰‹å‹•åœæ­¢ cmsimde.service æœå‹™ \n sudo systemctl stop cmsimde \n \n', 'tags': '', 'url': 'å‹•æ…‹ç¶²ç«™.html'}, {'title': 'æ•¸ä½ç°½ç« ', 'text': 'https://letsencrypt.org/ \n https://certbot.eff.org/lets-encrypt/ubuntufocal-nginx \xa0 \n sudo apt-get update\nsudo apt-get install software-properties-common\nsudo add-apt-repository universe\nsudo apt-get update\n\nsudo apt-get install certbot python3-certbot-nginx\n\nsudo certbot certonly --nginx\n\nsudo certbot renew --dry-run \n \n', 'tags': '', 'url': 'æ•¸ä½ç°½ç« .html'}, {'title': 'æ©Ÿé›»æ§åˆ¶', 'text': 'Mechatronic system control \n æ§åˆ¶å¡: \n Arduino \n Raspberry Pi \n æ©Ÿé›»ç³»çµ±: \n iRobot Create \n', 'tags': '', 'url': 'æ©Ÿé›»æ§åˆ¶.html'}, {'title': 'iRobot Create', 'text': 'https://www.cyberbotics.com/doc/guide/create \n \n https://github.com/mgobryan/pycreate \xa0 \n https://github.com/mdecourse/create_autonomy \xa0 \n iRobot Create Manual.pdf \n iRobot Create cookbook.pdf \n iRobot Create Command Module manual v2.pdf \n iRobot Create Open Interface v2.pdf \n Use Arduino to control iRobot Create.pdf \n Use Arduino to control iRobot Create_2.pdf \n', 'tags': '', 'url': 'iRobot Create.html'}, {'title': 'æ·±åº¦å­¸ç¿’', 'text': 'Solving Nonlinear andHigh-Dimensional PartialDifferential Equations viaDeep Learning.pdf \n https://github.com/alialaradi/DeepGalerkinMethod \n DGM A deep learning algorithm for solving partial differentialequations.pdf \n \n https://cloud4scieng.org/ \xa0é›²ç«¯é‹ç®— \n https://www.uio.no/studier/emner/matnat/ifi/IN5400/v20/material/week1/ \n https://wcm.kmol.info:8443  (KMOLer only) \n https://github.com/mdecourse/cd2020pj1 \n https://cs.stanford.edu/people/karpathy/convnetjs/\xa0 \n http://neuralnetworksanddeeplearning.com/chap1.html \xa0 \n https://cs.stanford.edu/people/karpathy/convnetjs/demo/rldemo.html \n http://deeplearning.net/ \n Playing Atari with Deep Reinforcement Learning.pdf \n Robust Auto-parking: Reinforcement Learning based Real-time Planning Approach with Domain Template.pdf \n Automatic Car Parking: A Reinforcement Learning Approach.pdf \n Real-time image-based parking occupancy detection using deep learning.pdf \n \n \n ä»¥ä¸‹ç‚º convnet javascript æ‡‰ç”¨ \n  import convnetjs library  \n \n  javascript goes here  \n \n \n', 'tags': '', 'url': 'æ·±åº¦å­¸ç¿’.html'}, {'title': 'é›»è…¦', 'text': 'å°ˆé¡Œå¯æ”œ 22GB.7z \n é›»è…¦è¼”åŠ©è¨­è¨ˆå®¤ 2016 æ›´æ›çš„ é›»è…¦ç¡¬é«” : \n 2016-2 å”åŒè¨­è¨ˆå®¤ 6 å°é›»è…¦ \n Intel Core i7-6700 3.4 GHz Ram 16GB \n é¡¯ç¤ºå¡ NVIDIA GeForce GTX 950 2GB 768 CUDA cores version 10.1 \n å®‰è£ Pytorch æŒ‡ä»¤ : \n pip install torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f  https://download.pytorch.org/whl/torch_stable.html https://github.com/pytorch/examples Deep learning with python.pdf Deep Learning with Pytorch.pdf  ( ä¾†æº ) \n', 'tags': '', 'url': 'é›»è…¦.html'}, {'title': 'Flask', 'text': 'Flutter å‰ç«¯èˆ‡å¾Œç«¯ Flask + Keras çµåˆæ‡‰ç”¨ \n https://medium.com/analytics-vidhya/deploy-deep-learning-models-as-rest-apis-using-keras-and-access-from-a-flutter-app-9a6752f0d907 \n \n Flutter send image file to backend: \n \n import \'package:flutter/material.dart\';\nimport \'dart:io\';\nimport \'package:http/http.dart\' as http;\nimport \'package:image_picker/image_picker.dart\';\nimport \'package:mime/mime.dart\';\nimport \'dart:convert\';\nimport \'package:http_parser/http_parser.dart\';\nimport \'package:toast/toast.dart\';\n\nvoid main() => runApp(MyApp());\n\nclass MyApp extends StatelessWidget {\n  // This widget is the root of your application.\n  @override\n  Widget build(BuildContext context) {\n    return MaterialApp(\n        title: \'Image Upload Demo\',\n        theme: ThemeData(primarySwatch: Colors.pink),\n        home: ImageInput());\n  }\n}\n\nclass ImageInput extends StatefulWidget {\n  @override\n  State<StatefulWidget> createState() {\n    return _ImageInput();\n  }\n}\n\nclass _ImageInput extends State<ImageInput> {\n  // To store the file provided by the image_picker\n  File _imageFile;\n\n  // To track the file uploading state\n  bool _isUploading = false;\n\n  String baseUrl = \'http://YOUR_IPV4_ADDRESS/flutterdemoapi/api.php\';\n\n  void _getImage(BuildContext context, ImageSource source) async {\n    File image = await ImagePicker.pickImage(source: source);\n\n    setState(() {\n      _imageFile = image;\n    });\n\n    // Closes the bottom sheet\n    Navigator.pop(context);\n  }\n\n  Future<Map<String, dynamic>> _uploadImage(File image) async {\n    setState(() {\n      _isUploading = true;\n    });\n\n    // Find the mime type of the selected file by looking at the header bytes of the file\n    final mimeTypeData =\n        lookupMimeType(image.path, headerBytes: [0xFF, 0xD8]).split(\'/\');\n\n    // Intilize the multipart request\n    final imageUploadRequest =\n        http.MultipartRequest(\'POST\', Uri.parse(baseUrl));\n\n    // Attach the file in the request\n    final file = await http.MultipartFile.fromPath(\'image\', image.path,\n        contentType: MediaType(mimeTypeData[0], mimeTypeData[1]));\n\n    // Explicitly pass the extension of the image with request body\n    // Since image_picker has some bugs due which it mixes up\n    // image extension with file name like this filenamejpge\n    // Which creates some problem at the server side to manage\n    // or verify the file extension\n    imageUploadRequest.fields[\'ext\'] = mimeTypeData[1];\n\n    imageUploadRequest.files.add(file);\n\n    try {\n      final streamedResponse = await imageUploadRequest.send();\n\n      final response = await http.Response.fromStream(streamedResponse);\n\n      if (response.statusCode != 200) {\n        return null;\n      }\n\n      final Map<String, dynamic> responseData = json.decode(response.body);\n\n      _resetState();\n\n      return responseData;\n    } catch (e) {\n      print(e);\n      return null;\n    }\n  }\n\n  void _startUploading() async {\n    final Map<String, dynamic> response = await _uploadImage(_imageFile);\n    print(response);\n    // Check if any error occured\n    if (response == null || response.containsKey("error")) {\n      Toast.show("Image Upload Failed!!!", context,\n          duration: Toast.LENGTH_LONG, gravity: Toast.BOTTOM);\n    } else {\n      Toast.show("Image Uploaded Successfully!!!", context,\n          duration: Toast.LENGTH_LONG, gravity: Toast.BOTTOM);\n    }\n  }\n\n  void _resetState() {\n    setState(() {\n      _isUploading = false;\n      _imageFile = null;\n    });\n  }\n\n  void _openImagePickerModal(BuildContext context) {\n    final flatButtonColor = Theme.of(context).primaryColor;\n    print(\'Image Picker Modal Called\');\n    showModalBottomSheet(\n        context: context,\n        builder: (BuildContext context) {\n          return Container(\n            height: 150.0,\n            padding: EdgeInsets.all(10.0),\n            child: Column(\n              children: <Widget>[\n                Text(\n                  \'Pick an image\',\n                  style: TextStyle(fontWeight: FontWeight.bold),\n                ),\n                SizedBox(\n                  height: 10.0,\n                ),\n                FlatButton(\n                  textColor: flatButtonColor,\n                  child: Text(\'Use Camera\'),\n                  onPressed: () {\n                    _getImage(context, ImageSource.camera);\n                  },\n                ),\n                FlatButton(\n                  textColor: flatButtonColor,\n                  child: Text(\'Use Gallery\'),\n                  onPressed: () {\n                    _getImage(context, ImageSource.gallery);\n                  },\n                ),\n              ],\n            ),\n          );\n        });\n  }\n\n  Widget _buildUploadBtn() {\n    Widget btnWidget = Container();\n\n    if (_isUploading) {\n      // File is being uploaded then show a progress indicator\n      btnWidget = Container(\n          margin: EdgeInsets.only(top: 10.0),\n          child: CircularProgressIndicator());\n    } else if (!_isUploading && _imageFile != null) {\n      // If image is picked by the user then show a upload btn\n\n      btnWidget = Container(\n        margin: EdgeInsets.only(top: 10.0),\n        child: RaisedButton(\n          child: Text(\'Upload\'),\n          onPressed: () {\n            _startUploading();\n          },\n          color: Colors.pinkAccent,\n          textColor: Colors.white,\n        ),\n      );\n    }\n\n    return btnWidget;\n  }\n\n  @override\n  Widget build(BuildContext context) {\n    return Scaffold(\n      appBar: AppBar(\n        title: Text(\'Image Upload Demo\'),\n      ),\n      body: Column(\n        children: <Widget>[\n          Padding(\n            padding: const EdgeInsets.only(top: 40.0, left: 10.0, right: 10.0),\n            child: OutlineButton(\n              onPressed: () => _openImagePickerModal(context),\n              borderSide:\n                  BorderSide(color: Theme.of(context).accentColor, width: 1.0),\n              child: Row(\n                mainAxisAlignment: MainAxisAlignment.center,\n                children: <Widget>[\n                  Icon(Icons.camera_alt),\n                  SizedBox(\n                    width: 5.0,\n                  ),\n                  Text(\'Add Image\'),\n                ],\n              ),\n            ),\n          ),\n          _imageFile == null\n              ? Text(\'Please pick an image\')\n              : Image.file(\n                  _imageFile,\n                  fit: BoxFit.cover,\n                  height: 300.0,\n                  alignment: Alignment.topCenter,\n                  width: MediaQuery.of(context).size.width,\n                ),\n          _buildUploadBtn(),\n        ],\n      ),\n    );\n  }\n} \n Server ç«¯, å¿…é ˆå°‡ php æ”¹ç‚º Flask: \n     <?php\n    if(isset($_FILES["image"]["name"])) {\n      \n        // Make sure you have created this directory already\n        $target_dir = "uploads/";\n      \n        // Generate a random name \n        $target_file = $target_dir . md5(time()) . \'.\' . $_POST[\'ext\'];\n        $check = getimagesize($_FILES["image"]["tmp_name"]);\n        if($check !== false) {\n            if (move_uploaded_file($_FILES["image"]["tmp_name"], $target_file)) {\n          echo json_encode([\'response\' => "The image has been uploaded."]);\n           }else {\n          echo json_encode(["error" => "Sorry, there was an error uploading your file."]); \n        }\n        } else {\n            echo json_encode(["error" => "File is not an image."]);\n           \n        }\n    }\n     else {\n         echo json_encode(["error" => "Please provide a image to upload"]);\n    }\n    ?> \n \n \n', 'tags': '', 'url': 'Flask.html'}, {'title': 'å¼·åŒ–å­¸ç¿’', 'text': 'https://github.com/dennybritz/reinforcement-learning \n http://incompleteideas.net/book/RLbook2018.pdf \n Artificial Intelligence (  äººå·¥æ™ºæ…§ç³»åˆ—èª²ç¨‹ ) \n \n Machine Learning ( æ©Ÿå™¨å­¸ç¿’ç³»åˆ—èª²ç¨‹ ) \n \n Reinforcement Learning ( å¼·åŒ–å­¸ç¿’ç³»åˆ—èª²ç¨‹ ) \n Learn to make good sequences of decision. \n \n https://github.com/keras-rl/keras-rl \n https://towardsdatascience.com/learning-reinforcement-learning-reinforce-with-pytorch-5e8ad7fc7da0 \n https://github.com/astooke/rlpyt \xa0( Document ) ( Blog ) \n https://github.com/p-christ/Deep-Reinforcement-Learning-Algorithms-with-PyTorch \n https://openai.com/blog/openai-baselines-ppo/ \xa0 \n Deep Q Learning \n \n Vanilla Policy Gradient Method \n Trust Region / Natural Policy Gradient Methods \n Proximal Policy Optimization Algorithms.pdf \xa0( è¿‘ç«¯ç­–ç•¥å„ªåŒ–åŸç†) \n https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html \n https://www.mlq.ai/deep-reinforcement-learning-pytorch-implementation/ \n', 'tags': '', 'url': 'å¼·åŒ–å­¸ç¿’.html'}, {'title': '2021', 'text': 'need Python and Node.js and Typescript \n https://github.com/Positronic-IO/air-hockey-training-environment \xa0 \n https://github.com/Positronic-IO/air-hockey-web-ui \xa0 \n https://jonathan-hui.medium.com/rl-dqn-deep-q-network-e207751f7ae4 \xa0 \n https://keon.github.io/ \xa0 \n', 'tags': '', 'url': '2021.html'}, {'title': 'Reference', 'text': '2018_Robotic Harvesting of Fruiting Vegetables-A Simulation Approach in V-REP, ROS and MATLAB.pdf \n 2019_Hovering Control of a Quadrotor.pdf \n 2019_Accelerating Training of Deep Reinforcement Learning-based Autonomous Driving Agents Through Comparative Study of Agent and Environment Designs.pdf \n 2018_Curved Path Following with Deep Reinforcement Learning-Results from Three Vessel Models.pdf \n 2019_Application of deep reinforcement learning for control problems.pdf \n 2018_Path Following in Simulated Environments using the A3C Reinforcement Learning Method.pdf \n FlashRL_A Reinforcement Learning Platform.pdf \n', 'tags': '', 'url': 'Reference.html'}, {'title': 'é¡ç¥ç¶“ç¶²è·¯å­¸ç¿’', 'text': 'nn_and_air_hockey.7z \n å°‡  https://github.com/Purusharth07/Ping-Pong-Neural-Game- \xa0 æ”¹ç‚º  tensorflow 2.0  ç‰ˆæœ¬, ä½¿ç”¨ Pygame æ¨¡æ“¬. \n', 'tags': '', 'url': 'é¡ç¥ç¶“ç¶²è·¯å­¸ç¿’.html'}, {'title': 'neural_network_in_python.pdf', 'text': 'èªªæ˜å‰ä¸‰ç« çš„ç¨‹å¼ç¢¼ \n 2LayerNeuralNetwork.py \n origin codes: \n # 2 Layer Neural Network in NumPy\nimport numpy as np\n# X = input of our 3 input XOR gate\n# set up the inputs of the neural network (right from the table)\nX = np.array(([0,0,0],[0,0,1],[0,1,0], [0,1,1],[1,0,0],[1,0,1],[1,1,0],[1,1,1]), dtype=float)\n# y = our output of our neural network\ny = np.array(([1], [0], [0], [0], [0], [0], [0], [1]), dtype=float)\n# what value we want to predict\nxPredicted = np.array(([0,0,1]), dtype=float)\nX = X/np.amax(X, axis=0) # maximum of X input array\n# maximum of xPredicted (our input data for the prediction)\nxPredicted = xPredicted/np.amax(xPredicted, axis=0)\n# set up our Loss file for graphing\nlossFile = open("SumSquaredLossList.csv", "w")\nclass Neural_Network (object):\n    def __init__(self):\n        #parameters\n        self.inputLayerSize = 3 # X1,X2,X3\n        self.outputLayerSize = 1 # Y1\n        self.hiddenLayerSize = 4 # Size of the hidden layer\n        # build weights of each layer\n        # set to random values\n        # look at the interconnection diagram to make sense of this\n        # 3x4 matrix for input to hidden\n        self.W1 = np.random.randn(self.inputLayerSize, self.hiddenLayerSize)\n        # 4x1 matrix for hidden layer to output\n        self.W2 = np.random.randn(self.hiddenLayerSize, self.outputLayerSize)\n    def feedForward(self, X):\n        # feedForward propagation through our network\n        # dot product of X (input) and first set of 3x4 weights\n        self.z = np.dot(X, self.W1)\n        # the activationSigmoid activation function - neural magic\n        self.z2 = self.activationSigmoid(self.z)\n        # dot product of hidden layer (z2) and second set of 4x1 weights\n        self.z3 = np.dot(self.z2, self.W2)\n        # final activation function - more neural magic\n        o = self.activationSigmoid(self.z3)\n        return o\n     def backwardPropagate(self, X, y, o):\n        # backward propagate through the network\n        # calculate the error in output\n        self.o_error = y - o\n        # apply derivative of activationSigmoid to error\n        self.o_delta = self.o_error*self.activationSigmoidPrime(o)\n        # z2 error: how much our hidden layer weights contributed to output\n        # error\n        self.z2_error = self.o_delta.dot(self.W2.T)\n        # applying derivative of activationSigmoid to z2 error\n        self.z2_delta = self.z2_error*self.activationSigmoidPrime(self.z2)\n        # adjusting first set (inputLayer --> hiddenLayer) weights\n        self.W1 += X.T.dot(self.z2_delta)\n        # adjusting second set (hiddenLayer --> outputLayer) weights\n        self.W2 += self.z2.T.dot(self.o_delta)\n    def trainNetwork(self, X, y):\n        # feed forward the loop\n        o = self.feedForward(X)\n        # and then back propagate the values (feedback)\n        self.backwardPropagate(X, y, o)\n    def activationSigmoid(self, s):\n        # activation function\n        # simple activationSigmoid curve as in the book\n        return 1/(1+np.exp(-s))\n    def activationSigmoidPrime(self, s):\n        # First derivative of activationSigmoid\n        # calculus time!\n        return s * (1 - s)\n    def saveSumSquaredLossList(self,i,error):\n        lossFile.write(str(i)+","+str(error.tolist())+\'\\n\')\n    def saveWeights(self):\n        # save this in order to reproduce our cool network\n        np.savetxt("weightsLayer1.txt", self.W1, fmt="%s")\n        np.savetxt("weightsLayer2.txt", self.W2, fmt="%s")\n    def predictOutput(self):\n        print ("Predicted XOR output data based on trained weights: ")\n        print ("Expected (X1-X3): \\n" + str(xPredicted))\n        print ("Output (Y1): \\n" + str(self.feedForward(xPredicted)))\n\nmyNeuralNetwork = Neural_Network()\ntrainingEpochs = 1000\n#trainingEpochs = 100000\n\nfor i in range(trainingEpochs): # train myNeuralNetwork 1,000 times\n    print ("Epoch # " + str(i) + "\\n")\n    print ("Network Input : \\n" + str(X))\n    print ("Expected Output of XOR Gate Neural Network: \\n" + str(y))\n    print ("Actual Output from XOR Gate Neural Network: \\n" + \\\n    str(myNeuralNetwork.feedForward(X)))\n    # mean sum squared loss\n    Loss = np.mean(np.square(y - myNeuralNetwork.feedForward(X)))\n    myNeuralNetwork.saveSumSquaredLossList(i,Loss)\n    print ("Sum Squared Loss: \\n" + str(Loss))\n    print ("\\n")\n    myNeuralNetwork.trainNetwork(X, y)\n\nmyNeuralNetwork.saveWeights()\nmyNeuralNetwork.predictOutput()p \n å®šç¾©input(X)å’Œoutput(Y) \n X = np.array(([0,0,0],[0,0,1],[0,1,0], [0,1,1],[1,0,0],[1,0,1],[1,1,0],[1,1,1]), dtype=float)\ny = np.array(([1], [0], [0], [0], [0], [0], [0], [1]), dtype=float) \n è¨­å®šç¥ç¶“å…ƒåŠæ¬Šé‡ \n python\n def __init__(self):\n        # X1,X2,X3(è‡ªè¨‚ç¾©inputçš„ç¥ç¶“å…ƒæ•¸é‡)\n        self.inputLayerSize = 3\n        # Y1(è‡ªè¨‚ç¾©outputçš„ç¥ç¶“å…ƒæ•¸é‡)   \n        self.outputLayerSize = 1\n        # Size of the hidden layer(è‡ªè¨‚ç¾©hiddenLayerçš„ç¥ç¶“å…ƒæ•¸é‡)          \n        self.hiddenLayerSize = 4 \n        \n        # è¨­å®šç¬¬ä¸€å±¤æ¬Šé‡ç‚ºéš¨æ©Ÿæ•¸å€¼ï¼Œinput--->hidden\n        self.W1 = np.random.randn(self.inputLayerSize, self.hiddenLayerSize)\n        \n        # è¨­å®šç¬¬äºŒå±¤æ¬Šé‡ç‚ºéš¨æ©Ÿæ•¸å€¼ï¼Œhidden--->output\n        self.W2 = np.random.randn(self.hiddenLayerSize, self.outputLayerSize)\n \n feedForward(å‰é¥‹) \n \n (åœ–ç‰‡ä¾†æº) \n  def feedForward(self, X):\n        # ç¬¬ä¸€å±¤çš„å‹•æ…‹æ–¹ç¨‹å¼(activation function)è¼¸å…¥(z)\n        # z(activation function) = ç¬¬ä¸€å±¤æ‰€æœ‰ç¥ç¶“å…ƒçš„ input * weights ç¸½å’Œè¼¸å…¥åˆ°ç¬¬äºŒå±¤çš„å…¶ä¸­ä¸€å€‹ç¥ç¶“å…ƒ\n        self.z = np.dot(X, self.W1)\n\n        # ç¬¬ä¸€å±¤çš„å‹•æ…‹æ–¹ç¨‹å¼(activation function)è¼¸å‡º(a)\n        # z2(a) = å‹•æ…‹æ–¹ç¨‹å¼(activation function)ç”¨Sigmoid functionç®—æ³•\n        self.z2 = self.activationSigmoid(self.z)\n\n        # ç¬¬äºŒå±¤çš„å‹•æ…‹æ–¹ç¨‹å¼(activation function)è¼¸å…¥(z)\n        # z3(activation function) = ç¬¬äºŒå±¤æ‰€æœ‰ç¥ç¶“å…ƒçš„ input * weights ç¸½å’Œè¼¸å…¥åˆ°è¼¸å‡ºå±¤çš„(å…¶ä¸­ä¸€å€‹)ç¥ç¶“å…ƒ\n        self.z3 = np.dot(self.z2, self.W2)\n\n        # ç¬¬äºŒå±¤çš„å‹•æ…‹æ–¹ç¨‹å¼(activation function)è¼¸å‡º(a)\n        # o(a) = å‹•æ…‹æ–¹ç¨‹å¼(activation function)ç”¨Sigmoid functionç®—æ³•\n        o = self.activationSigmoid(self.z3)\n\n        # å›å‚³å‡ºå‰é¥‹çµæœ\n        return o \n backwardPropagate(åå‘å‚³æ’­) \n def backwardPropagate(self, X, y, o):\n        # è¨ˆç®—è¼¸å‡ºèª¤å·®\n        self.o_error = y - o\n\n        # å°‡Sigmoid functionç®—æ³•ç”¨åœ¨è¼¸å‡ºèª¤å·®(éŒ¯èª¤ã€error)\n        self.o_delta = self.o_error*self.activationSigmoidPrime(o)\n\n        # éš±è—å±¤çš„è¼¸å‡ºèª¤å·®*æ¬Šé‡\n        self.z2_error = self.o_delta.dot(self.W2.T)\n\n        # å°‡Sigmoid functionç®—æ³•ç”¨åœ¨éš±è—å±¤è¼¸å‡ºèª¤å·®(éŒ¯èª¤ã€error)\n        self.z2_delta = self.z2_error*self.activationSigmoidPrime(self.z2)\n\n        # ç³¾æ­£ç¬¬ä¸€å±¤æ¬Šé‡æ•¸å€¼ï¼Œinput--->hidden\n        self.W1 += X.T.dot(self.z2_delta)\n        # ç³¾æ­£ç¬¬äºŒå±¤æ¬Šé‡æ•¸å€¼ï¼Œhidden--->output\n        self.W2 += self.z2.T.dot(self.o_delta) \n trainNetwork(è¨“ç·´æµç¨‹) \n def trainNetwork(self, X, y):\n        # å‰é¥‹å¾ªç’° \n        o = self.feedForward(X)\n        # åå‘å‚³æ’­å€¼\n        self.backwardPropagate(X, y, o) \n activationSigmoid \n def activationSigmoid(self, s):\n        # activation function\n        # ä½¿ç”¨Sigmoid functionç®—æ³•(S-curve)\n        return 1/(1+np.exp(-s)) \n \n activationSigmoidPrime \n def activationSigmoidPrime(self, s):\n        # First derivative of activationSigmoid\n        # calculus time!\n        return s * (1 - s) \n \n saveSumSquaredLossList(å„²å­˜æå¤±å‡½æ•¸å€¼) \n  def saveSumSquaredLossList(self,i,error):\n        lossFile.write(str(i)+","+str(error.tolist())+\'\\n\') \n saveWeights(å„²å­˜æ¬Šé‡å€¼) \n  def saveWeights(self):\n        np.savetxt("weightsLayer1.txt", self.W1, fmt="%s")\n        np.savetxt("weightsLayer2.txt", self.W2, fmt="%s") \n predictOutput(çµæœè¼¸å‡º) \n def predictOutput(self):\n        print ("Predicted XOR output data based on trained weights: ")\n        print ("Expected (X1-X3): \\n" + str(xPredicted))\n        print ("Output (Y1): \\n" + str(self.feedForward(xPredicted))) \n Epochs(ç–Šä»£æ¬¡æ•¸ï¼ŒfeedForward+backprogationé‹ç®—å®Œç®—ä¸€æ¬¡ç–Šä»£) \n # è¨“ç·´ç–Šä»£æ¬¡æ•¸\ntrainingEpochs = 1000 \n TensorFlowKeras.py \n origin\xa0codes: \n import tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers import Activation, Dense\nimport numpy as np\n# X = input of our 3 input XOR gate\n# set up the inputs of the neural network (right from the table)\nX = np.array(([0,0,0], [0,0,1], [0,1,0], [0,1,1], [1,0,0], [1,0,1], [1,1,0], [1,1,1]), dtype=float)\n# y = our output of our neural network\ny = np.array(([1], [0], [0], [0], [0], [0], [0], [1]), dtype=float)\nmodel = tf.keras.Sequential()\nmodel.add(Dense(4, input_dim=3, activation=\'relu\', use_bias=True))\n#model.add(Dense(4, activation=\'relu\', use_bias=True))\nmodel.add(Dense(1, activation=\'sigmoid\', use_bias=True))\nmodel.compile(loss=\'mean_squared_error\', optimizer=\'adam\', metrics=[\'binary_accuracy\'])\nprint (model.get_weights())\nhistory = model.fit(X, y, epochs=2000, validation_data = (X, y))\nmodel.summary()\n# printing out to file\nloss_history = history.history["loss"]\nnumpy_loss_history = np.array(loss_history)\nnp.savetxt("loss_history.txt", numpy_loss_history, delimiter="\\n")\nbinary_accuracy_history = history.history["binary_accuracy"]\nnumpy_binary_accuracy = np.array(binary_accuracy_history)\nnp.savetxt("binary_accuracy.txt", numpy_binary_accuracy, delimiter="\\n")\nprint(np.mean(history.history["binary_accuracy"]))\nresult = model.predict(X ).round()\nprint (result) \n å®šç¾©input(X)å’Œoutput(Y) \n X = np.array(([0,0,0],[0,0,1],[0,1,0], [0,1,1],[1,0,0],[1,0,1],[1,1,0],[1,1,1]), dtype=float)\n# Xæ˜¯ä¸‰è¼¸å…¥XORé‚è¼¯é–˜\ny = np.array(([1], [0], [0], [0], [0], [0], [0], [1]), dtype=float)\n# Yæ˜¯è¼¸å‡ºç¥ç¶“ç¶²è·¯ \n setting \n model = tf.keras.Sequential() #sequentialå®šç¾©modleç‚ºå±¤ç‹€çµæ§‹\nmodel.add(Dense(4, input_dim=3, activation=\'relu\', use_bias=True))\n\'\'\'\naddæ˜¯å¾æœ€ä¸Šå±¤é–‹å§‹åŠ å…¥ï¼ŒDenseæ˜¯å¯†é›†é€£ç·šçš„ç¥ç¶“ç¶²è·¯ï¼Œ\n4:è¼¸å‡ºç©ºé–“(ç¥ç¶“å…ƒï¼Œè¼¸å‡ºåˆ°4å€‹ç¥ç¶“å…ƒ)ï¼Œinput_dim:è¼¸å…¥ç¥ç¶“å…ƒå€‹æ•¸ï¼Œactivation:å®šç¾©å•Ÿå‹•å‡½æ•¸ä½¿ç”¨çš„é¡å‹ï¼Œuse_bias:ä½¿ç”¨åå·®ï¼ŒTrueé–‹å•Ÿã€‚å¾inputlayerè¼¸å‡ºåˆ°hiddenlayerçš„è¨­å®š\n\'\'\'\n\n#model.add(Dense(4, activation=\'relu\', use_bias=True))\nmodel.add(Dense(1, activation=\'sigmoid\', use_bias=True))\n# å¾hiddenlayerè¼¸å‡ºåˆ°outputlayerçš„è¨­å®š\n\nmodel.compile(loss=\'mean_squared_error\', optimizer=\'adam\', metrics=[\'binary_accuracy\'])\n\'\'\'\né…ç½®è¨“ç·´æ¨¡çµ„ï¼Œloss funsion:ç”¨maen squared error(å·®å¹³æ–¹èª¤å·®)ï¼Œoptimizer:å„ªåŒ–å™¨ï¼Œ\nç”¨adam functionï¼Œmetricsï¼šè¨ˆç®—æº–ç¢ºç‡ï¼Œç”¨binary_accuracy\n\'\'\'\n\nprint (model.get_weights())#å°å‡ºå›å‚³çš„æ­£ç¢ºæ¬Šé‡\nhistory = model.fit(X, y, epochs=2000, validation_data = (X, y))\n\'\'\'\nè¨“ç·´æ¨¡å‹çµ¦äºˆå›ºå®šepochsï¼Œè¿­ä»£æ”¶é›†åˆ°çš„è³‡æ–™ï¼Œvalidation_dataï¼šè©•ä¼°æº–ç¢ºç‡(ä¸åŒ…å«åœ¨è¨“ç·´è£¡é¢)\n\'\'\'\n \n ReLU max_valueï¼šè¼¸å‡ºå¾Œæœ€å¤§å€¼ä¸Šé™ negative_slopeï¼šè² æ–œç‡ä¿‚æ•¸ thresholdï¼šå¯é€šéçš„æ•¸å€¼ç•Œç·š \n [ tf.keras.layers.ReLU | TensorFlow Core v2.4.0 ] \n mean squared error(MSE) \n \n ( åœ–ç‰‡ä¾†æº ) \n \n [ Proof (part 1) minimizing squared error to regression line (video) | Khan Academy ] \n [ 15 Types of Regression in Data Science ] \n [ tf.keras.Sequential | TensorFlow Core v2.4.0 ] \n [ Machine learning: an introduction to mean squared error and regression lines ] \n [ tf.keras.layers.Dense | TensorFlow Core v2.4.0 ] \n [ Module: tf.keras.losses | TensorFlow Core v2.4.0 ] \n [ Module: tf.keras.optimizers | TensorFlow Core v2.4.0 ] \n [ Module: tf.keras.metrics | TensorFlow Core v2.4.0 ] \n [ hub.KerasLayer | TensorFlow Hub ] \n [ Module: tf.summary | TensorFlow Core v2.4.0 ] \n [ Keras documentation: Layer activation functions ] \n history \n model.summary()\n# æ‘˜è¦è³‡æ–™ä½¿ç”¨åœ¨åˆ†æå’Œå¯è¦–åŒ–ï¼Œç‚ºäº†ç¢ºèªè¨“ç·´æ¶æ§‹åœ¨ç¬¦åˆé æœŸæ–¹å‘\n\nloss_history = history.history["loss"]\n#å›å‚³ç´€éŒ„äº‹ä»¶(loss)åˆ°historyç‰©ä»¶ï¼Œå–å¾—fitæ–¹æ³•çš„æ¨¡çµ„å›å‚³å€¼\nnumpy_loss_history = np.array(loss_history)\n#å°‡loss_historyæ•¸å€¼å­˜æˆarray\nnp.savetxt("loss_history.txt", numpy_loss_history, delimiter="\\n")\n#å°‡numpy_loss_historyå­˜æˆloss_history.txtï¼Œä¸¦å°‡æ¯ç­†è³‡æ–™ç”¨æ›è¡Œç¬¦è™Ÿéš”é–‹\n\nbinary_accuracy_history = history.history["binary_accuracy"]\n#å›å‚³ç´€éŒ„äº‹ä»¶(binary_accuracy)åˆ°historyç‰©ä»¶\nnumpy_binary_accuracy = np.array(binary_accuracy_history)\n#å°‡binary_accuracy_historyæ•¸å€¼å­˜æˆarray\nnp.savetxt("binary_accuracy.txt", numpy_binary_accuracy, delimiter="\\n")\n#å°‡numpy_binary_accuracyå­˜æˆbinary_accuracy.txtï¼Œä¸¦å°‡æ¯ç­†è³‡æ–™ç”¨æ›è¡Œç¬¦è™Ÿéš”é–‹\n \n result \n print(np.mean(history.history["binary_accuracy"]))\n#å°å‡ºå¹³å‡binary_accuracyè¨˜éŒ„åˆ°çš„æ•¸å€¼\nresult = model.predict(X ).round()\n#æ›¿è¼¸å…¥æ¨£æœ¬ç”¢ç”Ÿè¼¸å‡ºé æ¸¬\nprint (result)\n#å°å‡ºçµæœ \n æ•´ç†å¥½çš„PDFæª”', 'tags': '', 'url': 'neural_network_in_python.pdf.html'}, {'title': 'åƒè€ƒç¯„ä¾‹', 'text': 'åƒè€ƒç¯„ä¾‹\xa0 https://github.com/mdecourse/4072pj1/blob/master/40723150/example/pong2.py \n GPUé‹ç®— \n with cp.cuda.Device(0):#ç”¨GPU0åšè¨ˆç®—\n    if resume:\n        model = pickle.load(open(\'save.p\', \'rb\'))\n        \'\'\'ä»¥\xa0Binary çš„æ–¹å¼è®€å–\xa0save.p\'\'\'\n        print(\'resuming\')\n    else:\n        model = {}\n        model[\'W1\'] = np.random.randn(D,H) / np.sqrt(D) \n\t\'\'\'W1æª¢æ¸¬éŠæˆ²å ´æ™¯\'\'\'\n        model[\'W2\'] = np.random.randn(H,A) / np.sqrt(H)\n\t\'\'\'W2æ±ºå®šæ“ŠéŒ˜å‘ä¸Šæˆ–å‘ä¸‹ç§»å‹•\'\'\'\n    grad_buffer = { k : np.zeros_like(v) for k, v in model.items() }\n    # update buffers that add up gradients over a batch\n    rmsprop_cache = { k : np.zeros_like(v) for k, v in model.items() }\n    # rmsprop memory\n \n \n \xa0python open()[ä¾†æºï¼š w3schools ] \n sigmoid\xa0 \n def sigmoid(x): \n    return 1.0 / (1.0 + np.exp(-x)) \n \n softmax \n def softmax(x):\n    probs = np.exp(x - np.max(x, axis=1, keepdims=True))\n    probs /= np.sum(probs, axis=1, keepdims=True)\n    return probs \n [ä¾†æºï¼š softmax è³‡æ–™] \n prepro \n def prepro(I):\n    """ prepro 210x160x3 uint8 frame into 6400 (80x80) 1D float vector """\n    I = I[35:195] # è£æ‰é ‚éƒ¨çš„è¨ˆåˆ†å’Œåº•éƒ¨ç©ºç™½ï¼Œå‰©ä¸‹160x160\n    I = I[::2,::2,0] # å¾160x160ç¸®æ¸›åˆ°80x80ï¼Œå–å‡ºç¬¬ä¸€å€‹é¡è‰²channel\n    I[I == 144] = 0 # å°‡èƒŒæ™¯é¡è‰²è®Šæˆé»‘è‰²\n    I[I == 109] = 0 # å°‡èƒŒæ™¯é¡è‰²è®Šæˆé»‘è‰²\n    I[I != 0] = 1 # çƒå’Œæ“ŠéŒ˜è®Šæˆç™½è‰²\n    return I.astype(np.float).ravel() \n discount rewards \n def discount_rewards(r):\n    """ take 1D float array of rewards and compute discounted reward """\n    discounted_r = np.zeros_like(r) #å’ŒrçŸ©é™£ç›¸åŒç¶­åº¦å¤§å°çš„0çŸ©é™£\n    running_add = 0\n    for t in reversed(range(0, r.size)):\n        if r[t] != 0: running_add = 0 \n        # ç•¶çƒåˆ°é‚Šç•Œçš„æ™‚å€™é‡è¨­ç¸½å’Œ\n        running_add = running_add * gamma + r[t]\n        discounted_r[t] = running_add\n\t\t    \'\'\'åŠ å…¥ç¬¬té …æŠ˜æ‰£\'\'\'\n    return discounted_r \n policy forward \n def policy_forward(x):\n    if(len(x.shape)==1):\n        x = x[np.newaxis,...]\n\n    h = x.dot(model[\'W1\'])\n    h[h<0] = 0 # ReLU nonlinearity\n    logp = h.dot(model[\'W2\'])\n    #p = sigmoid(logp)\n    p = softmax(logp)\n\n    return p, h \n    # return probability of taking action 2, and hidden state\n    # h æ˜¯çƒåœ¨ç’°å¢ƒä¸Šçš„ç‹€æ…‹ï¼Œp æ˜¯ç§»å‹•çš„æ±ºç­–\n \n policy backward \n def policy_backward(eph, epdlogp):\n    """ backward pass. (eph is array of intermediate hidden states) """\n    dW2 = eph.T.dot(epdlogp)  \n    dh = epdlogp.dot(model[\'W2\'].T)\n    dh[eph <= 0] = 0 # backpro prelu\n\n    t = time.time()\n    # problem: https://github.com/chainer/chainer/issues/8582\n    if(be == cp): #å°‡åƒæ•¸è¤‡è£½åˆ°GPUæˆ–CPU\n        dh_gpu = cuda.to_gpu(dh, device=0)\n        epx_gpu = cuda.to_gpu(epx.T, device=0)\n        dW1 = cuda.to_cpu( epx_gpu.dot(dh_gpu) )\n        # å°‡GPUçš„çŸ©é™£è¤‡è£½åˆ°CPU\n    else:\n        dW1 = epx.T.dot(dh) \n    \n\n    print((time.time()-t0)*1000, \' ms, @final bprop\')\n\n    return {\'W1\':dW1, \'W2\':dW2} \n è¨“ç·´éç¨‹ \n while True:\n    t0  = time.time()\n    #render = True\n    if render: \n        t  = time.time()\n        env.render()# é¡¯ç¤ºè¨“ç·´ä¸­ç‹€æ³(å½±åƒ)\n        print((time.time()-t)*1000, \' ms, @rendering\')\n        # è¨ˆç®—æ¯å¹€æ™‚é–“å·®\n\n    t  = time.time()\n    # preprocess the observation, set input to network to be difference image\n    cur_x = prepro(observation)\n    x = cur_x - prev_x if prev_x is not None else np.zeros(D)\n    prev_x = cur_x\n  \n    # forward the policy network and sample an action from the returned probability\n    t  = time.time()\n    aprob, h = policy_forward(x)\n    # roll the dice, in the softmax loss\n    u = np.random.uniform()\n    aprob_cum = np.cumsum(aprob)\n    a = np.where(u <= aprob_cum)[0][0]\n    action = a+2\n    #print(u, a, aprob_cum)\n  \n    # record various intermediates (needed later for backprop)\n    t = time.time()\n    xs.append(x) # observation\n    hs.append(h) # hidden state\n\n    #softmax loss gradient\n    dlogsoftmax = aprob.copy()\n    dlogsoftmax[0,a] -= 1 #-discounted reward \n    dlogps.append(dlogsoftmax)\n\n\n    # step the environment and get new measurements\n    t  = time.time()\n    observation, reward, done, info = env.step(action)\n    reward_sum += reward \n\n    drs.append(reward) # record reward (has to be done after we call step() to get reward for previous action)\n\n\n    if done: # an episode finished\n        episode_number += 1\n\n        t  = time.time()\n\n        # stack together all inputs, hidden states, action gradients, and rewards for this episode\n        epx = np.vstack(xs)\n        eph = np.vstack(hs)\n        epdlogp = np.vstack(dlogps)\n        epr = np.vstack(drs)\n        xs,hs,dlogps,drs = [],[],[],[] # reset array memory\n\n        print(epdlogp.shape)\n\n        # compute the discounted reward backwards through time\n        discounted_epr = discount_rewards(epr)\n        # standardize the rewards to be unit normal (helps control the gradient estimator variance)\n        discounted_epr -= np.mean(discounted_epr)\n        discounted_epr /= np.std(discounted_epr)\n\n        epdlogp *= discounted_epr # modulate the gradient with advantage (PG magic happens right here.)\n        grad = policy_backward(eph, epdlogp)\n        for k in model: grad_buffer[k] += grad[k] # accumulate grad over batch\n\n        # perform rmsprop parameter update every batch_size episodes\n        if episode_number % update_freq == 0: #update_freq used to be batch_size\n            for k,v in model.items():\n                g = grad_buffer[k] # gradient\n                rmsprop_cache[k] = decay_rate * rmsprop_cache[k] + (1 - decay_rate) * g**2\n                model[k] -= learning_rate * g / (np.sqrt(rmsprop_cache[k]) + 1e-5)\n                grad_buffer[k] = np.zeros_like(v) # reset batch gradient buffer\n\n        # boring book-keeping\n        running_reward = reward_sum if running_reward is None else running_reward * 0.99 + reward_sum * 0.01\n        print(\'resetting env. episode reward total was %f. running mean: %f\' % (reward_sum, running_reward))\n        if episode_number % 100 == 0: pickle.dump(model, open(\'save.p\', \'wb\'))\n        reward_sum = 0\n        observation = env.reset() # reset env\n        prev_x = None\n        \n        print((time.time()-t)*1000, \' ms, @backprop\')\n\n\n    outstring =""\n\n    if reward != 0: # Pong has either +1 or -1 reward exactly when game ends.\n        if reward == -1:\n            outstring = \'\'\n        else:\n            outstring = \'!!!!!!!\'\n        \n        print (\'ep \'+ str(episode_number) + \': game finished, reward:\' +str(reward)+ outstring )', 'tags': '', 'url': 'åƒè€ƒç¯„ä¾‹.html'}, {'title': 'Markov Decision Process', 'text': 'Markov Chain \n ç•¶å‰æ±ºç­–åªæœƒå½±éŸ¿ä¸‹å€‹ç‹€æ…‹ï¼Œç•¶å‰ç‹€æ…‹è½‰ç§»(action)åˆ°å…¶ä»–ç‹€æ…‹çš„æ©Ÿç‡æœ‰æ‰€å·®ç•°ã€‚ \n Markov Reward Process \n action åˆ°æŒ‡å®šç‹€æ…‹æœƒç²å¾—çå‹µã€‚ \n R(s t =s) =\xa0ğ”¼[r t |s t  = s] \n Î³ âˆˆ[0, 1] \n \n Horizonï¼š åœ¨ç„¡é™çš„ç‹€æ…‹ä»¥æœ‰é™çš„ç‹€æ…‹è¡¨ç¤º \n Returnï¼š G t  = R t+1 +\xa0Î³R t+2 \xa0+\xa0 Î³ 2 R t+3 \xa0 +\xa0 Î³ 3 R t+4 \xa0+ ...\xa0 +\xa0 Î³ T-t-1 R T è¶Šæ—©åšå‡ºæ­£ç¢ºæ±ºç­–çå‹µè¶Šé«˜ \n State value functionï¼š V t (S) =\xa0 ğ”¼[G t |s t \xa0 = s] æ±ºç­–åƒ¹å€¼ \n \n Discount Factor (Î³) \n \n è¶Šæ—©åšå‡ºæœ‰çå‹µçš„æ±ºç­–ï¼Œçå‹µè¶Šé«˜ \n åšå‡ºæœ‰åƒ¹å€¼çš„æ±ºç­– Î³ = 1ï¼Œä¸åˆ†æ±ºç­–é †åºå…ˆå¾Œ \n ç„¡ç”¨çš„æ±ºç­–Î³ = 0ï¼Œä¸æœƒå¾—åˆ°çå‹µ \n', 'tags': '', 'url': 'Markov Decision Process.html'}, {'title': 'å„ªåŒ–å™¨', 'text': 'ç‚ºäº†è®“AIå­¸ç¿’çš„éŒ¯èª¤ç‡é™ä½ï¼Œå› æ­¤åˆ©ç”¨å„ªåŒ–å™¨ä¾†é™ä½loss functionçš„å€¼ï¼Œåœ¨error surfaceä¸Šæ‰¾åˆ°æœ€å°å€¼ï¼Œå³æ˜¯æ‰¾åˆ°éŒ¯èª¤ç‡æœ€ä½çš„åœ°æ–¹ã€‚ä»¥ä¸‹å°‡ä»‹ç´¹å¹¾ç¨®å„ªåŒ–çš„æ–¹æ³•ï¼š \n Gradient Descent \n åˆ©ç”¨æ¢¯åº¦çš„æ–¹å¼å°‹æ‰¾æœ€å°å€¼çš„ä½ç½®ï¼Œå…¶ç‰¹è‰²å¯æ‰¾åˆ°å‡¸é¢error surfaceçš„çµ•å°æœ€å°å€¼ï¼Œåœ¨éå‡¸é¢error surfaceä¸Šæ‰¾åˆ°ç›¸å°æœ€å°å€¼ã€‚å…¶ç¼ºé»æ˜¯åœ¨éå‡¸é¢error surfaceè¦é¿å…è¢«å›°åœ¨æ¬¡å„ªçš„å±€éƒ¨æœ€å°å€¼ã€‚ \n Batch gradient descent \n ç”¨æ‰¹æ¬¡çš„æ–¹å¼è¨ˆç®—è¨“ç·´è³‡æ–™ï¼Œæ•´å€‹è³‡æ–™é›†è¨ˆç®—æ¢¯åº¦åªæ›´æ–°ä¸€æ¬¡ï¼Œå› æ­¤è¨ˆç®—å’Œæ›´æ–°æ™‚æœƒå ç”¨å¤§é‡è¨˜æ†¶é«”ã€‚æ•´é«”æ•ˆç‡è¼ƒå·®ã€é€Ÿåº¦è¼ƒç·©æ…¢ã€‚ç”± Gradient Descent å»¶ä¼¸å‡ºä¾†çš„ç®—æ³•ã€‚å…¶æ”¶æ–‚è¡Œç‚ºèˆ‡ \xa0Gradient Descent\xa0ç›¸åŒã€‚ \n Stochastic gradient descent \n æ¯æ¬¡åŸ·è¡Œæ™‚æœƒæ›´æ–°ä¸¦æ¶ˆé™¤èª¤å·®ï¼Œæœ‰é »ç¹æ›´æ–°å’Œè®ŠåŒ–å¤§çš„ç‰¹æ€§ï¼Œè¼ƒä¸å®¹æ˜“å›°åœ¨ç‰¹å®šå€åŸŸã€‚ ç”± Gradient Descent å»¶ä¼¸å‡ºä¾†çš„ç®—æ³•ã€‚å…¶æ”¶æ–‚è¡Œç‚ºèˆ‡ \xa0Gradient Descent\xa0ç›¸åŒã€‚ \n Mini-batch gradient descent \n çµåˆ\xa0Batch gradient descent å’Œ\xa0Stochastic gradient descent çš„ç‰¹é»ï¼šæ‰¹é‡è¨ˆç®—å’Œé »ç¹æ›´æ–°ï¼Œæ‰€è¡ä¼¸çš„ç®—æ³•ã€‚åˆ©ç”¨å°æ‰¹é‡çš„æ–¹å¼é »ç¹æ›´æ–°ï¼Œä¸¦ä½¿æ”¶æ–‚æ›´ç©©å®šã€‚å…¶ç¼ºé»ï¼šå­¸ç¿’ç‡æŒ‘é¸ä¸æ˜“ã€é å®šç¾© threshold\xa0ç„¡æ³•é©æ‡‰æ•¸æ“šé›†çš„ç‰¹å¾µã€å°å¾ˆå°‘ç™¼ç”Ÿçš„ç‰¹å¾µç„¡æ³•åŸ·è¡Œè¼ƒå¤§çš„æ›´æ–°ã€ éå‡¸é¢error surfaceè¦é¿å…è¢«å›°åœ¨æ¬¡å„ªçš„å±€éƒ¨æœ€å°å€¼ç­‰ã€‚ \n Gradient descent optimization algorithms \n ç‚ºäº†æ”¹å–„å‰é¢å¹¾ç¨®ç®—æ³•è€Œç™¼å±•å‡ºä¾†çš„å„ªåŒ–ç®—æ³•ã€‚ä»¥ä¸‹å°‡åˆ—å‡ºæ•¸ç¨®å„ªåŒ–ç®—æ³•ã€‚ \n Momentum \n åœ¨æ¢¯åº¦ä¸‹é™æ³•åŠ ä¸Šå‹•é‡çš„æ¦‚å¿µï¼ŒæœƒåŠ é€Ÿæ”¶æ–‚åˆ°æœ€å°å€¼ä¸¦æ¸›å°‘éœ‡ç›ªã€‚ \n Nesterov accelerated gradient \n NAGï¼Œæœ‰æ„ŸçŸ¥èƒ½åŠ›çš„ Momentumï¼šåœ¨å¡åº¦è®Šé™¡æ™‚æ¸›é€Ÿï¼Œé¿å…è¡éæœ€å°å€¼æ‰€é€ æˆçš„éœ‡ç›ª(ç‚ºäº†ä¿®æ­£åˆ°æœ€å°å€¼ï¼Œä¾†å›ä¿®æ­£è€Œç”¢ç”Ÿçš„éœ‡ç›ª) \n Adagrad \n å…¶å­¸ç¿’ç‡èƒ½é©æ‡‰åƒæ•¸ï¼š é »ç¹å‡ºç¾çš„ç‰¹å¾µç”¨è¼ƒä½çš„å­¸ç¿’ç‡ï¼Œä¸ç¶“å¸¸å‡ºç¾çš„ç‰¹å¾µå‰‡ç”¨è¼ƒé«˜çš„å­¸ç¿’ç‡ï¼Œä¸”ç„¡é ˆæ‰‹å‹•èª¿æ•´å­¸ç¿’ç‡ã€‚å…¶ç¼ºé»æ˜¯ï¼Œå­¸ç¿’ç‡æœƒæ€¥é½ä¸‹é™ï¼Œæœ€å¾Œæœƒç„¡é™å°ï¼Œé€™ç®—æ³•å°±ä¸å†ç²å¾—çŸ¥è­˜ã€‚ \n Adadelta \n ç‚º Adagrad çš„å»¶ä¼¸ï¼Œä¸‹é™æ¿€é€²ç¨‹åº¦ï¼Œå­¸ç¿’ç‡å¾æ›´æ–°è¦å‰‡ä¸­æ·˜æ±°ï¼Œä¸éœ€è¨­å®šé è¨­å­¸ç¿’ç‡ã€‚ \n RMSprop \n ç‚ºäº†è§£æ±º Adagrad å­¸ç¿’ç‡æ€¥åŠ‡ä¸‹é™çš„å•é¡Œï¼Œå­¸ç¿’ç‡é™¤ä»¥æ¢¯åº¦å¹³æ–¹çš„RMSï¼Œè§£æ±ºå­¸ç¿’ç‡ç„¡é™å°çš„æƒ…å½¢ã€‚ \n Adam \n é¡ä¼¼ Momentumï¼Œæ›´åŠ ç©©å®šå¿«é€Ÿçš„æ”¶æ–‚ã€‚ \n AdaMax \n èˆ‡ Adam ç›¸ä¼¼ï¼Œä¾é  u t \xa0 æœ€å¤§é‹ç®— \n Nadam \n çµåˆ Adam å’Œ NAG ï¼Œæ‡‰ç”¨å…ˆå‰åƒæ•¸åŸ·è¡Œå…©æ¬¡æ›´æ–°ï¼Œä¸€æ¬¡æ›´æ–°åƒæ•¸ä¸€æ¬¡æ›´æ–°æ¢¯åº¦ã€‚ \n AMSGrad \n æ”¹å–„ Adam ç®—æ³•æ‰€å°è‡´æ”¶æ–‚è¼ƒå·®çš„æƒ…æ³(ç”¨æŒ‡æ•¸å¹³å‡æœƒæ¸›å°‘å…¶å½±éŸ¿)ï¼Œæ›ç”¨æ¢¯åº¦å¹³æ–¹æœ€å¤§å€¼ä¾†åšè¨ˆç®—ï¼Œä¸¦ç§»é™¤å»åå·®çš„æ­¥é©Ÿã€‚æ˜¯å¦æœ‰æ¯”\xa0 Adam ç®—æ³•å¥½ä»æœ‰å¾…è§€å¯Ÿã€‚ \n Gradient noise \n æœ‰åŠ©æ–¼è¨“ç·´ç‰¹åˆ¥æ·±ä¸”å¾©é›œçš„ç¶²çµ¡ï¼Œnoise å¯æ”¹å–„ä¸è‰¯åˆå§‹åŒ–çš„ç¶²è·¯ã€‚ \n ç¥ç¶“ç¶²è·¯å„ªåŒ–å™¨ç®—æ³•æ•´ç† \n', 'tags': '', 'url': 'å„ªåŒ–å™¨.html'}, {'title': 'Gradient Descent Optimizer', 'text': '( è³‡æ–™ä¾†æº ) \n \n åœ–1.\xa0Error_surface ( åœ–ç‰‡ä¾†æº ) \n è—‰ç”±æ¢¯åº¦ä¸‹é™å°‡ç›®æ¨™å‡½æ•¸å€¼æœ€å°åŒ–ï¼Œç›®æ¨™å‡½æ•¸ä»¥loss function L(Î¸)ç‚ºä¾‹ï¼ŒÎ¸ç‚ºweight(w) å’Œ bias(b) çš„å‘é‡å‡½æ•¸ï¼Œç‚ºäº†æ‰¾åˆ°error surface[åœ–1]ä¸Šçš„æœ€å°å€¼ï¼Œå› æ­¤åŠ ä¸Šâˆ†Î¸ å°‡Î¸çš„æ–¹å‘ä¿®æ­£ä¸¦å¼•å°åˆ°æ­£ç¢ºæ–¹å‘ï¼Œé¿å…æ¯æ¬¡ä¿®æ­£çš„éå¤šå°è‡´éŒ¯éæœ€å°å€¼ï¼Œåˆ©ç”¨ä¿‚æ•¸Î·(å­¸ç¿’ç‡)ç¸®æ”¾ âˆ†Î¸çš„ä¿®æ­£é‡[åœ–2]ï¼Œä¿®æ­£å¾Œæ–¹ç¨‹å¼ç‚ºï¼š \n Î¸ = Î¸ + Î·Â·âˆ†Î¸ \n \n åœ–2. Theta_vector ( åœ–ç‰‡ä¾†æº ) \n å°‡ Î¸ä»¥ æ³°å‹’å±•é–‹å¼ è¡¨ç¤ºï¼Œå‡è¨­ä¸¦âˆ†Î¸ç‚ºu: \n â–½L(Î¸) = [âˆ‚L(Î¸)/âˆ‚w , âˆ‚L(Î¸)/âˆ‚b] \n L(Î¸+Î·u) = L(Î¸) + Î·u T Â·â–½Î¸L(Î¸) + (Î· 2 /2!)u T Â·â–½2L(Î¸)u + (Î· 3 /3!) ... + (Î· 4 /4!) ... + (Î· n /n!)... \n ä»¥æ³°å‹’å±•é–‹å¼çš„å‹å¼è¡¨ç¤ºçš„å¥½è™•æ˜¯ï¼š Î¸ äº›å¾®çš„æ›´å‹•ç”¢ç”Ÿæ–°å€¼ã€‚Î· å€¼é€šå¸¸å°æ–¼ä¸€ï¼Œç•¶ Î· 2  << 1ï¼Œå› æ­¤å¯ä»¥å¿½ç•¥é«˜éšé …\xa0 \n L(Î¸+Î·u) = L(Î¸) + Î·u T  Â· â–½Î¸L(Î¸) [Î· is typically small, so Î· 2  , Î· 3  , Â· Â· Â· â†’ 0] \n æ–°çš„ L(Î¸ + Î·u) è¼¸å‡ºçš„å€¼æœƒå°æ–¼ L(Î¸) L(Î¸+Î·u) âˆ’ L(Î¸) < 0ï¼ŒåŒç†å¯è­‰ u T Â·â–½Î¸L(Î¸) < 0ï¼Œç¬¦åˆué€™æ¢ä»¶ï¼šç•¶æ–°çš„å€¼å°æ–¼èˆŠçš„å€¼ï¼Œuå°±æ˜¯ä¸€å€‹å¥½çš„å€¼ã€‚å‡è¨­uå’Œâ–½Î¸L(Î¸) çš„å¤¾è§’ç‚º Î² \n cos(Î²) = u T Â·â–½Î¸L(Î¸)|u T ||â–½Î¸L(Î¸)|  \n å› ç‚º cos(Î¸) çš„å€¼ä»‹æ–¼ 1 å’Œ-1 ä¹‹é–“ \n  âˆ’1 < cos(Î²) = u T Â·â–½Î¸L(Î¸) |u T ||â–½Î¸ L(Î¸)| â‰¤ 1  \n k = |u T ||â–½Î¸ L(Î¸)|  âˆ’k â‰¤ k cos(Î²) =  u T Â·â–½Î¸L(Î¸) â‰¤ k   \n æ‰€ä»¥ç›¡å¯èƒ½çš„è®“æ–°å€¼å°æ–¼èˆŠå€¼ (L(Î¸+Î·u) âˆ’ L(Î¸) < 0)ï¼Œloss å€¼å°±æœƒæ¸›å°‘å¾—è¶Šå¤šã€‚å› æ­¤ u T Â· â–½Î¸L(Î¸) æ‡‰è©²ç‚ºè² ï¼Œåœ¨ é€™æƒ…æ³ä¸‹ cos(Î²) ç­‰æ–¼ âˆ’1ï¼ŒÎ² çš„è§’åº¦ç‚º 180 â—¦ ï¼Œé€™å°±æ˜¯Î¸ç§»å‹•çš„æ–¹å‘èˆ‡æ¢¯åº¦æ–¹å‘ç›¸åçš„åŸå› ã€‚ æ¢¯åº¦ä¸‹é™æ³•å‘Šè¨´æˆ‘å€‘ï¼šç•¶ Î¸ åœ¨ç‰¹å®šå€¼ï¼Œä¸¦æƒ³æ¸›å°‘æ–°çš„ Î¸ å€¼ï¼Œä½¿ loss å€¼é€æ¼¸æ¸›å°‘å°±æ‡‰è©²èˆ‡æ¢¯åº¦ç›¸åçš„æ–¹å‘æ‰¾ (è‹¥æ¢¯åº¦ç‚ºæ­£å€¼ï¼Œæ‰¾æœ€å°å€¼å°±éœ€å¾€è² çš„æ–¹å‘æ‰¾)  \n w t=1  =  w t  âˆ’ Î·â–½w t \n b t=1  =  b t  âˆ’ Î·â–½b t \n where at w = w t , b =  b t   \n w t  = âˆ‚L(Î¸)/âˆ‚wï¼›â–½b t  = âˆ‚L(Î¸)/âˆ‚b \n', 'tags': '', 'url': 'Gradient Descent Optimizer.html'}, {'title': 'Stochastic gradient descent', 'text': '( è³‡æ–™ä¾†æº ) \n Batch gradient descrnt \n Vanilla gradient descent åˆç¨± Batch gradient descent(æ‰¹æ¬¡æ¢¯åº¦ä¸‹é™æ³•)ï¼Œè¨ˆç®—ç›®æ¨™å‡½æ•¸çš„æ¢¯åº¦ï¼Œåƒæ•¸ Î¸ å°æ–¼æ•´å€‹ è¨“ç·´è³‡æ–™ï¼š \n  Î¸ = Î¸ âˆ’ Î· Â· â–½Î¸L(Î¸) \n ç›®æ¨™å‡½æ•¸ä»¥ç‚ºä¾‹ loss function L(Î¸)ï¼Œåƒæ•¸ Î¸ ç‚º weight (w) å’Œ bias (b) çš„å‡½æ•¸ï¼ŒÎ· ç‚ºå­¸ç¿’ç‡ã€‚ç”±æ–¼è¨ˆç®—æ•´å€‹è³‡æ–™é›†è¨ˆç®—æ¢¯åº¦åªæ›´æ–°ä¸€æ¬¡ï¼ŒBath gradient descent å¯èƒ½éå¸¸æ…¢ä¸¦ä¸”å°æ–¼è³‡æ–™é›†ç„¡æ³•ç¬¦åˆåŠè¨˜æ†¶é«”ä¾†èªªæ£˜æ‰‹ (ä¸€æ¬¡éœ€è¦å„²å­˜æ•´å€‹è³‡æ–™é›†çš„è³‡æ–™ï¼Œç•¶æ›´æ–°å’Œè¨ˆç®—æ™‚æœƒå ç”¨å¤§é‡è¨˜æ†¶é«”)ã€‚ \n for i in range(nb_epochs) :\nparams_grad = evaluate_gradient (loss_function, data, params)\nparams = params âˆ’ learning_rate âˆ— params_grad\n \n ç¨‹å¼1.\xa0Batch gradient descrnt\xa0 ( ç¨‹å¼ä¾†æº ) \n é å®šç¾©æ¯æ¬¡ epochï¼Œå…ˆè¨ˆç®— loss function æ¢¯åº¦å‘é‡å°æ–¼æ•´å€‹è³‡æ–™é›†åƒæ•¸å‘é‡ã€‚å¦‚æœæ¢¯åº¦å€¼ä¾†è‡ªæ–¼å…ˆå‰è¨ˆç®—å‡ºçš„æ¢¯åº¦å€¼ï¼Œå°±æœƒæª¢æŸ¥æ¢¯åº¦ï¼Œä¸¦ä»¥æ¢¯åº¦ç›¸åçš„æ–¹å‘æ›´æ–°åƒæ•¸\xa0 Î¸ ï¼Œå­¸ç¿’ç‡\xa0 Î·\xa0 æ±ºå®šå¤šå¤§çš„æ›´æ–°é‡ã€‚Batch gradient descent å°æ–¼å‡¸é¢èª¤å·®å¯ä»¥ä¿è­‰æ”¶æ–‚åˆ°å»£åŸŸæœ€å°å€¼ï¼Œå°æ–¼éé¢å‡¸èª¤å·®å¯ä»¥æ”¶æ–‚åˆ°å±€éƒ¨æœ€å°å€¼ã€‚ \n Stochastic gradient descent \n Stochastic gradient descent(SGD) éš¨æ©Ÿæ¢¯åº¦ä¸‹é™æ³•ï¼Œé€™è£¡çš„ç›®æ¨™å‡½æ•¸ç‚º J (Î¸, x i , y i ) (è®Šæ•¸ Î¸ ç‚º w(weight) å’Œ b(bias) çš„å‡½æ•¸ï¼Œä¹Ÿå¯ä»¥å¯«æˆ J (w, b, x i , y i ) )ã€‚ \n Î¸ = Î¸ âˆ’ Î· Â· â–½Î¸J(Î¸, x i , y i ) \n æ‰¹é‡æ¢¯åº¦ä¸‹é™ä»–æœƒåœ¨æ¯å€‹åƒæ•¸æ›´æ–°å‰é‡æ–°è¨ˆç®—ç›¸ä¼¼æ¢¯åº¦ã€‚SGD æ¯æ¬¡æ¬¡åŸ·è¡Œæœƒæ›´æ–°ä¾†æ¶ˆé™¤å¤šé¤˜ (èª¤å·®)ï¼Œå› æ­¤é€šå¸¸é€Ÿåº¦ å¾ˆå¿«ã€‚SGD é »ç¹æ›´æ–°ä¸¦è®ŠåŒ–å¾ˆå¤§ï¼Œå› ç‚ºç›®æ¨™æ–¹ç¨‹å¼æ³¢å‹•å¾ˆå¤§ [åœ–1]ã€‚ \n \n åœ–1.SGD fluctuation\xa0 ( åœ–ç‰‡ä¾†æº ) \n SGD çš„æ–¹ç¨‹å¼ä¸€æ–¹é¢æœƒè·³åˆ°æ–°çš„å€¼å’Œæ½›åœ¨å±€éƒ¨æœ€å°å€¼ï¼Œå¦ä¸€æ–¹é¢ SGD æœƒæŒçºŒè¶…èª¿ (èª¤å·®è¶…éé æœŸ) æœ€å¾Œæ”¶æ–‚åˆ°å»£åŸŸæœ€å°å€¼ã€‚ç„¡è«–å¦‚ä½•ä»–è¢«é¡¯ç¤ºç•¶å­¸ç¿’ç‡ä¸‹é™ç·©æ…¢ï¼ŒSGD é¡¯ç¤ºèˆ‡ Batch gradient descent åŒæ¨£æ”¶æ–‚è¡Œç‚ºï¼Œå¹¾ä¹å¯ä»¥è‚¯å®šåœ°ï¼Œå°æ–¼å‡¸é¢æˆ–éå‡¸é¢å„ªåŒ–ï¼Œæœƒæ”¶æ–‚åˆ°çµ•å°æˆ–æ˜¯å±€éƒ¨æœ€å°å€¼ã€‚é€™ç¨‹å¼ç¢¼ç‰‡æ®µ [ç¨‹å¼.2] åœ¨è¨“ç·´æ¨£æœ¬ä¸ŠåŠ å…¥ä¸€å€‹è¿´åœˆä¾†å°æ¯å€‹æ¨£æœ¬è©•ä¼°æ¢¯åº¦ã€‚æ¯å€‹ epoch(è¨“ç·´å¾ªç’°) æœƒæ‰“äº‚è¨“ç·´æ•¸æ“šã€‚ \n for i in range(nb_epochs) :\nnp.random.shuffle(data)\nfor example in data :\nparams_grad = evaluate_gradient (loss_function, example, params)\nparams = params âˆ’ learning_rate âˆ— params_grad \n ç¨‹å¼2.\xa0Stochastic\xa0gradient descrnt\xa0 ( ç¨‹å¼ä¾†æº ) \n Mini-batch gradient descent \n Mini-batch gradient descent(å°æ‰¹é‡æ¢¯åº¦ä¸‹é™) å„å–å‰å…©è€…çš„å„ªé»ï¼Œå°‡è³‡æ–™é›†åˆ†å‰²æˆå°å€å¡Šï¼Œæ¯å€‹å°å€å¡Šå¤§å°ç¨±ä½œ batch sizeï¼Œæ¯æ¬¡è·‘å®Œ batch size ç®—è¿­ä»£ (iteration)ä¸€æ¬¡ï¼Œç®—å®Œä¸€æ¬¡è³‡æ–™é›†å³å®Œæˆä¸€æ¬¡ epochã€‚èˆ‰ä¾‹: è³‡æ–™é›†å¤§å°ç‚º 1000ï¼Œè‹¥ batch size ç‚º 50ï¼Œiteration ç‚º datasets çš„ batch_size = 1000Ã·50 = 20ï¼Œç•¶ iteration è·‘å®Œ 20 æ¬¡ç®—å®Œæˆä¸€æ¬¡ epochã€‚ \n é€™æ–¹å¼å¯ä»¥æ¸›å°‘åƒæ•¸æ›´æ–°çš„æ–¹å·®ï¼Œä¸¦ä¸”å¯ä»¥ç©©å®šæ”¶æ–‚ï¼›å¯åˆ©ç”¨æ·±åº¦å­¸ç¿’åº«æ‰€å…±æœ‰çš„é«˜åº¦å„ªåŒ–çš„çŸ©é™£å„ªåŒ–ï¼Œå¾è€Œç”±ä¸€å€‹å°æ‰¹é‡è¨ˆç®—å‡ºæ¢¯åº¦éå¸¸æœ‰æ•ˆã€‚é€šå¸¸ batch sizes çš„ç¯„åœä»‹æ–¼ 50 ~256ï¼Œæœƒå› ç‚ºæ‡‰ç”¨è€Œæœ‰æ‰€å·®ç•°ã€‚è¨“ç·´ç¥ç¶“ç¶²çµ¡æ™‚ï¼Œé€šå¸¸é¸æ“‡ Mini-batch gradient descent ç®—æ³•ï¼Œè€Œç•¶ä½¿ç”¨é€™ç®—æ³•æ™‚ï¼Œé€šå¸¸ä¹Ÿç”¨ SGD ç¨±å‘¼ã€‚ \n Î¸ = Î¸ âˆ’ Î·Â·â–½Î¸J(Î¸, x ( i : i + n) , y ( i : i + n) ) \n ä¸‹é¢ç¨‹å¼ç¢¼ [ç¨‹å¼.3] ç‚ºè¿­ä»£ç¯„ä¾‹ï¼Œbatch size å¤§å°ç‚º 50ï¼š \n for i in range(nb_epochs ) :\nnp.random.shuffle(data)\nfor batch in get_batches (data, batch_size = 50):\nparams_grad = evaluate_gradient (loss_function, batch, params)\nparams = params âˆ’ learning_rate âˆ— params_grad\n \n ç¨‹å¼3.  Mini-batch  gradient descrnt\xa0 ( ç¨‹å¼ä¾†æº ) \n Challenges \n Mini-batch gradient descent ç„¡è«–å¦‚ä½•é‚„æ˜¯ç„¡æ³•ç¢ºä¿æ”¶æ–‚çš„å¾ˆå¥½ï¼Œå­˜åœ¨ä¸€äº›éœ€è¦è§£æ±ºçš„æŒ‘æˆ°ï¼š \n \n é¸æ“‡é©ç•¶çš„å­¸ç¿’ç‡æ˜¯æœ‰é›£åº¦çš„ã€‚å¦‚æœå­¸ç¿’ç‡å¤ªå°æœƒå°è‡´æ”¶æ–‚å›°é›£æˆ–ç·©æ…¢ï¼Œå­¸ç¿’ç‡å¤ªå¤§å‰‡æœƒé˜»ç¤™æ”¶æ–‚å°è‡´ loss function ä¾†å›æ³¢å‹•æˆ–ç™¼ç”Ÿåé›¢ã€‚ \n \xa0å­¸ç¿’ç‡æ¸…å–®å˜—è©¦åœ¨è¨“ç·´çš„æ™‚å€™èª¿æ•´å­¸ç¿’ç‡ï¼Œå³æ ¹æ“šé å®šç¾©æ¸…å–®æˆ–ç•¶ç›®æ¨™ä¸‹é™æ–¼é–¾å€¼ (threshold) æ™‚é™ä½å­¸ç¿’ç‡ã€‚ ä½†æ¸…å–®å’Œé–¾å€¼é ˆé å…ˆå®šç¾©ï¼Œå› æ­¤ç„¡æ³•é©æ‡‰æ•¸æ“šé›†çš„ç‰¹å¾µã€‚ \n \xa0å¦å¤–ç›¸åŒå­¸ç¿’ç‡é©ç”¨å…¨éƒ¨åƒæ•¸æ›´æ–°ã€‚å¦‚æœè³‡æ–™ç¨€ç–è€Œä¸”å¤–å‹æœ‰å¾ˆç‰¹åˆ¥çš„é »ç‡ï¼Œæˆ‘å€‘å¯èƒ½ä¸å¸Œæœ›å°‡æ‰€æœ‰ç‰¹å¾µæ›´æ–° åˆ°ç›¸åŒçš„ç¨‹åº¦ï¼Œè€Œæ˜¯å°å¾ˆå°‘ç™¼ç”Ÿçš„ç‰¹å¾µåŸ·è¡Œè¼ƒå¤§çš„æ›´æ–°ã€‚ \n \xa0æœ€å°åŒ–ç¥ç¶“ç¶²è·¯å¸¸è¦‹çš„é«˜åº¦éå‡¸é¢èª¤å·®æ–¹ç¨‹å¼ (error function) çš„å¦ä¸€é—œéµæŒ‘æˆ°å‰‡æ˜¯è¦é¿å…è¢«å›°åœ¨å¤§é‡æ¬¡å„ªçš„å±€ éƒ¨æœ€å°å€¼å€åŸŸä¸­ã€‚èªç‚ºå›°é›£å¯¦éš›ä¸Šä¸æ˜¯ç”±å±€éƒ¨æœ€å°å€¼å¼•èµ·çš„ï¼Œè€Œæ˜¯ç”±éé»å¼•èµ·çš„ï¼Œå³ä¸€ç¶­å‘ä¸Šå‚¾æ–œè€Œå¦ä¸€ç¶­å‘ä¸‹ å‚¾æ–œçš„é»ã€‚é€™äº›éé»é€šå¸¸è¢«ç›¸åŒèª¤å·®çš„å¹³ç©©æ®µåŒ…åœï¼Œé€™ä½¿å¾— SGD å¾ˆé›£é€ƒè„«ï¼Œå› ç‚ºåœ¨æ‰€æœ‰ç¶­åº¦ä¸Šæ¢¯åº¦éƒ½æ¥è¿‘æ–¼é›¶ã€‚ \n \n', 'tags': '', 'url': 'Stochastic gradient descent.html'}, {'title': 'Gradient descent optimization algorithms', 'text': '( è³‡æ–™ä¾†æº ) \n Momentum \n SGD é›£ä»¥åœ¨é™¡å³­çš„å¾€æ­£ç¢ºçš„æ–¹å‘ï¼Œé‚£å°±æ˜¯èªªåœ¨ä¸€å€‹ç¶­åº¦ä¸Šï¼Œæ›²é¢çš„å½æ›²æ¯”å¦ä¸€å€‹ç¶­åº¦è¦é™¡å¾—å¤šï¼Œé€™åœ¨å±€éƒ¨æœ€å„ªæƒ…æ³ä¸‹å¾ˆå¸¸è¦‹ã€‚ä¸‹åœ–[åœ–.1]çš„åŒå¿ƒåœ“ä»£è¡¨ä¸­å¿ƒä¸‹å‡¹çš„æ›²é¢ã€‚åœ¨é€™äº›æƒ…æ³ä¸‹ï¼ŒSGD æœƒåœ¨é™¡å³­çš„åœ°æ–¹æŒ¯ç›ªï¼Œè€Œåƒ…æ²¿è‘—åº•éƒ¨æœè‘—å±€éƒ¨æœ€å„ªæ–¹å‘çŒ¶è±«å‰é€²ï¼Œå¦‚ [åœ–.1.a] æ‰€ ç¤ºã€‚ Momentun(å‹•é‡) æ˜¯ä¸€å€‹å¹«åŠ©åŠ é€Ÿ SGD åœ¨æ­£ç¢ºæ–¹å‘å’ŒæŠ‘åˆ¶éœ‡ç›ªçš„æ–¹æ³•ï¼Œåœ¨ [åœ–.1.b]ã€‚ \n \n \n \n \n \n \n \n \xa0åœ–.1. a SGD without momentum\xa0 ( åœ–ç‰‡ä¾†æº ) \n åœ–.1. b SGD with momentum\xa0 ( åœ–ç‰‡ä¾†æº ) \n \n \n \n é€™éº¼åšæœƒå¢åŠ ä¸€å€‹ä¿‚æ•¸ Î³ (gamma) ä¾†æ›´æ–°ä¸Šæ¬¡çš„å‘é‡åˆ°æ­£ç¢ºå‘é‡ (ä¿®æ­£åå·®)ï¼ŒÎ³ é€šå¸¸è¨­ç‚º 0.9 å·¦å³ã€‚ \n v t  = Î³v tâˆ’1  + Î·Â·â–½Î¸J(Î¸)  Î¸ = Î¸ âˆ’ v t \n å¯¦éš›ä¸Šï¼Œä½¿ç”¨å‹•é‡çš„æ™‚å€™ï¼Œå°±åƒå°‡çƒæ¨ä¸‹å±±å¡ã€‚çƒåœ¨ä¸‹å¡æ™‚æ»¾å‹•æ™‚æœƒç´¯ç©å‹•é‡ï¼Œåœ¨é€”ä¸­é€Ÿåº¦æœƒè¶Šä¾†è¶Šå¿«ï¼ˆå¦‚æœå­˜åœ¨ç©ºæ°£é˜»åŠ›ï¼Œç›´åˆ°é”åˆ°æ¥µé™é€Ÿåº¦ï¼Œä¹Ÿå°±æ˜¯ Î³ < 1) åƒæ•¸æ›´æ–°ä¹Ÿç™¼ç”Ÿäº†åŒæ¨£çš„äº‹æƒ…ï¼šå‹•é‡ (momentum) å°æ–¼æ¢¯åº¦æŒ‡å‘ç›¸åŒæ–¹å‘çš„ç¶­åº¦å¢åŠ ï¼Œè€Œå°æ–¼æ¢¯åº¦æ”¹è®Šæ–¹å‘çš„ç¶­æ¸›å°‘å‹•é‡ã€‚çµæœï¼Œæˆ‘å€‘ç²å¾—äº†æ›´å¿«çš„æ”¶æ–‚ä¸¦æ¸›å°‘äº†æŒ¯ç›ªã€‚ \n Nesterov accelerated gradient \n Nesterov accelerated gradientï¼ˆNAGï¼‰æ˜¯ä¸€ç¨®ä½¿å‹•é‡å…·æœ‰ä¸€å€‹å»å‘çš„æ¦‚å¿µï¼Œä»¥ä¾¿åœ¨å±±å¡å†æ¬¡è®Šé«˜ä¹‹å‰çŸ¥é“å®ƒæœƒæ¸›é€Ÿã€‚æˆ‘å€‘çŸ¥é“ä½¿ç”¨å‹•é‡ Î³v tâˆ’1  ä¾†ç§»å‹•åƒæ•¸ã€‚è¨ˆç®— Î¸ âˆ’ Î³v tâˆ’1  é€™æ¨£å°±çµ¦äº†åƒæ•¸çš„ä¸‹ä¸€å€‹ä½ç½®çš„è¿‘ä¼¼å€¼ï¼ˆå®Œæ•´æ›´æ–°ç¼ºå°‘çš„æ¢¯åº¦ï¼‰ï¼Œé€™æ˜¯åƒæ•¸å°‡è¦å­˜åœ¨çš„å¤§è‡´æ¦‚å¿µã€‚ç¾åœ¨ï¼Œé€šéè¨ˆç®—èˆ‡ç•¶å‰åƒæ•¸ç„¡é—œçš„æ¢¯åº¦ä¾†æœ‰æ•ˆåœ°çœ‹åˆ°ç›®å‰çš„åƒæ•¸ Î¸ å°‡æœƒç§»å‹•åˆ°çš„ä½ç½®ï¼š \n v t  = Î³vtâˆ’1 + Î·Â·â–½Î¸J(Î¸âˆ’Î³vtâˆ’1) \n Î¸ = Î¸ âˆ’ v t \n \n åœ–.2 NAG\xa0 ( åœ–ç‰‡ä¾†æº ) \n åŒæ¨£ï¼Œæˆ‘å€‘è¨­ç½®å‹•é‡ Î³ ç´„ç‚º 0.9ã€‚å‹•é‡é¦–å…ˆè¨ˆç®—ç•¶å‰æ¢¯åº¦ï¼ˆ[åœ–.2] ä¸­çš„è—è‰²å°å‘é‡ï¼‰ï¼Œç„¶å¾Œåœ¨æ›´æ–°çš„ç´¯ç©æ¢¯åº¦ï¼ˆè— è‰²å‘é‡ï¼‰çš„æ–¹å‘ä¸Šç™¼ç”Ÿè¼ƒå¤§çš„è·³èºï¼Œè€Œ NAG é¦–å…ˆåœ¨å…ˆå‰çš„ç´¯ç©æ¢¯åº¦çš„æ–¹å‘ä¸Šé€²è¡Œè¼ƒå¤§çš„è·³èºï¼ˆæ£•è‰²å‘é‡ï¼‰ï¼Œæ¸¬é‡æ¢¯åº¦ï¼Œç„¶å¾Œé€²è¡Œæ ¡æ­£ï¼ˆç´…è‰²å‘é‡ï¼‰ï¼Œå¾è€Œå®Œæˆ NAG æ›´æ–°ï¼ˆç¶ è‰²å‘é‡ï¼‰ã€‚é€™ç¨®é æœŸçš„æ›´æ–°å¯é˜²æ­¢æˆ‘å€‘éå¿«åœ°é€²è¡Œï¼Œä¸¦å°è‡´éŸ¿æ‡‰é€Ÿåº¦å¢åŠ ï¼Œå¾è€Œé¡¯è‘—æé«˜äº† RNN åœ¨è¨±å¤šä»»å‹™ä¸Šçš„æ€§èƒ½ã€‚æœ‰é—œ NAG èƒŒå¾Œå¦ä¸€è§£é‡‹ï¼Œè«‹ åƒè¦‹æ­¤è™• ï¼Œè€Œ Ilya Sutskever åœ¨å…¶åšå£«è«–æ–‡ä¸­çµ¦å‡ºäº†æ›´è©³ç´°çš„æ¦‚è¿°ã€‚ \n Adagrad \n Adagrad æ˜¯ä¸€å€‹æ¢¯åº¦å„ªåŒ–çš„ç®—æ³•ï¼Œå®ƒå¯ä»¥åšåˆ°ï¼šå­¸ç¿’ç‡é©æ‡‰åƒæ•¸ï¼Œå°æ–¼é »ç¹å‡ºç¾çš„ç‰¹å¾µç›¸é—œåƒæ•¸åŸ·è¡Œè¼ƒå°çš„æ›´æ–°(è¼ƒä½çš„å­¸ç¿’ç‡)ï¼Œä»¥åŠå°ä¸ç¶“å¸¸å‡ºç¾çš„ç‰¹å¾µç›¸é—œåƒæ•¸é€²è¡Œè¼ƒå¤§æ›´æ–°ï¼ˆå³å­¸ç¿’ç‡è¼ƒé«˜ï¼‰ã€‚Adagrad å¯ä»¥æé«˜ SGD çš„å¼·åº¦ï¼Œç”¨æ–¼è¨“ç·´å¤§å‹ç¥ç¶“ç¶²çµ¡ã€‚ \n å…ˆå‰ï¼Œåœ¨åŒä¸€æ¬¡ Î¸ åƒæ•¸(æ›´æ–°å¾Œå°±ç®—å¦ä¸€æ¬¡)ï¼Œæ¯å€‹ Î¸ éƒ½ä½¿ç”¨ç›¸åŒçš„ Î· (å­¸ç¿’ç‡)ã€‚Adagrad å‰‡æ˜¯å°æ¯å€‹ Î¸ åƒæ•¸ä½¿ç”¨ ä¸åŒçš„ Î·ï¼Œt ä»£è¡¨ time stepã€‚å…ˆå°‡ Adagrad çš„æ›´æ–°åƒæ•¸å‘é‡åŒ–ã€‚ç”¨ g t  è¡¨ç¤º time step çš„æ¢¯åº¦ï¼Œg t,i  è¡¨ç¤ºç›®æ¨™å‡½æ•¸ (åƒæ•¸ Î¸ åœ¨ time step t) å°åƒæ•¸åšåå¾®åˆ†è¨ˆç®—ã€‚ \n g t,i  = â–½Î¸J(Î¸ t,i\xa0 ) \n ç•¶ SGD æ›´æ–°æ¯å€‹åƒæ•¸ Î¸ i ï¼Œåœ¨æ¯å€‹ time step tï¼Œå› æ­¤è®Šæˆï¼š \n Î¸ t+1,i  = Î¸ t,i  âˆ’ Î· Â· g t,i  \n æ›´æ–°è¦å‰‡ï¼ŒAdagrad æ ¹æ“šå…ˆå‰ Î¸ i  è¨ˆç®—çš„æ¢¯åº¦ï¼Œå°æ¯å€‹åƒæ•¸ Î¸ i  ä¿®æ”¹æ•´å€‹å­¸ç¿’ç‡ Î· åœ¨æ¯å€‹ time steptï¼š \n Î¸ t+1,i  = Î¸ t,i  âˆ’ [Î· / (G t,ii  + Ïµ) Â½ ] \n G t  âˆˆ R dÃ—d  é€™æ˜¯ä¸€å€‹å°è§’çŸ©é™£æ¯å€‹å°è§’å…ƒç´  iï¼Œi æ˜¯é—œæ–¼ Î¸ æ¢¯åº¦å¹³æ–¹å’Œå–æ±ºæ–¼ time steptï¼ŒÏµ æ˜¯é¿å…åˆ†æ¯ç‚º 0(Ïµ é€šå¸¸ ç‚º 10 âˆ’8  )ï¼Œå¦‚æœæ²’æœ‰å¹³æ–¹æ ¹é‹ç®—ï¼Œè©²ç®—æ³•çš„æ€§èƒ½å°‡å¤§å¤§é™ä½ã€‚ G t  åŒ…å«äº†éå»æ¢¯åº¦å¹³æ–¹æ ¹ï¼Œç”±æ–¼å…¨éƒ¨ Î¸ åƒæ•¸æ²¿è‘—å°è§’ç·šï¼Œé€šéå‘é‡çš„å…§ç©è¨ˆç®— G t  å’Œ g t ï¼š \n Î¸ t+1  = Î¸ t  âˆ’ \xa0[Î· / (G t\xa0 + Ïµ) Â½ ] Â·g t  \n Adagrad ä¸»è¦å¥½è™•ä¹‹ä¸€æ˜¯ï¼Œç„¡éœ€æ‰‹å‹•èª¿æ•´å­¸ç¿’ç‡ã€‚å¤§å¤šæ•¸å¯¦ç¾ä½¿ç”¨é è¨­å€¼ 0.01 ä¸¦å°‡å…¶ä¿ç•™ç‚ºé è¨­å€¼ã€‚Adagrad ä¸» è¦å¼±é»æ˜¯æœƒç´¯ç©åˆ†æ¯çš„å¹³æ–¹æ¢¯åº¦ï¼šç”±æ–¼æ¯é …éƒ½æ˜¯æ­£çš„ï¼Œç´¯ç©å’Œæœƒåœ¨è¨“ç·´ä¸­ä¸æ–·å¢é•·ã€‚åéä¾†ï¼Œå­¸ç¿’ç‡ä¸‹é™ï¼Œä¸¦æœ€çµ‚è®Š å¾—ç„¡é™å°ï¼Œé€™ç®—æ³•å°±ä¸å†ç²å¾—çŸ¥è­˜ã€‚ \n Adadelta \n Adadelta æ˜¯ Adagrad çš„å»¶ä¼¸ï¼Œä¸‹é™å…¶æ¿€é€²çš„ç¨‹åº¦ï¼Œå–®èª¿çš„é™ä½å­¸ç¿’ç‡ã€‚Adadelta æœƒé™åˆ¶éå»ç´¯ç©çš„æ¢¯åº¦ï¼Œä¸¦å°‡å…¶ é™åˆ¶åœ¨æŸå€‹ç‰¹å®šå¤§å° wï¼Œä¸¦ä»£æ›¿ Adagrad éå»ç´¯ç©çš„æ¢¯åº¦å¹³æ–¹ï¼Œä»¥æ¢¯åº¦ç¸½å’Œæ˜¯éè¿´å®šç¾©ç‚ºæ‰€æœ‰éå»è¡°æ¸›æ¢¯åº¦å¹³æ–¹å¹³å‡å€¼ã€‚æµå‹•å¹³å‡ E[g 2 ] t  åœ¨ time step t ç„¶å¾Œå–æ±ºæ–¼ (åƒ Momentum çš„ Î³) å…ˆå‰ å¹³å‡å’Œæœ€è¿‘æ¢¯åº¦ï¼š \n E[g 2 ] t  = Î³ E[g 2 ] t -1 \xa0+ (1 âˆ’ Î³)g 2 t \n Î³ å€¼å’Œ Momentum çš„ç›¸ä¼¼ï¼Œç´„ç‚º 0.9ï¼Œç¾åœ¨æ ¹æ“šåƒæ•¸æ›´æ–°å‘é‡ â–³Î¸t ä¾†é‡å¯« SGDï¼š \n â–³Î¸ t  = âˆ’Î· Â· g t,i \n Î¸ t+1  = Î¸ t  + â–³Î¸ t \n Adagrad çš„åƒæ•¸æ›´æ–°å‘é‡æ›¿æ›æˆï¼šå°è§’çŸ©é™£ G t  éå»æ¢¯åº¦å¹³æ–¹çš„è¡°é€€å¹³å‡  E[g 2 ] t \n â–³Î¸ t  = âˆ’  [Î· / (G t\xa0 + Ïµ) Â½ ] Â·g t \n replace  G t \xa0 with  \xa0 E[g 2 ] t \xa0  â‡’ â–³ Î¸ t  =\xa0 âˆ’ \xa0 [Î· / (E[g 2 ] t\xa0 + Ïµ) Â½ ] Â·g t \n ç”±æ–¼åˆ†æ¯åªæ˜¯æ¢¯åº¦çš„å‡æ–¹æ ¹ (RMS)ï¼Œæˆ‘å€‘å¯ä»¥å–ä»£æˆç¸®å¯«ï¼š \n â–³Î¸ t  = âˆ’ Î· RMS[g] t  Â·  g t \n é€™å€‹æ›´æ–°å–®ä½å’Œ SGDã€Momentum ä»¥åŠ Adagrad çš„å–®ä½ä¸ç¬¦åˆï¼Œå› æ­¤æ›´æ–°éœ€æœ‰ç›¸åŒçš„åƒæ•¸ã€‚ç‚ºäº†å¯¦ç¾é€™ä¸€é»ï¼Œé¦–å…ˆå®šç¾©å¦ä¸€å€‹æŒ‡æ•¸è¡°æ¸›å¹³å‡å€¼ï¼Œé€™æ¬¡ä¸æ˜¯æ¢¯åº¦å¹³æ–¹æ›´æ–°è€Œæ˜¯åƒæ•¸å¹³æ–¹æ›´æ–°ï¼š \n E[ â–³Î¸ 2 ] t  = Î³E[â–³Î¸ 2 ] tâˆ’1  + (1 âˆ’ Î³) â–³ Î¸ 2 t \n RMS åƒæ•¸æ›´æ–°: \n RMS[â–³Î¸ ] t  = (E [â–³Î¸ 2 ] t  + Ïµ ) Â½ \n RMS[â–³Î¸ ] t  æ˜¯æœªçŸ¥çš„ï¼Œæ›´æ–°åƒæ•¸çš„ RMS å–è¿‘ä¼¼å€¼åˆ°ä¸Šå€‹ time stepã€‚ç”¨ RMS [â–³Î¸ ] t-1  å–ä»£å­¸ç¿’ç‡ Î·ï¼Œæœ€å¾Œç”¢ç”Ÿæ–° çš„è¦å‰‡ï¼š \n â–³ Î¸ t  = âˆ’ (RMS[â–³Î¸ ] t-1  / RMS[g ] t  ) Â·g t Î¸ t-1 = Î¸ t \xa0+ â–³ Î¸ t \n ä½¿ç”¨ Adadeltaï¼Œç”šè‡³ä¸éœ€è¦è¨­å®šé è¨­å­¸ç¿’ç‡ï¼Œå› ç‚ºå®ƒå·²å¾æ›´æ–°è¦å‰‡æ·˜æ±°ã€‚ \n RMSprop \n RMSprop æ˜¯ Geoffrey Hinton åœ¨ä»–çš„èª²ç¨‹ä¸­æå‡ºçš„æœªå…¬é–‹è‡ªé©æ‡‰å­¸ç¿’ç‡çš„æ–¹æ³•ã€‚ \n RMSprop å’Œ Adadelta éƒ½æ˜¯ç‚ºäº†è§£æ±º Adagrad çš„å­¸ç¿’ç‡æ€¥åŠ‡ä¸‹é™çš„å•é¡Œå€‹åˆ¥ç¨ç«‹é–‹ç™¼å‡ºä¾†çš„è§£æ±ºæ–¹å¼ã€‚RMSprop å¯¦éš›ä¸Šèˆ‡ Adadelta å¾—å‡ºçš„ç¬¬ä¸€å€‹æ›´æ–°å‘é‡ç›¸åŒï¼š \n E[g 2 ] t\xa0 = 0.9 E[g 2 ] t\xa0  + 0.1 g 2 t Î¸ t+1\xa0 =\xa0 Î¸ t \xa0 âˆ’ \xa0 [Î· / (E[g 2 ] t\xa0 + Ïµ) Â½ ] Â·g t \n RMSprop ä¹Ÿå°‡å­¸ç¿’ç‡é™¤ä»¥æ¢¯åº¦å¹³æ–¹çš„æŒ‡æ•¸è¡°æ¸›å¹³å‡å€¼ã€‚Hinton å»ºè­° Î³ è¨­ç‚º 0.9ï¼Œå¥½çš„é è¨­å­¸ç¿’ç‡ Î· æ•¸å€¼ç‚º 0.001ã€‚ \n Adam \n Adaptive Moment Estimation è‡ªé©æ‡‰çŸ©è©•ä¼° (Adam) æ˜¯å¦ä¸€ç¨®è¨ˆç®—æ¯å€‹è©•ä¼°å­¸ç¿’ç‡çš„æ–¹æ³•ã€‚å‡ºäº†å„²å­˜éå»æ¢¯åº¦å¹³ æ–¹çš„æŒ‡æ•¸è¡°æ¸›å¹³å‡å€¼  v t ï¼Œå°±åƒ Adadelta å’Œ RMSprop ä¸€æ¨£ï¼ŒAdam é‚„ä¿ç•™éå»æ¢¯åº¦çš„æŒ‡æ•¸è¡°æ¸›å¹³å‡å€¼  m t ï¼Œé¡ä¼¼å‹•é‡ (Momentum)ã€‚å¦‚æœ Momentum è¢«è¦–ç‚ºé †è‘—æ–œå¡ä¸‹æ»‘çš„çƒï¼Œè€Œ Adam å‰‡æ˜¯åƒä¸€å€‹å¸¶æœ‰æ‘©æ“¦çš„æ²‰é‡çš„çƒï¼Œå› æ­¤æ›´é©åˆå¾…åœ¨ error face å¹³å¦çš„æœ€å°å€¼å€åŸŸã€‚è¨ˆç®—éå»æ¢¯åº¦å¹³æ–¹çš„è¡°æ¸›å¹³å‡å€¼  m t  å’Œ  v t  åˆ†åˆ¥å¦‚ä¸‹ï¼š \n m t  =  Î² 1 m t-1  + (1 âˆ’  Î² 1 ) Â·g t v t  =  Î² 2 v t-1 \xa0+ (1 âˆ’  Î² 2 ) Â· g 2 t \n m t  å’Œ  v t  åˆ†åˆ¥æ˜¯ç¬¬ä¸€éšçŸ©å¹³å‡ä¼°è¨ˆå€¼å’Œç¬¬äºŒéšçŸ©ç„¡ä¸­å¿ƒæ–¹å·®ä¼°è¨ˆå€¼ï¼Œå› æ­¤æ˜¯æ–¹æ³•çš„åç¨±ã€‚åƒ  m t  å’Œ  v t\xa0 è¢«åˆå§‹åŒ–ç‚ºå‘é‡ oï¼ŒAdam çš„ä½œè€…è§€å¯Ÿåˆ°å®ƒå€‘åå‘é›¶ï¼Œç‰¹åˆ¥æ˜¯åœ¨åˆå§‹ time stepï¼Œå°¤å…¶æ˜¯åœ¨è¡°æ¸›ç‡è¼ƒå°çš„æ™‚å€™ (ä¹Ÿå°±æ˜¯èªª  Î² 1 \xa0 å’Œ  Î² 2 \xa0 è¶¨è¿‘æ–¼ 1) è—‰ç”±è¨ˆç®—æ ¡æ­£åå·®ç¬¬ä¸€çŸ©\xa0 mÌ‚ t\xa0 å’Œç¬¬äºŒçŸ©  vÌ‚ t\xa0 æŠµæ¶ˆåå·®ï¼š \n mÌ‚ t  =  m t \xa0 /(1 âˆ’  Î² t 1 ) vÌ‚ t  =  v t \xa0 /(1 âˆ’  Î² t 2 ) \n ä½¿ç”¨ä»–å€‘å»æ›´æ–°åƒæ•¸ï¼Œå°±åƒ Adadelta å’Œ RMSprop ä¸­æ‰€çœ‹åˆ°çš„é‚£æ¨£ï¼Œé€™å°‡ç”¢ç”Ÿ Adam æ›´æ–°è¦å‰‡ï¼š \n Î¸ t+1  =  Î¸ t  âˆ’ [Î· ( vÌ‚ t\xa0 ) Â½\xa0 + Ïµ]\xa0 mÌ‚ t \xa0 \n Î² 1  é è¨­å€¼å»ºè­°ç‚º 0.9ï¼ŒÎ² 2  é è¨­å€¼å»ºè­°ç‚º 0.999ï¼ŒÏµ é è¨­å€¼å»ºè­°ç‚º  10 âˆ’8 ã€‚æ ¹æ“šç¶“é©—è­‰æ˜ Adam è¡¨ç¾è‰¯å¥½ï¼Œä¸¦ä¸”èˆ‡å…¶ä»–è‡ªé©æ‡‰å­¸ç¿’ç®—æ³•ç›¸æ¯”å…·æœ‰å„ªå‹¢ã€‚ \n AdaMax \n åœ¨ Adam æ›´æ–°è¦å‰‡ä¸­çš„  v t  ä¿‚æ•¸æ˜¯èˆ‡æ¢¯åº¦æˆåæ¯”åœ°ç¸®æ”¾éå»æ¢¯åº¦çš„ç¯„æ•¸ (é€šé  v t-1  é …) å’Œç•¶å‰æ¢¯åº¦  | g t | 2\xa0 ï¼š \n v t \xa0 =  Î² 2 v t-1  + (1 âˆ’  Î² 2 )| g t | 2\xa0 \n æˆ‘å€‘è½‰æ›é€™å€‹æ›´æ–°åˆ° â„“pã€‚æ³¨æ„  Î² 2 \xa0åƒæ•¸åŒ–ç‚º  Î² p 2 ï¼š \n v t \xa0 =  Î² p 2 v t-1  + (1 âˆ’  Î² p 2 ) | g t | p \n å¤§è¦ç¯„ p å€¼ä½¿æ•¸å€¼ä¸Šè®Šå¾—ä¸ç©©å®šï¼Œé€™å°±æ˜¯ç‚ºä»€éº¼ â„“1 å’Œ â„“2 è¦ç¯„åœ¨å¯¦è¸ä¸­æ˜¯æœ€å¸¸è¦‹çš„ã€‚ç„¶è€Œï¼Œâ„“âˆ é€šå¸¸ä¹Ÿè¡¨ç¾å‡ºç©©å®š çš„è¡Œç‚ºã€‚ä½œè€… (Kingma and Ba, 2015) æå‡ºäº† AdaMax ä¸¦è­‰æ˜äº†å’Œ â„“âˆ æ”¶æ–‚åˆ°æ›´ç©©å®šçš„å€¼ã€‚ç‚ºäº†é¿å…èˆ‡ Adam æ··ç”¨ï¼Œæ‰€ä»¥ä½¿ç”¨ u t \xa0 ä¾†è¡¨ç¤ºç„¡çª®ç¯„æ•¸ç´„æŸ  v t \xa0 ï¼š \n u t  =  Î² âˆ 2 v t-1  + (1 âˆ’  Î² âˆ 2 )| g t | âˆ \xa0 = max( Î² 2 \xa0Â·  v t-1 , |gt|) \n æ›¿æ›ç‚º Adam æ›´æ–°å…¬å¼  ( vÌ‚ t\xa0 ) Â½\xa0 + Ïµ\xa0 å’Œ  u t  å¾—å‡º AdaMax æ›´æ–°è¦å‰‡ï¼š \n Î¸ t+1  =  Î¸ t  âˆ’ Î· Â· u t Â· mÌ‚ t \xa0 \n æ³¨æ„ u t  ä¾é æœ€å¤§é‹ç®—ï¼Œä¸å»ºè­° Adam ä¸­çš„  m t \xa0 å’Œ  v t \xa0 åå‘é›¶ï¼Œé€™å°±æ˜¯ç‚ºä»€éº¼ä¸éœ€è¦é‡å°  u t  è¨ˆç®—åå·®ã€‚å¥½çš„é è¨­å€¼ Î· = 0.002ï¼Œ Î² 1\xa0 = 0.9 å’Œ  Î² 2  = 0.999ã€‚ \n Nadam \n Nadam (Nesterov-accelerated Adaptive Moment Estimationï¼ŒNesterov åŠ é€Ÿçš„è‡ªé©æ‡‰çŸ©ä¼°è¨ˆ)ï¼Œçµåˆ Adam å’Œ NAGã€‚ç‚ºäº†å°‡ NAG ç´å…¥ Adamï¼Œéœ€è¦ä¿®æ”¹å‹•é‡é …  m t ã€‚ä½¿ç”¨å…ˆå‰ç¬¦è™Ÿå›é¡§å‹•é‡æ›´æ–°è¦å‰‡ï¼š \n g t  = âˆ‡ Î¸ t\xa0 J( Î¸ t )  m t \xa0 = Î³ m t-1 \xa0  + Î· g t Î¸ t+1  =  Î¸ t\xa0 âˆ’  m t \n Jæ˜¯ç›®æ¨™å‡½æ•¸ï¼ŒÎ³ æ˜¯å‹•é‡è¡°æ¸›é …ï¼ŒÎ· æ˜¯ step size(å­¸ç¿’ç‡)ï¼Œä¸Šé¢çš„ç¬¬ä¸‰å€‹æ–¹ç¨‹å¼æ“´å±•ç‚ºï¼š \n Î¸ t+1  =  Î¸ t  âˆ’ (Î³ m t-1  + Î· g t ) \n å†æ¬¡è­‰æ˜äº†å‹•é‡æ¶‰åŠåœ¨å‰ä¸€å€‹å‹•é‡å‘é‡çš„æ–¹å‘ä¸Šå¾€å‰ä¸€æ­¥å’Œåœ¨ç•¶å‰æ¢¯åº¦çš„æ–¹å‘ä¸Šé‚å‡ºä¸€æ­¥ã€‚NAG ç„¶å¾Œå…è¨±è¨ˆç®—æ¢¯åº¦ä¹‹å‰é€éæ›´æ–°å‹•é‡æ­¥é•·åƒæ•¸ä½¿æ¢¯åº¦æ–¹å‘ä¸ŠåŸ·è¡Œæ›´ç²¾ç¢ºçš„æ­¥é•·ã€‚å› æ­¤ï¼Œæˆ‘å€‘åªéœ€è¦ä¿®æ”¹æ¢¯åº¦  g t  åˆ°é” NAGï¼š \n g t  = âˆ‡ Î¸ t  J( Î¸ t  âˆ’ Î³ m t-1 )  m t \xa0 = Î³ m t-1  + Î· g t Î¸ t+1  =  Î¸ t  âˆ’  m t \xa0 \n Dozat å»ºè­°ä¿®æ”¹ NAGï¼šä¸€æ¬¡ç”¨æ–¼æ›´æ–°æ¢¯åº¦  g t  ç¬¬äºŒæ¬¡æ›´æ–°åƒæ•¸  Î¸ t+1 ï¼Œç›´æ¥æ‡‰ç”¨å…ˆå‰çš„å‹•é‡å‘é‡ä¾†æ›´æ–°ç•¶å‰åƒæ•¸ï¼š \n g t  = âˆ‡ Î¸ t  J( Î¸ t )  m t \xa0 = Î³ m t-1  + Î· g t Î¸ t+1  =  Î¸ t  âˆ’ (Î³ m t \xa0+ Î· g t ) \n ç‚ºäº†å°‡ Nesterov å‹•é‡æ·»åŠ åˆ° Adamï¼Œå¯ä»¥é¡ä¼¼åœ°ç”¨ç•¶å‰å‹•é‡å‘é‡æ›¿æ›ä»¥å‰çš„å‹•é‡å‘é‡ã€‚å›æƒ³ä¸€ä¸‹ Adam æ›´æ–°è¦å‰‡ å¦‚ä¸‹ï¼š \n m t \xa0 =  Î² 1 m t-1  + (1 âˆ’  Î² 1 ) g t mÌ‚ t \xa0  =  m t \xa0/ ( 1 âˆ’  Î² t 1 ) Î¸ t+1  =  Î¸ t  âˆ’ { Î·\xa0/ [ ( vÌ‚ t\xa0 ) Â½  + Ïµ ]}  mÌ‚ t \xa0 \n ç”¨å®šç¾©æ‹“å±•ç¬¬äºŒå€‹æ–¹ç¨‹å¼ï¼š \n Î¸ t+1  =\xa0 Î¸ t \xa0 âˆ’  { Î· \xa0/ [ ( vÌ‚ t\xa0 ) Â½ \xa0 + Ïµ ]} {(  Î² 1 m t-1 ) / (1 âˆ’  Î² t 1 \xa0)  + [(1 âˆ’  Î² 1 ) g t ]/(1 âˆ’\xa0 Î² t 1  )} \n æ³¨æ„ ( Î² 1 m t-1 ) / (1âˆ’ Î² t 1 )åªæ˜¯å‰ä¸€å€‹çš„ time step çš„å‹•é‡å‘é‡çš„åå·®ä¾†æ ¡æ­£è©•ä¼°ã€‚å› æ­¤ï¼Œå¯ä»¥å°‡å…¶æ›¿æ›ç‚º  mÌ‚ t-1 ï¼š \n Î¸ t+1  =  Î¸ t\xa0 âˆ’  { Î· \xa0/ [ ( vÌ‚ t\xa0 ) Â½ \xa0 + Ïµ ]}[ Î² 1 mÌ‚ t-1 \xa0 \xa0+ (1 âˆ’  Î² 1 ) g t \xa0/ (1 âˆ’  Î² t 1  )] \n ç‚ºç°¡åŒ–ï¼Œå› ç‚ºç„¡è«–å¦‚ä½•å°‡åœ¨ä¸‹ä¸€æ­¥ä¸­æ›¿æ›åˆ†æ¯ï¼Œæ‰€ä»¥å¿½ç•¥äº†åˆ†æ¯ 1 âˆ’  Î² t 1 ã€‚è©²æ–¹ç¨‹å¼å†æ¬¡çœ‹èµ·ä¾†å’Œä¸Šé¢æ“´å±•çš„å‹•é‡æ›´ æ–°è¦å‰‡éå¸¸ç›¸ä¼¼ã€‚å¯ä»¥åƒä»¥å‰ä¸€æ¨£æ·»åŠ  Nesterov å‹•é‡ï¼Œæ–¹æ³•æ˜¯ç”¨ç•¶å‰å‹•é‡å‘é‡åå·®æ ¡æ­£å¾Œçš„è©•ä¼°å€¼æ›¿æ›å‰ä¸€æ™‚é–“æ­¥ é•·çš„å‹•é‡å‘é‡åå·®æ ¡æ­£å¾Œçš„è©•ä¼°å€¼ï¼Œé€™ç‚ºæˆ‘å€‘æä¾›äº† Nadam æ›´æ–°è¦å‰‡ï¼š \n Î¸ t+1  =  Î¸ t  âˆ’  \xa0 { Î· \xa0/ [ ( vÌ‚ t\xa0 ) Â½ \xa0 + Ïµ ]} [( Î² 1 mÌ‚ t \xa0 \xa0+ (1 âˆ’  Î² 1 ) g t \xa0/ (1 âˆ’  Î² t 1  )] \n AMSGrad \n Reddi ç­‰ï¼ˆ2018ï¼‰ã€‚æ­£å¼åŒ–äº†é€™å€‹å•é¡Œï¼Œä¸¦æŒ‡å‡ºäº†æ³›åŒ–è¡Œç‚ºä¸ä½³çš„åŸå› ï¼šå°‡éå»æ¢¯åº¦å¹³æ–¹çš„æŒ‡æ•¸ç§»å‹•å¹³å‡å€¼ä½œç‚ºè‡ªé©æ‡‰å­¸ç¿’ç‡æ–¹æ³•ã€‚é›–ç„¶å¼•å…¥æŒ‡æ•¸å¹³å‡å€¼çš„å‹•æ©Ÿå¾ˆå……åˆ†ï¼šæ‡‰é˜²æ­¢å­¸ç¿’ç‡éš¨è‘—è¨“ç·´çš„é€²è¡Œè€Œè®Šå¾—ç„¡é™å°ï¼›ä½†é€™ä¹Ÿæ˜¯ Adagrad ç®—æ³•çš„é—œéµç¼ºé™·ã€‚åœ¨å…¶ä»–æƒ…æ³ä¸‹ï¼ŒçŸ­æœŸè¨˜æ†¶çš„æ¢¯åº¦æˆç‚ºéšœç¤™ã€‚ \n åœ¨ Adam æ”¶æ–‚åˆ°æ¬¡å„ªè§£çš„ç’°å¢ƒä¸­ï¼Œå·²ç¶“è§€å¯Ÿåˆ°ä¸€äº›å°å‹æ‰¹æ¬¡æä¾›äº†è¼ƒå¤§ä¸”ä¿¡æ¯è±å¯Œçš„æ¢¯åº¦ï¼Œä½†æ˜¯é€™äº›å°å‹æ‰¹æ¬¡å¾ˆå°‘å‡ºç¾ï¼Œå› æ­¤æŒ‡æ•¸å¹³å‡æœƒæ¸›å°å…¶å½±éŸ¿ï¼Œå¾è€Œå°è‡´æ”¶æ–‚æ€§è¼ƒå·®ã€‚ä½œè€… (è³‡æ–™ä¾†æºçš„ä½œè€…) æä¾›äº†ä¸€å€‹ç°¡å–®çš„å‡¸å‹å„ªåŒ–å•é¡Œçš„ä¾‹å­ï¼Œå…¶ä¸­ Adam å¯ä»¥è§€å¯Ÿåˆ°ç›¸åŒçš„è¡Œç‚ºã€‚AMSGradç®—æ³•æ˜¯ç‚ºäº†è§£æ±ºæ­¤å•é¡Œï¼Œé€™ç®—æ³•ä½¿ç”¨äº†éå»æ¢¯åº¦å¹³æ–¹çš„æœ€å¤§å€¼  v t\xa0 è€Œä¸æ˜¯æŒ‡æ•¸å¹³å‡å€¼ä¾†æ›´æ–°åƒæ•¸ã€‚ v t\xa0 çš„å®šç¾©èˆ‡å…ˆå‰çš„ Adam ç›¸åŒï¼š \n v t\xa0 =  Î² 2 v t-1\xa0 + (1 âˆ’  Î² 2 ) g 2 t \n è€Œä¸æ˜¯ç›´æ¥ä½¿ç”¨ vt(æˆ–å…¶åå·®æ›´æ­£çš„ç‰ˆæœ¬ vË†tï¼‰ï¼Œå¦‚æœç¾åœ¨ä½¿ç”¨ä»¥å‰å€¼çš„å¤§æ–¼ç¾åœ¨çš„å€¼ï¼š \n vÌ‚ t \xa0= max( vÌ‚ t-1\xa0 ,  v t ) \n é€™æ–¹å¼ AMSGrad ä¸æœƒå¢åŠ æ­¥é•· (step size)ï¼Œå¾è€Œé¿å…äº† Adam é‡åˆ°çš„å•é¡Œã€‚ç‚ºäº†ç°¡åŒ–ï¼ŒAMSGrad å»é™¤äº† Adam çš„å»åå·® (debias) æ­¥é©Ÿã€‚å¯ä»¥çœ‹åˆ°å®Œæ•´çš„ AMSGrad æ›´æ–°ï¼Œæ²’æœ‰ç¶“éåå·®æ ¡æ­£çš„ä¼°è¨ˆï¼š \n m t \xa0 =  Î² 1 m t-1 \xa0 + (1 âˆ’  Î² 1 ) g t v t\xa0 =  Î² 2 v t-1  + (1 âˆ’  Î² 2 ) g 2 t vË†t = max( vÌ‚ t-1\xa0 ,  v t\xa0 )  Î¸ t+1 \xa0= Î¸t âˆ’\xa0 { Î·\xa0/ [ ( vÌ‚ t\xa0 ) Â½ \xa0 + Ïµ ]}   m t \xa0 \n åœ¨å°å‹æ•¸æ“šé›†å’Œ CIFAR-10 ä¸Šï¼Œèˆ‡ Adam ç›¸æ¯”ï¼Œæ€§èƒ½æœ‰æ‰€æé«˜ã€‚ä½†æ˜¯ï¼Œå…¶ä»–å¯¦é©—é¡¯ç¤ºå…¶æ€§èƒ½èˆ‡ Adam ç›¸è¿‘æˆ–æ›´ å·®ã€‚åœ¨å¯¦éš›é‹ç”¨ï¼ŒAMSGrad æ˜¯å¦èƒ½å‹é Adamï¼Œé‚„æœ‰å¾…è§€å¯Ÿã€‚ \n Gradient noise \n å¢åŠ  noise è·Ÿéš¨é«˜æ–¯åˆ†å¸ƒ N(0, Ïƒ 2 t  ) å°æ¯å€‹æ¢¯åº¦æ›´æ–°ï¼š \n g t,i  =  g t,i  + N(0, \xa0Ïƒ 2 t  ) \n æ ¹æ“šæ’å®šæ™‚é–“å°å·®ç•°è¨ˆç®—ï¼š \n \xa0 Ïƒ 2 t  = Î· /(1 + t) Î³ \n æ·»åŠ é€™ç¨® noise å°ä¸è‰¯åˆå§‹åŒ–çš„ç¶²çµ¡å¯ä½¿å…¶å¼·åŒ–ï¼Œä¸¦æœ‰åŠ©æ–¼è¨“ç·´ç‰¹åˆ¥æ·±ä¸”å¾©é›œçš„ç¶²çµ¡ã€‚ä»–å€‘æ‡·ç–‘å¢åŠ çš„å™ªè²ä½¿æ¨¡å‹ æœ‰æ›´å¤šçš„æ©Ÿæœƒé€ƒè„«ä¸¦æ‰¾åˆ°æ–°çš„å±€éƒ¨æ¥µå°å€¼ï¼Œé€™å°æ–¼æ›´æ·±çš„æ¨¡å‹è€Œè¨€æ›´å¸¸è¦‹ã€‚ \n', 'tags': '', 'url': 'Gradient descent optimization algorithms.html'}, {'title': 'ç¨‹å¼', 'text': 'pygame \n è¨“ç·´ç”¨çš„Pygameç¨‹å¼ï¼š \n https://github.com/s40723150/pygame_airhockey \n https://github.com/mdecourse/4072pj1/tree/master/40723150/pygame \n \n', 'tags': '', 'url': 'ç¨‹å¼.html'}, {'title': 'RL-Pong Game', 'text': 'import pygame\nimport random , sys\nfrom pygame.locals import *\nimport numpy as np\nfrom collections import deque\nimport tensorflow as tf  # http://blog.topspeedsnail.com/archives/10116\nimport cv2  # http://blog.topspeedsnail.com/archives/4755\n\ntf.compat.v1.disable_eager_execution()\n\nBLACK = (0, 0, 0)\nWHITE = (255, 255, 255)\n\nSCREEN_SIZE = [320, 400]\nBAR_SIZE = [50, 5]\nBAR2_SIZE = [50,5]\nBALL_SIZE = [15, 15]\n\n# ç¥ç¶“ç¶²çµ¡çš„è¼¸å‡º\nMOVE_STAY = [1, 0, 0]\nMOVE_LEFT = [0, 1, 0]\nMOVE_RIGHT = [0, 0, 1]\n\n\nclass Game(object):\n    def __init__(self):\n        pygame.init()\n        self.clock = pygame.time.Clock()\n        self.screen = pygame.display.set_mode(SCREEN_SIZE)\n        pygame.display.set_caption(\'Simple Game\')\n\n        self.ball_pos_x = SCREEN_SIZE[0] // 2 - BALL_SIZE[0] / 2\n        self.ball_pos_y = SCREEN_SIZE[1] // 2 - BALL_SIZE[1] / 2\n\n        self.ball_dir_x = -1  # -1 = left 1 = right\n        self.ball_dir_y = -1  # -1 = up   1 = down\n        self.ball_pos = pygame.Rect(self.ball_pos_x, self.ball_pos_y, BALL_SIZE[0], BALL_SIZE[1])\n\n        self.bar_pos_x = SCREEN_SIZE[0] // 2 - BAR_SIZE[0] // 2\n        self.bar_pos = pygame.Rect(self.bar_pos_x, SCREEN_SIZE[1] - BAR_SIZE[1]-5, BAR_SIZE[0], BAR_SIZE[1])\n\n        self.bar2_pos_x = SCREEN_SIZE[0] // 2 - BAR_SIZE[0] // 2\n        self.bar2_pos = pygame.Rect(self.bar_pos_x, 5, BAR_SIZE[0], BAR_SIZE[1])\n        self.bar2_speed = 7\n\n\n    # actionæ˜¯MOVE_STAYã€MOVE_LEFTã€MOVE_RIGHT\n    # aiæ§åˆ¶æ£’å­å·¦å³ç§»å‹•ï¼›è¿”å›éŠæˆ²ç•Œé¢åƒç´ æ•¸å’Œå°æ‡‰çš„çå‹µã€‚(åƒç´ ->çå‹µ->å¼·åŒ–æ£’å­å¾€çå‹µé«˜çš„æ–¹å‘ç§»å‹•)\n\n\n    def step(self, action):\n\n        if action == MOVE_LEFT:\n            self.bar_pos_x = self.bar_pos_x - 2\n        elif action == MOVE_RIGHT:\n            self.bar_pos_x = self.bar_pos_x + 2\n        else:\n            pass\n        if self.bar_pos_x < 0:\n            self.bar_pos_x = 0\n        if self.bar_pos_x > SCREEN_SIZE[0] - BAR_SIZE[0]:\n            self.bar_pos_x = SCREEN_SIZE[0] - BAR_SIZE[0]\n\n        if  self.bar2_pos.left < self.ball_pos.x:\n            self.bar2_pos.x += self.bar2_speed\n        if  self.bar2_pos.right > self.ball_pos.x:\n            self.bar2_pos.x -= self.bar2_speed\n\n        if  self.bar2_pos.left <= 0:\n            self.bar2_pos.left = 0\n        if  self.bar2_pos.right >= SCREEN_SIZE[0]:\n            self.bar2_pos.right = SCREEN_SIZE[0]\n\n        self.screen.fill(BLACK)\n        self.bar_pos.left = self.bar_pos_x\n        pygame.draw.rect(self.screen, WHITE, self.bar_pos)\n        pygame.draw.rect(self.screen, WHITE, self.bar2_pos)\n        pygame.draw.rect(self.screen, (255, 0, 0), Rect((5, 5), (310, 390)), 2)\n        pygame.draw.line(self.screen, (255, 0, 0), (7, 195), (313, 195), 2)\n        pygame.draw.circle(self.screen, (255, 0, 0), (160, 195), 50, 2)\n\n        self.ball_pos.left += self.ball_dir_x * 2\n        self.ball_pos.bottom += self.ball_dir_y * 3\n        pygame.draw.rect(self.screen, WHITE, self.ball_pos)\n\n        if self.ball_pos.top <= 0 or self.ball_pos.bottom >= (SCREEN_SIZE[1] - BAR_SIZE[1] + 1):\n            self.ball_dir_y = self.ball_dir_y * -1\n        if self.ball_pos.left <= 0 or self.ball_pos.right >= (SCREEN_SIZE[0]):\n            self.ball_dir_x = self.ball_dir_x * -1\n\n        reward = 0\n        if self.bar_pos.top <= self.ball_pos.bottom and (\n                self.bar_pos.left < self.ball_pos.right and self.bar_pos.right > self.ball_pos.left):\n            reward = 1  # æ“Šä¸­çå‹µ\n        elif self.bar_pos.top <= self.ball_pos.bottom and (\n                self.bar_pos.left > self.ball_pos.right or self.bar_pos.right < self.ball_pos.left):\n            reward = -1  # æ²’æ“Šä¸­æ‡²ç½°\n\n        # ç²å¾—éŠæˆ²ç•Œé¢åƒç´ \n        screen_image = pygame.surfarray.array3d(pygame.display.get_surface())\n        pygame.display.update()\n        # è¿”å›éŠæˆ²ç•Œé¢åƒç´ å’Œå°æ‡‰çš„çå‹µ\n        return reward, screen_image\n\n\n# learning_rate\nLEARNING_RATE = 0.99\n# æ›´æ–°æ¢¯åº¦\nINITIAL_EPSILON = 1.0\nFINAL_EPSILON = 0.05\n# æ¸¬è©¦è§€æ¸¬æ¬¡æ•¸\nEXPLORE = 500000\nOBSERVE = 50000\n# å­˜å„²éå¾€ç¶“é©—å¤§å°\nREPLAY_MEMORY = 500000\n\nBATCH = 100\n\noutput = 3  # è¼¸å‡ºå±¤ç¥ç¶“å…ƒæ•¸ã€‚ä»£è¡¨3ç¨®æ“ä½œ-MOVE_STAY:[1, 0, 0]  MOVE_LEFT:[0, 1, 0]  MOVE_RIGHT:[0, 0, 1]\ninput_image = tf.compat.v1.placeholder("float", [None, 80, 100, 4])  # éŠæˆ²åƒç´ \naction = tf.compat.v1.placeholder("float", [None, output])  # æ“ä½œ\n\n\n# å®šç¾©CNN-å·ç©ç¥ç¶“ç¶²çµ¡ åƒè€ƒ:http://blog.topspeedsnail.com/archives/10451\ndef convolutional_neural_network(input_image):\n    weights = {\'w_conv1\': tf.Variable(tf.zeros([8, 8, 4, 32])),\n               \'w_conv2\': tf.Variable(tf.zeros([4, 4, 32, 64])),\n               \'w_conv3\': tf.Variable(tf.zeros([3, 3, 64, 64])),\n               \'w_fc4\': tf.Variable(tf.zeros([3456, 784])),\n               \'w_out\': tf.Variable(tf.zeros([784, output]))}\n\n    biases = {\'b_conv1\': tf.Variable(tf.zeros([32])),\n              \'b_conv2\': tf.Variable(tf.zeros([64])),\n              \'b_conv3\': tf.Variable(tf.zeros([64])),\n              \'b_fc4\': tf.Variable(tf.zeros([784])),\n              \'b_out\': tf.Variable(tf.zeros([output]))}\n\n    conv1 = tf.nn.relu(\n        tf.nn.conv2d(input_image, weights[\'w_conv1\'], strides=[1, 4, 4, 1], padding="VALID") + biases[\'b_conv1\'])\n    conv2 = tf.nn.relu(\n        tf.nn.conv2d(conv1, weights[\'w_conv2\'], strides=[1, 2, 2, 1], padding="VALID") + biases[\'b_conv2\'])\n    conv3 = tf.nn.relu(\n        tf.nn.conv2d(conv2, weights[\'w_conv3\'], strides=[1, 1, 1, 1], padding="VALID") + biases[\'b_conv3\'])\n    conv3_flat = tf.reshape(conv3, [-1, 3456])\n    fc4 = tf.nn.relu(tf.matmul(conv3_flat, weights[\'w_fc4\']) + biases[\'b_fc4\'])\n\n    output_layer = tf.matmul(fc4, weights[\'w_out\']) + biases[\'b_out\']\n    return output_layer\n\n\n# æ·±åº¦å¼·åŒ–å­¸ç¿’å…¥é–€: https://www.nervanasys.com/demystifying-deep-reinforcement-learning/\n# è¨“ç·´ç¥ç¶“ç¶²çµ¡\ndef train_neural_network(input_image):\n    predict_action = convolutional_neural_network(input_image)\n\n    argmax = tf.compat.v1.placeholder("float", [None, output])\n    gt = tf.compat.v1.placeholder("float", [None])\n\n    action = tf.reduce_sum(tf.multiply(predict_action, argmax), axis=1)\n    cost = tf.reduce_mean(tf.square(action - gt))\n    optimizer = tf.compat.v1.train.AdamOptimizer(1e-6).minimize(cost)\n\n    game = Game()\n    D = deque()\n\n    _, image = game.step(MOVE_STAY)\n    # è½‰æ›çˆ²ç°åº¦å€¼\n    image = cv2.cvtColor(cv2.resize(image, (100, 80)), cv2.COLOR_BGR2GRAY)\n    # è½‰æ›çˆ²äºŒå€¼\n    ret, image = cv2.threshold(image, 1, 255, cv2.THRESH_BINARY)\n    input_image_data = np.stack((image, image, image, image), axis=2)\n\n    with tf.compat.v1.Session() as sess:\n        sess.run(tf.compat.v1.initialize_all_variables())\n\n        saver = tf.compat.v1.train.Saver()\n\n        n = 0\n        epsilon = INITIAL_EPSILON\n        while True:\n            for event in pygame.event.get():\n             if event.type == pygame.QUIT:\n                 pygame.quit()\n                 sys.exit()\n\n\n            action_t = predict_action.eval(feed_dict={input_image: [input_image_data]})[0]\n\n            argmax_t = np.zeros([output], dtype=np.int)\n            if (random.random() <= INITIAL_EPSILON):\n                maxIndex = random.randrange(output)\n            else:\n                maxIndex = np.argmax(action_t)\n            argmax_t[maxIndex] = 1\n            if epsilon > FINAL_EPSILON:\n                epsilon -= (INITIAL_EPSILON - FINAL_EPSILON) / EXPLORE\n\n            # for event in pygame.event.get():  macOSéœ€è¦äº‹ä»¶å¾ªç’°ï¼Œå¦å‰‡ç™½å±\n            #\tif event.type == QUIT:\n            #\t\tpygame.quit()\n            #\t\tsys.exit()\n            reward, image = game.step(list(argmax_t))\n\n            image = cv2.cvtColor(cv2.resize(image, (100, 80)), cv2.COLOR_BGR2GRAY)\n            ret, image = cv2.threshold(image, 1, 255, cv2.THRESH_BINARY)\n            image = np.reshape(image, (80, 100, 1))\n            input_image_data1 = np.append(image, input_image_data[:, :, 0:3], axis=2)\n\n            D.append((input_image_data, argmax_t, reward, input_image_data1))\n\n            if len(D) > REPLAY_MEMORY:\n                D.popleft()\n\n            if n > OBSERVE:\n                minibatch = random.sample(D, BATCH)\n                input_image_data_batch = [d[0] for d in minibatch]\n                argmax_batch = [d[1] for d in minibatch]\n                reward_batch = [d[2] for d in minibatch]\n                input_image_data1_batch = [d[3] for d in minibatch]\n\n                gt_batch = []\n\n                out_batch = predict_action.eval(feed_dict={input_image: input_image_data1_batch})\n\n                for i in range(0, len(minibatch)):\n                    gt_batch.append(reward_batch[i] + LEARNING_RATE * np.max(out_batch[i]))\n\n                optimizer.run(feed_dict={gt: gt_batch, argmax: argmax_batch, input_image: input_image_data_batch})\n\n            input_image_data = input_image_data1\n            n = n + 1\n\n            if n % 10000 == 0:\n                saver.save(sess, \'game.cpk\', global_step=n)  # ä¿å­˜æ¨¡å‹\n\n            print(n, "epsilon:", epsilon, " ", "action:", maxIndex, " ", "reward:", reward)\n\n\ntrain_neural_network(input_image) \n \n', 'tags': '', 'url': 'RL-Pong Game.html'}, {'title': 'Ref', 'text': '', 'tags': '', 'url': 'Ref.html'}, {'title': 'Flutter', 'text': 'Flutter èˆ‡ Android sdk ç‰ˆæœ¬å·®ç•°å•é¡Œè§£æ±º:  https://stackoverflow.com/questions/60440509/android-command-line-tools-sdkmanager-always-shows-warning-could-not-create-se/61613986#61613986 \n Flask èˆ‡ ML ç³»çµ±åœ¨å¾Œç«¯, Flutter ä½œç‚ºå‰ç«¯ \n https://medium.com/analytics-vidhya/deploy-ml-models-using-flask-as-rest-api-and-access-via-flutter-app-7ce63d5c1f3b \n https://medium.com/@pyzimos/flutter-chatbot-with-python-flask-backend-heroku-deployment-706baafbb8f1 \n https://github.com/SHARONZACHARIA/Deploy-ML-model \n https://github.com/tonynguyen72/Flask_API_Flutter \n https://github.com/mohammedhashim44/Flutter-Flask-Login \n', 'tags': '', 'url': 'Flutter.html'}, {'title': 'CMSiMDE', 'text': 'https://websitesetup.org/bootstrap-tutorial-for-beginners/ \n https://colorlib.com/wp/themes/travelify/ \xa0 \n https://github.com/puikinsh/travelify \n \n', 'tags': '', 'url': 'CMSiMDE.html'}]};