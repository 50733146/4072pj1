<!DOCTYPE html><html>
        <head>
        <title>Reinforcement Learning in Mechatroinc Systems</title>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
        <link href="https://fonts.googleapis.com/css?family=Quicksand:300,400,500,700,900" rel="stylesheet">
        <link rel="stylesheet" href="./../cmsimde/static/chimper/fonts/icomoon/style.css">
        <link rel="stylesheet" href="./../cmsimde/static/chimper/css/bootstrap.min.css">
        <link rel="stylesheet" href="./../cmsimde/static/chimper/css/magnific-popup.css">
        <link rel="stylesheet" href="./../cmsimde/static/chimper/css/jquery-ui.css">
        <link rel="stylesheet" href="./../cmsimde/static/chimper/css/owl.carousel.min.css">
        <link rel="stylesheet" href="./../cmsimde/static/chimper/css/owl.theme.default.min.css">
        <link rel="stylesheet" href="./../cmsimde/static/chimper/css/bootstrap-datepicker.css">
        <link rel="stylesheet" href="./../cmsimde/static/chimper/fonts/flaticon/font/flaticon.css">
        <link rel="stylesheet" href="./../cmsimde/static/chimper/css/aos.css">
        <link rel="stylesheet" href="./../cmsimde/static/chimper/css/style.css">
        <link rel="shortcut icon" href="./../cmsimde/static/favicons.png">
        
        <style type='text/css'>
            .site-section {
            background-color: #FFFF;
            padding: 40px 40px;
            }
            body > div > div.dropdown.open {
                display: block;
            }
        </style>
    
        <!-- <script src="./../cmsimde/static/jquery.js"></script> -->
        <!-- <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script> -->
        <script src="../cmsimde/static/chimper/js/jquery-3.3.1.min.js"></script>
        <link rel="stylesheet" href="./../cmsimde/static/tipuesearch/css/normalize.min.css">
        <script src="./../cmsimde/static/tipuesearch/tipuesearch_set.js"></script>
        <script src="tipuesearch_content.js"></script>
        <link rel="stylesheet" href="./../cmsimde/static/tipuesearch/css/tipuesearch.css">
        <script src="./../cmsimde/static/tipuesearch/tipuesearch.js"></script>
        <script>
            /* original tipuesearch
            $(document).ready(function() {
                 $('#tipue_search_input').tipuesearch();
            });
            */
            // customed doSearch
            function doSearch() {
                $('#tipue_search_input').tipuesearch({
                    newWindow: true, 
                    minimumLength: 2,
                    wholeWords: false, // for search 中文
                });
            }
            $(document).ready(doSearch);
        </script>
        
<script type="text/javascript" src="./../cmsimde/static/syntaxhighlighter/shCore.js"></script>
<script type="text/javascript" src="./../cmsimde/static/syntaxhighlighter/shBrushBash.js"></script>
<script type="text/javascript" src="./../cmsimde/static/syntaxhighlighter/shBrushDiff.js"></script>
<script type="text/javascript" src="./../cmsimde/static/syntaxhighlighter/shBrushJScript.js"></script>
<script type="text/javascript" src="./../cmsimde/static/syntaxhighlighter/shBrushJava.js"></script>
<script type="text/javascript" src="./../cmsimde/static/syntaxhighlighter/shBrushPython.js"></script>
<script type="text/javascript" src="./../cmsimde/static/syntaxhighlighter/shBrushSql.js"></script>
<script type="text/javascript" src="./../cmsimde/static/syntaxhighlighter/shBrushHaxe.js"></script>
<script type="text/javascript" src="./../cmsimde/static/syntaxhighlighter/shBrushXml.js"></script>
<script type="text/javascript" src="./../cmsimde/static/syntaxhighlighter/shBrushPhp.js"></script>
<script type="text/javascript" src="./../cmsimde/static/syntaxhighlighter/shBrushLua.js"></script>
<script type="text/javascript" src="./../cmsimde/static/syntaxhighlighter/shBrushCpp.js"></script>
<script type="text/javascript" src="./../cmsimde/static/syntaxhighlighter/shBrushCss.js"></script>
<script type="text/javascript" src="./../cmsimde/static/syntaxhighlighter/shBrushCSharp.js"></script>
<script type="text/javascript" src="./../cmsimde/static/syntaxhighlighter/shBrushDart.js"></script>
<link type="text/css" rel="stylesheet" href="./../cmsimde/static/syntaxhighlighter/css/shCoreDefault.css"/>
<script type="text/javascript">SyntaxHighlighter.all();</script>
<!-- 暫時不用
<script src="./../cmsimde/static/fengari-web.js"></script>
<script type="text/javascript" src="./../cmsimde/static/Cango-13v08-min.js"></script>
<script type="text/javascript" src="./../cmsimde/static/CangoAxes-4v01-min.js"></script>
<script type="text/javascript" src="./../cmsimde/static/gearUtils-05.js"></script>
-->
<!-- for Brython 暫時不用
<script src="https://scrum-3.github.io/web/brython/brython.js"></script>
<script src="https://scrum-3.github.io/web/brython/brython_stdlib.js"></script>
-->
<style>
img.add_border {
    border: 3px solid blue;
}
</style>

</head>
<body>
<div class='container'><nav>
        
    <div class="site-wrap">

    <div class="site-mobile-menu">
      <div class="site-mobile-menu-header">
        <div class="site-mobile-menu-close mt-3">
          <span class="icon-close2 js-menu-toggle"></span>
        </div>
      </div>
      <div class="site-mobile-menu-body"></div>
    </div>
    
            <header class="site-navbar py-4 bg-white" role="banner">
              <div class="container-fluid">
                <div class="row align-items-center">
                <h1>強化學習在機電系統設計與控制中之應用 </h1>
                <div class="pl-4">
                    <form>
                    <input type="text" placeholder="Search" name="q" id="tipue_search_input" pattern=".{2,}" title="At least 2 characters" required>
                    </form>
                </div>
                  <!-- <div class="col-11 col-xl-2">
                    <h1 class="mb-0 site-logo"><a href="index.html" class="text-black h2 mb-0">強化學習在機電系統設計與控制中之應用 </a></h1> 
                  </div>
                  -->
                  <div class="col-12 col-md-10 d-none d-xl-block">
                    <nav class="site-navigation position-relative text-right" role="navigation">
    <ul class='site-menu js-clone-nav mr-auto d-none d-lg-block'>
                        <li class="active has-children"><a href="index.html">Home</a>
                        <ul class="dropdown">
                            <li><a href="sitemap.html">Site Map</a></li>
                            <li><a href="./../reveal/index.html">reveal</a></li>
                            <li><a href="./../blog/index.html">blog</a></li>
                        </ul>
                      </li>
                     <li class='has-children'><a href='About.html'>About</a><ul class='dropdown'><li><a href='專題定位.html'>專題定位</a><li><a href='LaTeX.html'>LaTeX</a><li><a href='參考資料.html'>參考資料</a><li><a href='研究生考試.html'>研究生考試</a></li></ul><li class='has-children'><a href='動態網站.html'>動態網站</a><ul class='dropdown'><li><a href='數位簽章.html'>數位簽章</a><li><a href='機電控制.html'>機電控制</a><li><a href='iRobot Create.html'>iRobot Create</a></li></ul><li class='has-children'><a href='深度學習.html'>深度學習</a><ul class='dropdown'><li><a href='電腦.html'>電腦</a><li><a href='Flask.html'>Flask</a></li></ul><li class='has-children'><a href='強化學習.html'>強化學習</a><ul class='dropdown'><li><a href='2021.html'>2021</a><li><a href='Reference.html'>Reference</a><li class='has-children'><a href='類神經網路學習.html'>類神經網路學習</a><ul class='dropdown'><li><a href='neural_network_in_python.pdf.html'>neural_network_in_python.pdf</a></li></li></ul></ul><li class='has-children'><a href='優化器.html'>優化器</a><ul class='dropdown'><li><a href='Gradient Descent Optimizer.html'>Gradient Descent Optimizer</a><li><a href='Stochastic gradient descent.html'>Stochastic gradient descent</a><li><a href='Gradient descent optimization algorithms.html'>Gradient descent optimization algorithms</a></li></ul><li class='has-children'><a href='程式.html'>程式</a><ul class='dropdown'><li><a href='RL-Pong Game.html'>RL-Pong Game</a></li></ul><li class='has-children'><a href='Ref.html'>Ref</a><ul class='dropdown'><li><a href='Flutter.html'>Flutter</a><li><a href='CMSiMDE.html'>CMSiMDE</a></li>
                      </ul>
                </nav>
              </div>
              <div class="d-inline-block d-xl-none ml-md-0 mr-auto py-3" style="position: relative; top: 3px;"><a href="#" class="site-menu-toggle js-menu-toggle text-black"><span class="icon-menu h3"></span></a></div>
              </div>

            </div>
          </div>
          
        </header>
    <div id="tipue_search_content">類神經網路學習 << <a href='類神經網路學習.html'>Previous</a> <a href='優化器.html'>Next</a> >> 優化器<br /><h1>neural_network_in_python.pdf</h1>
<p>說明前三章的程式碼</p>
<h4>2LayerNeuralNetwork.py</h4>
<p><strong>origin codes:</strong></p>
<pre class="brush:py;auto-links:false;toolbar:false" contenteditable="false"># 2 Layer Neural Network in NumPy
import numpy as np
# X = input of our 3 input XOR gate
# set up the inputs of the neural network (right from the table)
X = np.array(([0,0,0],[0,0,1],[0,1,0], [0,1,1],[1,0,0],[1,0,1],[1,1,0],[1,1,1]), dtype=float)
# y = our output of our neural network
y = np.array(([1], [0], [0], [0], [0], [0], [0], [1]), dtype=float)
# what value we want to predict
xPredicted = np.array(([0,0,1]), dtype=float)
X = X/np.amax(X, axis=0) # maximum of X input array
# maximum of xPredicted (our input data for the prediction)
xPredicted = xPredicted/np.amax(xPredicted, axis=0)
# set up our Loss file for graphing
lossFile = open("SumSquaredLossList.csv", "w")
class Neural_Network (object):
    def __init__(self):
        #parameters
        self.inputLayerSize = 3 # X1,X2,X3
        self.outputLayerSize = 1 # Y1
        self.hiddenLayerSize = 4 # Size of the hidden layer
        # build weights of each layer
        # set to random values
        # look at the interconnection diagram to make sense of this
        # 3x4 matrix for input to hidden
        self.W1 = np.random.randn(self.inputLayerSize, self.hiddenLayerSize)
        # 4x1 matrix for hidden layer to output
        self.W2 = np.random.randn(self.hiddenLayerSize, self.outputLayerSize)
    def feedForward(self, X):
        # feedForward propagation through our network
        # dot product of X (input) and first set of 3x4 weights
        self.z = np.dot(X, self.W1)
        # the activationSigmoid activation function - neural magic
        self.z2 = self.activationSigmoid(self.z)
        # dot product of hidden layer (z2) and second set of 4x1 weights
        self.z3 = np.dot(self.z2, self.W2)
        # final activation function - more neural magic
        o = self.activationSigmoid(self.z3)
        return o
     def backwardPropagate(self, X, y, o):
        # backward propagate through the network
        # calculate the error in output
        self.o_error = y - o
        # apply derivative of activationSigmoid to error
        self.o_delta = self.o_error*self.activationSigmoidPrime(o)
        # z2 error: how much our hidden layer weights contributed to output
        # error
        self.z2_error = self.o_delta.dot(self.W2.T)
        # applying derivative of activationSigmoid to z2 error
        self.z2_delta = self.z2_error*self.activationSigmoidPrime(self.z2)
        # adjusting first set (inputLayer --&gt; hiddenLayer) weights
        self.W1 += X.T.dot(self.z2_delta)
        # adjusting second set (hiddenLayer --&gt; outputLayer) weights
        self.W2 += self.z2.T.dot(self.o_delta)
    def trainNetwork(self, X, y):
        # feed forward the loop
        o = self.feedForward(X)
        # and then back propagate the values (feedback)
        self.backwardPropagate(X, y, o)
    def activationSigmoid(self, s):
        # activation function
        # simple activationSigmoid curve as in the book
        return 1/(1+np.exp(-s))
    def activationSigmoidPrime(self, s):
        # First derivative of activationSigmoid
        # calculus time!
        return s * (1 - s)
    def saveSumSquaredLossList(self,i,error):
        lossFile.write(str(i)+","+str(error.tolist())+'\n')
    def saveWeights(self):
        # save this in order to reproduce our cool network
        np.savetxt("weightsLayer1.txt", self.W1, fmt="%s")
        np.savetxt("weightsLayer2.txt", self.W2, fmt="%s")
    def predictOutput(self):
        print ("Predicted XOR output data based on trained weights: ")
        print ("Expected (X1-X3): \n" + str(xPredicted))
        print ("Output (Y1): \n" + str(self.feedForward(xPredicted)))

myNeuralNetwork = Neural_Network()
trainingEpochs = 1000
#trainingEpochs = 100000

for i in range(trainingEpochs): # train myNeuralNetwork 1,000 times
    print ("Epoch # " + str(i) + "\n")
    print ("Network Input : \n" + str(X))
    print ("Expected Output of XOR Gate Neural Network: \n" + str(y))
    print ("Actual Output from XOR Gate Neural Network: \n" + \
    str(myNeuralNetwork.feedForward(X)))
    # mean sum squared loss
    Loss = np.mean(np.square(y - myNeuralNetwork.feedForward(X)))
    myNeuralNetwork.saveSumSquaredLossList(i,Loss)
    print ("Sum Squared Loss: \n" + str(Loss))
    print ("\n")
    myNeuralNetwork.trainNetwork(X, y)

myNeuralNetwork.saveWeights()
myNeuralNetwork.predictOutput()p</pre>
<p><strong>定義input(X)和output(Y)</strong></p>
<pre class="brush:py;auto-links:false;toolbar:false" contenteditable="false">X = np.array(([0,0,0],[0,0,1],[0,1,0], [0,1,1],[1,0,0],[1,0,1],[1,1,0],[1,1,1]), dtype=float)
y = np.array(([1], [0], [0], [0], [0], [0], [0], [1]), dtype=float)</pre>
<p><strong>設定神經元及權重</strong></p>
<pre class="brush:py;auto-links:false;toolbar:false" contenteditable="false">python
 def __init__(self):
        # X1,X2,X3(自訂義input的神經元數量)
        self.inputLayerSize = 3
        # Y1(自訂義output的神經元數量)   
        self.outputLayerSize = 1
        # Size of the hidden layer(自訂義hiddenLayer的神經元數量)          
        self.hiddenLayerSize = 4 
        
        # 設定第一層權重為隨機數值，input---&gt;hidden
        self.W1 = np.random.randn(self.inputLayerSize, self.hiddenLayerSize)
        
        # 設定第二層權重為隨機數值，hidden---&gt;output
        self.W2 = np.random.randn(self.hiddenLayerSize, self.outputLayerSize)
</pre>
<p><strong>feedForward(前饋)</strong></p>
<p><img alt="" height="361" src="./../images/NN_layers.png" width="500"/></p>
<p><a href="https://medium.com/ai-academy-taiwan/back-propagation-3946e8ed8c55">(圖片來源)</a></p>
<pre class="brush:py;auto-links:false;toolbar:false" contenteditable="false"> def feedForward(self, X):
        # 第一層的動態方程式(activation function)輸入(z)
        # z(activation function) = 第一層所有神經元的 input * weights 總和輸入到第二層的其中一個神經元
        self.z = np.dot(X, self.W1)

        # 第一層的動態方程式(activation function)輸出(a)
        # z2(a) = 動態方程式(activation function)用Sigmoid function算法
        self.z2 = self.activationSigmoid(self.z)

        # 第二層的動態方程式(activation function)輸入(z)
        # z3(activation function) = 第二層所有神經元的 input * weights 總和輸入到輸出層的(其中一個)神經元
        self.z3 = np.dot(self.z2, self.W2)

        # 第二層的動態方程式(activation function)輸出(a)
        # o(a) = 動態方程式(activation function)用Sigmoid function算法
        o = self.activationSigmoid(self.z3)

        # 回傳出前饋結果
        return o</pre>
<p><strong>backwardPropagate(反向傳播)</strong></p>
<pre class="brush:py;auto-links:false;toolbar:false" contenteditable="false">def backwardPropagate(self, X, y, o):
        # 計算輸出誤差
        self.o_error = y - o

        # 將Sigmoid function算法用在輸出誤差(錯誤、error)
        self.o_delta = self.o_error*self.activationSigmoidPrime(o)

        # 隱藏層的輸出誤差*權重
        self.z2_error = self.o_delta.dot(self.W2.T)

        # 將Sigmoid function算法用在隱藏層輸出誤差(錯誤、error)
        self.z2_delta = self.z2_error*self.activationSigmoidPrime(self.z2)

        # 糾正第一層權重數值，input---&gt;hidden
        self.W1 += X.T.dot(self.z2_delta)
        # 糾正第二層權重數值，hidden---&gt;output
        self.W2 += self.z2.T.dot(self.o_delta)</pre>
<p><strong>trainNetwork(訓練流程)</strong></p>
<pre class="brush:py;auto-links:false;toolbar:false" contenteditable="false">def trainNetwork(self, X, y):
        # 前饋循環 
        o = self.feedForward(X)
        # 反向傳播值
        self.backwardPropagate(X, y, o)</pre>
<p><strong>activationSigmoid</strong></p>
<pre class="brush:py;auto-links:false;toolbar:false" contenteditable="false">def activationSigmoid(self, s):
        # activation function
        # 使用Sigmoid function算法(S-curve)
        return 1/(1+np.exp(-s))</pre>
<p><img caption="false" height="100" src="./../images/Sigmoid_Function.jpg" width="222"/></p>
<p><strong>activationSigmoidPrime</strong></p>
<pre class="brush:py;auto-links:false;toolbar:false" contenteditable="false">def activationSigmoidPrime(self, s):
        # First derivative of activationSigmoid
        # calculus time!
        return s * (1 - s)</pre>
<p><strong><img caption="false" height="100" src="./../images/Sigmoid_Function.jpg" width="222"/></strong></p>
<p><strong>saveSumSquaredLossList(儲存損失函數值)</strong></p>
<pre class="brush:py;auto-links:false;toolbar:false" contenteditable="false"> def saveSumSquaredLossList(self,i,error):
        lossFile.write(str(i)+","+str(error.tolist())+'\n')</pre>
<p><strong>saveWeights(儲存權重值)</strong></p>
<pre class="brush:py;auto-links:false;toolbar:false" contenteditable="false"> def saveWeights(self):
        np.savetxt("weightsLayer1.txt", self.W1, fmt="%s")
        np.savetxt("weightsLayer2.txt", self.W2, fmt="%s")</pre>
<p><strong>predictOutput(結果輸出)</strong></p>
<pre class="brush:py;auto-links:false;toolbar:false" contenteditable="false">def predictOutput(self):
        print ("Predicted XOR output data based on trained weights: ")
        print ("Expected (X1-X3): \n" + str(xPredicted))
        print ("Output (Y1): \n" + str(self.feedForward(xPredicted)))</pre>
<p><strong>Epochs(疊代次數，feedForward+backprogation運算完算一次疊代)</strong></p>
<pre class="brush:html;auto-links:false;toolbar:false" contenteditable="false"># 訓練疊代次數
trainingEpochs = 1000</pre>
<h4>TensorFlowKeras.py</h4>
<p><strong>origin codes:</strong></p>
<pre class="brush:py;auto-links:false;toolbar:false" contenteditable="false">import tensorflow as tf
from tensorflow.keras import layers
from tensorflow.keras.layers import Activation, Dense
import numpy as np
# X = input of our 3 input XOR gate
# set up the inputs of the neural network (right from the table)
X = np.array(([0,0,0], [0,0,1], [0,1,0], [0,1,1], [1,0,0], [1,0,1], [1,1,0], [1,1,1]), dtype=float)
# y = our output of our neural network
y = np.array(([1], [0], [0], [0], [0], [0], [0], [1]), dtype=float)
model = tf.keras.Sequential()
model.add(Dense(4, input_dim=3, activation='relu', use_bias=True))
#model.add(Dense(4, activation='relu', use_bias=True))
model.add(Dense(1, activation='sigmoid', use_bias=True))
model.compile(loss='mean_squared_error', optimizer='adam', metrics=['binary_accuracy'])
print (model.get_weights())
history = model.fit(X, y, epochs=2000, validation_data = (X, y))
model.summary()
# printing out to file
loss_history = history.history["loss"]
numpy_loss_history = np.array(loss_history)
np.savetxt("loss_history.txt", numpy_loss_history, delimiter="\n")
binary_accuracy_history = history.history["binary_accuracy"]
numpy_binary_accuracy = np.array(binary_accuracy_history)
np.savetxt("binary_accuracy.txt", numpy_binary_accuracy, delimiter="\n")
print(np.mean(history.history["binary_accuracy"]))
result = model.predict(X ).round()
print (result)</pre>
<p><strong>定義input(X)和output(Y)</strong></p>
<pre class="brush:html;auto-links:false;toolbar:false" contenteditable="false">X = np.array(([0,0,0],[0,0,1],[0,1,0], [0,1,1],[1,0,0],[1,0,1],[1,1,0],[1,1,1]), dtype=float)
# X是三輸入XOR邏輯閘
y = np.array(([1], [0], [0], [0], [0], [0], [0], [1]), dtype=float)
# Y是輸出神經網路</pre>
<p><strong>setting</strong></p>
<pre class="brush:py;auto-links:false;toolbar:false" contenteditable="false">model = tf.keras.Sequential() #sequential定義modle為層狀結構
model.add(Dense(4, input_dim=3, activation='relu', use_bias=True))
'''
add是從最上層開始加入，Dense是密集連線的神經網路，
4:輸出空間(神經元，輸出到4個神經元)，input_dim:輸入神經元個數，activation:定義啟動函數使用的類型，use_bias:使用偏差，True開啟。從inputlayer輸出到hiddenlayer的設定
'''

#model.add(Dense(4, activation='relu', use_bias=True))
model.add(Dense(1, activation='sigmoid', use_bias=True))
# 從hiddenlayer輸出到outputlayer的設定

model.compile(loss='mean_squared_error', optimizer='adam', metrics=['binary_accuracy'])
'''
配置訓練模組，loss funsion:用maen squared error(差平方誤差)，optimizer:優化器，
用adam function，metrics：計算準確率，用binary_accuracy
'''

print (model.get_weights())#印出回傳的正確權重
history = model.fit(X, y, epochs=2000, validation_data = (X, y))
'''
訓練模型給予固定epochs，迭代收集到的資料，validation_data：評估準確率(不包含在訓練裡面)
'''
</pre>
<p><strong>ReLU</strong><br/>max_value：輸出後最大值上限<br/>negative_slope：負斜率係數<br/>threshold：可通過的數值界線</p>
<p>[<a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/ReLU">tf.keras.layers.ReLU | TensorFlow Core v2.4.0</a>]</p>
<p><strong>mean squared error(MSE)</strong></p>
<p><img caption="false" height="500" src="./../images/MSE.png" width="508"/></p>
<p>(<a href="https://www.freecodecamp.org/news/machine-learning-mean-squared-error-regression-line-c7dde9a26b93/">圖片來源</a>)</p>
<p><img alt="" height="100" src="./../images/MSE_Function.jpg" width="388"/></p>
<p>[<a href="https://www.khanacademy.org/math/statistics-probability/describing-relationships-quantitative-data/more-on-regression/v/proof-part-1-minimizing-squared-error-to-regression-line">Proof (part 1) minimizing squared error to regression line (video) | Khan Academy</a>]</p>
<p>[<a href="https://www.listendata.com/2018/03/regression-analysis.html">15 Types of Regression in Data Science</a>]</p>
<p>[<a href="https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#compile">tf.keras.Sequential | TensorFlow Core v2.4.0</a>]</p>
<p>[<a href="https://www.freecodecamp.org/news/machine-learning-mean-squared-error-regression-line-c7dde9a26b93/">Machine learning: an introduction to mean squared error and regression lines</a>]</p>
<p>[<a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense">tf.keras.layers.Dense | TensorFlow Core v2.4.0</a>]</p>
<p>[<a href="https://www.tensorflow.org/api_docs/python/tf/keras/losses">Module: tf.keras.losses | TensorFlow Core v2.4.0</a>]</p>
<p>[<a href="https://www.tensorflow.org/api_docs/python/tf/keras/optimizers">Module: tf.keras.optimizers | TensorFlow Core v2.4.0</a>]</p>
<p>[<a href="https://www.tensorflow.org/api_docs/python/tf/keras/metrics">Module: tf.keras.metrics | TensorFlow Core v2.4.0</a>]</p>
<p>[<a href="https://www.tensorflow.org/hub/api_docs/python/hub/KerasLayer?hl=fr#get_weights">hub.KerasLayer | TensorFlow Hub</a>]</p>
<p>[<a href="https://www.tensorflow.org/api_docs/python/tf/summary">Module: tf.summary | TensorFlow Core v2.4.0</a>]</p>
<p>[<a href="https://keras.io/api/layers/activations/">Keras documentation: Layer activation functions</a>]</p>
<p><strong>history</strong></p>
<pre class="brush:py;auto-links:false;toolbar:false" contenteditable="false">model.summary()
# 摘要資料使用在分析和可視化，為了確認訓練架構在符合預期方向

loss_history = history.history["loss"]
#回傳紀錄事件(loss)到history物件，取得fit方法的模組回傳值
numpy_loss_history = np.array(loss_history)
#將loss_history數值存成array
np.savetxt("loss_history.txt", numpy_loss_history, delimiter="\n")
#將numpy_loss_history存成loss_history.txt，並將每筆資料用換行符號隔開

binary_accuracy_history = history.history["binary_accuracy"]
#回傳紀錄事件(binary_accuracy)到history物件
numpy_binary_accuracy = np.array(binary_accuracy_history)
#將binary_accuracy_history數值存成array
np.savetxt("binary_accuracy.txt", numpy_binary_accuracy, delimiter="\n")
#將numpy_binary_accuracy存成binary_accuracy.txt，並將每筆資料用換行符號隔開
</pre>
<p><br/><strong>result</strong></p>
<pre class="brush:py;auto-links:false;toolbar:false" contenteditable="false">print(np.mean(history.history["binary_accuracy"]))
#印出平均binary_accuracy記錄到的數值
result = model.predict(X ).round()
#替輸入樣本產生輸出預測
print (result)
#印出結果</pre>
<p><a href="./../downloads/整理資料/neural_network_in_python_summary.pdf">整理好的PDF檔</a><br/><br/></p><br />類神經網路學習 << <a href='類神經網路學習.html'>Previous</a> <a href='優化器.html'>Next</a> >> 優化器</div>
        
    <!-- footer -->
      <div class="container">
        <div class="row pt-3 mx-auto">
            <p>
            <!-- Link back to Colorlib can't be removed. Template is licensed under CC BY 3.0. -->
            Copyright &copy;<script>document.write(new Date().getFullYear());</script> All rights reserved | This template is made with <i class="icon-heart" aria-hidden="true"></i> by <a href="https://colorlib.com" target="_blank" >Colorlib</a>
            <!-- Link back to Colorlib can't be removed. Template is licensed under CC BY 3.0. -->
            </p>
        </div>
      </div>
    <!-- for footer -->
    
        </div> <!-- for site wrap -->
            <!-- <script src="../cmsimde/static/chimper/js/jquery-3.3.1.min.js"></script> -->
            <script src="../cmsimde/static/chimper/js/jquery-migrate-3.0.1.min.js"></script>
            <script src="../cmsimde/static/chimper/js/jquery-ui.js"></script>
            <script src="../cmsimde/static/chimper/js/popper.min.js"></script>
            <script src="../cmsimde/static/chimper/js/bootstrap.min.js"></script>
            <script src="../cmsimde/static/chimper/js/owl.carousel.min.js"></script>
            <script src="../cmsimde/static/chimper/js/jquery.stellar.min.js"></script>
            <script src="../cmsimde/static/chimper/js/jquery.countdown.min.js"></script>
            <script src="../cmsimde/static/chimper/js/jquery.magnific-popup.min.js"></script>
            <script src="../cmsimde/static/chimper/js/bootstrap-datepicker.min.js"></script>
            <script src="../cmsimde/static/chimper/js/aos.js"></script>
            <!--
            <script src="../cmsimde/static/chimper/js/typed.js"></script>
                    <script>
                    var typed = new Typed('.typed-words', {
                    strings: ["Web Apps"," WordPress"," Mobile Apps"],
                    typeSpeed: 80,
                    backSpeed: 80,
                    backDelay: 4000,
                    startDelay: 1000,
                    loop: true,
                    showCursor: true
                    });
                    </script>
            -->
            <script src="../cmsimde/static/chimper/js/main.js"></script>
        
<!-- 啟用 LaTeX equations 編輯 -->
  <!-- <script>
  MathJax = {
    tex: {inlineMath: [['$', '$'], ['\(', '\)']]}
  };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>-->
    </body></html>
        