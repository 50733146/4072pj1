<h1>About</h1>
<p>專題題目: </p>
<p>強化學習在機電系統設計與控制中之應用 </p>
<p>Application of reinforcement learning in design and control of mechatronic systems</p>
<p>討論區: <a href="https://github.com/mdecourse/4072pj1/discussions">https://github.com/mdecourse/4072pj1/discussions</a></p>
<p>組員:</p>
<p style="padding-left: 30px;">40723110</p>
<p style="padding-left: 30px;">40723115</p>
<p style="padding-left: 30px;">40723138</p>
<p style="padding-left: 30px;">40723148</p>
<p style="padding-left: 30px;">40723150</p><h2>專題定位</h2>
<p>2021/01/08</p>
<p style="padding-left: 30px;">Adagrad: <a href="/downloads/2011_Adaptive Subgradient Methods for Online Learning and Stochastic Optimization.pdf">2011_Adaptive Subgradient Methods for Online Learning and Stochastic Optimization.pdf</a></p>
<p style="padding-left: 30px;"><a href="/downloads/2012_ADADELTA AN ADAPTIVE LEARNING RATE METHOD.pdf">2012_ADADELTA AN ADAPTIVE LEARNING RATE METHOD.pdf</a></p>
<p style="padding-left: 30px;">Adam: <a href="/downloads/2015_ADAM A METHOD  FORSTOCHASTICOPTIMIZATION.pdf">2015_ADAM A METHOD FORSTOCHASTICOPTIMIZATION.pdf</a></p>
<p style="padding-left: 30px;"><a href="/downloads/2017_An overview of gradient descent optimizationalgorithms.pdf">2017_An overview of gradient descent optimizationalgorithms.pdf</a></p>
<p style="padding-left: 30px;"><a href="/downloads/2018_A Comparative Analysis of Gradient Descent-Based Optimization Algorithms on Convolutional Neural Networks.pdf">2018_A Comparative Analysis of Gradient Descent-Based Optimization Algorithms on Convolutional Neural Networks.pdf</a></p>
<p style="padding-left: 30px;">第一組的理論與程式應用到第三組平面機構合成:</p>
<p style="padding-left: 30px;"><a href="/downloads/2015_Dimensional synthesis of mechanical linkages usingartificial neural networks and Fourier descriptors.pdf">2015_Dimensional synthesis of mechanical linkages usingartificial neural networks and Fourier descriptors.pdf</a></p>
<p style="padding-left: 30px;"><a href="/downloads/2017_Four-Bar Linkage Synthesis Using Non-ConvexOptimization.pdf">2017_Four-Bar Linkage Synthesis Using Non-ConvexOptimization.pdf</a></p>
<p style="padding-left: 30px;"><a href="/downloads/2018_Synthesis of a novel planar linkage to visit up to eight poses.pdf">2018_Synthesis of a novel planar linkage to visit up to eight poses.pdf</a></p>
<p></p>
<p>利用 <a href="https://cyberbotics.com/">Webots</a> 與 <a href="https://github.com/mdecourse/deepbots,">https://github.com/mdecourse/deepbots,</a> 透過 <a href="https://github.com/mdecourse/deepbots-tutorials">https://github.com/mdecourse/deepbots-tutorials</a> 與 <a href="https://github.com/mdecourse/deepworlds">https://github.com/mdecourse/deepworlds</a> 進一步了解 deepbots 如何應用在 Webots 中的受控系統.</p>
<p>專題目的在探討與 <a href="http://mde.tw/airhockey">http://mde.tw/airhockey</a> (<a href="https://github.com/mdecourse/airhockey">https://github.com/mdecourse/airhockey </a>)中虛實整合系統設計與控制有關的機器學習應用.</p>
<p>下載 <a href="https://drive.google.com/file/d/1FtyX29EcFwqlZ0xgzTCJVVol3Y_A9XBk/view?usp=sharing">Webots_R2020brev1_portable.7z</a></p>
<h4>參考資料:</h4>
<p><a href="https://github.com/mdecourse/RL_Webots">https://github.com/mdecourse/RL_Webots</a> </p>
<p><a href="https://drive.google.com/file/d/1fW0hZ24vqpDzuseVbZR60n9Z9-8MsP8c/view?usp=sharing">Deep Reinforcement Learning.pdf</a> (2019)</p>
<p><a href="https://drive.google.com/file/d/1If9EQqkmaIR8nZwHmyYHyx15OKvES4pw/view?usp=sharing">2020_Book_DeepReinforcementLearning.pdf</a></p>
<p><a href="https://drive.google.com/file/d/19irJA4Qchyew6XpucZPLYy5Nkyd7qQcF/view?usp=sharing">2019_Learning to Walk via Deep Reinforcement Learning</a></p>
<p><a href="https://drive.google.com/file/d/1a6o4GEwX7YJAuqf4PisMJzUn0g_l21O4/view?usp=sharing">2016_3d_simulated_robot_manipulation_using_deep_reinforcement_learning.pdf</a></p>
<p><a href="https://drive.google.com/file/d/11NfePzREpTGWD9aBGtjsrVWmRNma85hC/view?usp=sharing">2002_Book_HandbookOfMarkovDecisionProces.pdf</a></p>
<p><a href="https://link.springer.com/chapter/10.1007/978-3-030-49186-4_6">Deepbots: A Webots-Based Deep Reinforcement Learning Framework for Robotics</a></p><h2>LaTeX</h2>
<p><a href="https://github.com/sppmg/TW_Thesis_Template/wiki/%E7%84%A1%E8%85%A6%E6%89%8B%E5%86%8A">https://github.com/sppmg/TW_Thesis_Template/wiki/無腦手冊</a></p>
<p><a href="https://github.com/wengan-li/ncku-thesis-template-latex">https://github.com/wengan-li/ncku-thesis-template-latex</a></p>
<p><a href="https://github.com/HW-Lee/nthu-thesis-template">https://github.com/HW-Lee/nthu-thesis-template</a> </p>
<pre class="brush:js;auto-links:false;toolbar:false" contenteditable="false">    Features &amp; Benefits
    Templates
    Plans &amp; Pricing
    Help
    Register
    Log In

NTUST Thesis template 1.7.1 (Chinese Version)
Author
Ding-Jie Huang, Chien-Chun Ni
License
Creative Commons CC BY 4.0
Abstract

This is the Chinese Version of NTUST thesis template v1.7.1, please check "NTUST Thesis template Overleaf English Version" if you need the English one.

本範本是為台灣科技大學同學們所編寫的碩博士論文Latex模板， 主要由元智大學碩博士論文latex範本改編而來， 期望加快各位同學撰寫論文的速度。

P.S 原始陳念波老師的元智大學論文範本為 http://exciton.eo.yzu.edu.tw/~lab/latex/latex_note.html

Support 14pt font for this version
Tags
Find More Templates
NTUST Thesis template 1.7.1 (Chinese Version)

    © 2020 OverleafPrivacy and TermsSecurityContact UsAboutBlog

    Overleaf on TwitterOverleaf on FacebookOverleaf on LinkedIn

Source

% this file is encoded in utf-8
% v1.7

\documentclass[12pt, a4paper]{ntust_report} 

\usepackage{fontspec}   %加這個就可以設定字體 
\usepackage{xeCJK}       %讓中英文字體分開設置 

%設定主要字型，也就是英文字型
\setmainfont[Mapping=tex-text]{Times New Roman}            

%設定中文字型
%參考 https://www.overleaf.com/learn/latex/Questions/What_OTF/TTF_fonts_are_supported_via_fontspec%3F#Chinese
\setCJKmainfont{cwTeXKai}      

\XeTeXlinebreaklocale "zh"                %這兩行一定要加，中文才能自動換行 
\XeTeXlinebreakskip = 0pt plus 1pt       %這兩行一定要加，中文才能自動換行

\input{common_env}  %基本的環境設定  無需改變  

\begin{document}


	\input{chinese_trans} %在此檔案處定義文章中的中文名詞

	%----------------------------------------------------------------------------------------------------------------------------------------------------------
	%%% 以下是載入前頁、本文、後頁
	% 此行請勿更動

	%----------------------------------------------------------------------------------------------------------------------------------------------------------
	% front matter 前頁
	% 包括封面、書名頁、中文摘要、英文摘要、誌謝、目錄、表目錄、圖目錄、符號說明
	% 在撰寫各章草稿時，可以把此部份「關掉」，以節省無謂的編譯時間。
	% 實際內容由
	%    my_names.tex, my_cabstract.tex, my_eabstract.tex, my_ackn.tex, my_symbols.tex
	% 決定
	% ntust_frontpages.tex 此檔只提供整體架構的定義，不需更動
	% 在撰寫各章草稿時，可以把此部份「關掉」，以節省無謂的編譯時間。
	
	\input{frontpages/ntust_frontpages.tex} 




	%----------------------------------------------------------------------------------------------------------------------------------------------------------
	% main body 論文主體。建議以「章」為檔案分割的依據。
	% 以下為建議的命名分類
	%   introduction.tex   related_work.tex  protocol.tex  evaluation.tex  conclusion.tex
	% 做為這幾個「章」的檔案名稱，並將檔案存放於資料夾 sections/ 下
	% 實際命名方式可以隨你意
	% 在撰寫各章草稿時，可以把其他章節關掉 (行首加百分號)
	%\input{example/example_body.tex}  % 所附的範例

	\input{sections/introduction.tex}
	\input{sections/relative-work.tex}
	\input{sections/method.tex}
	\input{sections/Design.tex}
	\input{sections/evaluation.tex}
	\input{sections/Conclusion.tex}

	%----------------------------------------------------------------------------------------------------------------------------------------------------------
	% back pages 後頁
	% 包括參考文獻、附錄、自傳
	% 實際內容由
	%    my_bib.bib, my_appendix.tex, my_vita.tex
	% 決定
	% ntust_backpages.tex 此檔只提供整體架構的定義，不需更動
	% 在撰寫各章草稿時，可以把此部份「關掉」，以節省無謂的編譯時間。
	%\bibliographystyle{unsrt} 
	\input{backpages/ntust_backpages.tex}
	%\bibliographystyle{unsrt} 



\end{document} 
 

</pre>
<p></p><h2>參考資料</h2>
<ol>
<li><a href="https://easyai.tech/en/blog/reinforcement-learning-with-python/">https://easyai.tech/en/blog/reinforcement-learning-with-python/</a></li>
<li><a href="https://github.com/openai/gym">https://github.com/openai/gym</a></li>
<li><a href="https://github.com/bhyang/gym-vrep">https://github.com/bhyang/gym-vrep</a></li>
<li><a href="https://arxiv.org/pdf/1608.05742.pdf">https://arxiv.org/pdf/1608.05742.pdf</a></li>
<li><a href="https://github.com/stepjam/PyRep">https://github.com/stepjam/PyRep</a></li>
<li><a href="https://arxiv.org/abs/1906.11176">https://arxiv.org/abs/1906.11176</a></li>
<li><a href="https://github.com/ycps/vrep-env">https://github.com/ycps/vrep-env</a></li>
<li><a href="https://towardsdatascience.com/learning-to-drive-smoothly-in-minutes-450a7cdb35f4">https://towardsdatascience.com/learning-to-drive-smoothly-in-minutes-450a7cdb35f4</a></li>
<li><a href="https://github.com/araffin/learning-to-drive-in-5-minutes">https://github.com/araffin/learning-to-drive-in-5-minutes</a></li>
<li><a href="https://www.learndatasci.com/tutorials/reinforcement-q-learning-scratch-python-openai-gym/">https://www.learndatasci.com/tutorials/reinforcement-q-learning-scratch-python-openai-gym/</a></li>
<li><a href="https://upcommons.upc.edu/bitstream/handle/2117/133279/tfm-alex-cabaneros.pdf">https://upcommons.upc.edu/bitstream/handle/2117/133279/tfm-alex-cabaneros.pdf</a></li>
</ol><h2>研究生考試</h2>
<p>csme 研究生考試科目與題型: <a href="http://csme.org.tw/Certification/College.aspx?AwardID=62">考試內容</a>及<a href="http://csme.org.tw/Certification/Prepare.aspx?NewsType=2">考古題</a></p><h1>動態網站</h1>
<p>設定步驟請參考:</p>
<p><a href="https://github.com/mdecourse/project2020-1/issues/4">https://github.com/mdecourse/project2020-1/issues/4</a></p>
<h4>CMSiMDE 執行所需模組</h4>
<p style="padding-left: 30px;"><span>sudo pip3 install flask flask_cors bs4 lxml</span></p>
<h4>uwsgi 所需模組</h4>
<pre style="padding-left: 30px;"><code>sudo apt install uwsgi uwsgi-plugin-python3<br/><br/></code></pre>
<pre style="padding-left: 30px;"><code>sudo pip3 install uwsgi</code></pre>
<pre><code><br/></code>/etc/nginx/sites-available/default 附加 server 設定 <br/><br/></pre>
<pre class="brush:js;auto-links:false;toolbar:false" contenteditable="false">server {
 
    listen 9443 ssl;
    listen [::]:9443 ssl;
 
    # 指定 static 所在位置
    location /static {
	alias /home/yen/cad1_site/cmsimde/static/;
    }
 
    location / {
	# 導入 uwsgi_params 設定參數
	include uwsgi_params;
	# 根目錄設為近端的 8080 port 
	uwsgi_pass  127.0.0.1:8080;
    }
 
    ssl_certificate /home/yen/localhost.crt;
    ssl_certificate_key /home/yen/localhost.key;
    #ssl_certificate /etc/letsencrypt/live/cad1.kmol.info/fullchain.pem;
    #ssl_certificate_key /etc/letsencrypt/live/cad1.kmol.info/privkey.pem;
    ssl_session_timeout 5m;
    ssl_protocols SSLv3 TLSv1 TLSv1.1 TLSv1.2;
    ssl_ciphers "HIGH:!aNULL:!MD5 or HIGH:!aNULL:!MD5:!3DES";
    ssl_prefer_server_ciphers on;
    try_files $uri $uri/ =404;
}</pre>
<h4><br/>建立 self-signed key<br/><br/><span>sudo openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout localhost.key -out localhost.crt</span><br/><br/>/home/yen/uwsgi_ini/uwsgi.ini<br/><br/></h4>
<pre class="brush:js;auto-links:false;toolbar:false" contenteditable="false">[uwsgi]
socket = :8080
uid = yen
gid = yen
plugins-dir = /usr/lib/uwsgi/plugins/
plugin = python3
master = true
process = 4
threads = 2
chdir = /home/yen/cad1_site/cmsimde
wsgi-file = /home/yen/cad1_site/cmsimde/wsgi.py</pre>
<h4><br/>uwsgi emperor 手動測試</h4>
<h4><code>/usr/bin/uwsgi --emperor /home/yen/uwsgi_ini<br/><br/>防火牆設定<br/></code></h4>
<p>先暫時關閉 ufw</p>
<p>ufw disable</p>
<p>允許設計系 IP v6 網段連線 9443 port</p>
<p>ufw allow from 2001:288:6004:17::/32 to any port 9443</p>
<p>其他網段主機一律]不准連線</p>
<p>ufw deny 9443</p>
<p>重新開啟 ufw 防火牆</p>
<p>ufw enable</p>
<pre><code><span>/etc/systemd/system 目錄中建立 cmsimde.service 檔案</span></code></pre>
<pre></pre>
<pre class="brush:js;auto-links:false;toolbar:false" contenteditable="false">[Unit]
Description=uWSGI to serve CMSiMDE 
After=network.target
 
[Service]
User=yen
Group=yen
WorkingDirectory=/home/yen/uwsgi_ini
ExecStart=/usr/bin/uwsgi --emperor /home/yen/uwsgi_ini
 
[Install]
WantedBy=multi-user.target</pre>
<pre></pre>
<p>接著將 cmsimde 服務設為隨系統開機啟動:</p>
<pre><code>sudo systemctl enable cmsimde
</code></pre>
<p>若要取消 cmsimde 服務隨系統開機啟動:</p>
<pre><code>sudo systemctl disable cmsimde
</code></pre>
<p>手動啟動 cmsimde.service 服務</p>
<pre><code>sudo systemctl start cmsimde
</code></pre>
<p>手動停止 cmsimde.service 服務</p>
<pre><code>sudo systemctl stop cmsimde</code></pre>
<pre><br/><br/></pre><h2>數位簽章</h2>
<p><a href="https://letsencrypt.org/">https://letsencrypt.org/</a></p>
<p><a href="https://certbot.eff.org/lets-encrypt/ubuntufocal-nginx">https://certbot.eff.org/lets-encrypt/ubuntufocal-nginx</a> </p>
<pre class="brush:js;auto-links:false;toolbar:false" contenteditable="false">sudo apt-get update
sudo apt-get install software-properties-common
sudo add-apt-repository universe
sudo apt-get update

sudo apt-get install certbot python3-certbot-nginx

sudo certbot certonly --nginx

sudo certbot renew --dry-run</pre>
<p></p>
<h2>機電控制</h2>
<p>Mechatronic system control</p>
<h4>控制卡:</h4>
<p style="padding-left: 30px;">Arduino</p>
<p style="padding-left: 30px;">Raspberry Pi</p>
<h4>機電系統:</h4>
<p style="padding-left: 30px;">iRobot Create</p><h2>iRobot Create</h2>
<p><a href="https://www.cyberbotics.com/doc/guide/create">https://www.cyberbotics.com/doc/guide/create</a></p>
<p><iframe allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="allowfullscreen" frameborder="0" height="315" src="https://www.youtube.com/embed/dEgLYioQycA" width="560"></iframe></p>
<p><a href="https://github.com/mgobryan/pycreate">https://github.com/mgobryan/pycreate</a> </p>
<p><a href="https://github.com/mdecourse/create_autonomy">https://github.com/mdecourse/create_autonomy</a> </p>
<p><a href="/downloads/CreateManual_Final.pdf">iRobot Create Manual.pdf</a></p>
<p><a href="/downloads/iRobot Create Robot - Cookbook _ Mbed.pdf">iRobot Create cookbook.pdf</a></p>
<p><a href="/downloads/CommandModuleManual_v2.pdf">iRobot Create Command Module manual v2.pdf</a></p>
<p><a href="/downloads/CreateOpenInterface_v2.pdf">iRobot Create Open Interface v2.pdf</a></p>
<p><a href="/downloads/AD41700_Arduino_iRobot_workshop.pdf">Use Arduino to control iRobot Create.pdf</a></p>
<p><a href="/downloads/AD61600_Arduino_iRobot.pdf">Use Arduino to control iRobot Create_2.pdf</a></p>
<h1>深度學習</h1>
<p><a href="/downloads/Solving Nonlinear andHigh-Dimensional PartialDifferential Equations viaDeep Learning.pdf">Solving Nonlinear andHigh-Dimensional PartialDifferential Equations viaDeep Learning.pdf</a></p>
<p style="padding-left: 30px;"><a href="https://github.com/alialaradi/DeepGalerkinMethod">https://github.com/alialaradi/DeepGalerkinMethod</a></p>
<p><a href="/downloads/DGM A deep learning algorithm for solving partial differentialequations.pdf">DGM A deep learning algorithm for solving partial differentialequations.pdf</a></p>
<p></p>
<p><a href="https://cloud4scieng.org/">https://cloud4scieng.org/</a> 雲端運算</p>
<p><a href="https://www.uio.no/studier/emner/matnat/ifi/IN5400/v20/material/week1/">https://www.uio.no/studier/emner/matnat/ifi/IN5400/v20/material/week1/</a></p>
<p><a href="https://wcm.kmol.info:8443">https://wcm.kmol.info:8443</a> (KMOLer only)</p>
<p><a href="https://github.com/mdecourse/cd2020pj1">https://github.com/mdecourse/cd2020pj1</a></p>
<p><a href="https://cs.stanford.edu/people/karpathy/convnetjs/">https://cs.stanford.edu/people/karpathy/convnetjs/ </a></p>
<p><a href="http://neuralnetworksanddeeplearning.com/chap1.html">http://neuralnetworksanddeeplearning.com/chap1.html</a> </p>
<p><a href="https://cs.stanford.edu/people/karpathy/convnetjs/demo/rldemo.html">https://cs.stanford.edu/people/karpathy/convnetjs/demo/rldemo.html</a></p>
<p><a href="http://deeplearning.net/">http://deeplearning.net/</a></p>
<p><a href="/downloads/Playing Atari with Deep Reinforcement Learning.pdf">Playing Atari with Deep Reinforcement Learning.pdf</a></p>
<p><a href="/downloads/robust_auto_parking_reinforcement_learning_based_real_time_planning_approach_with_domain_template.pdf">Robust Auto-parking: Reinforcement Learning based Real-time Planning Approach with Domain Template.pdf</a></p>
<p><a href="/downloads/AutomaticCarParkingAReinforcem.pdf">Automatic Car Parking: A Reinforcement Learning Approach.pdf</a></p>
<p><a href="/downloads/Real-time image-based parking occupancy detection.pdf">Real-time image-based parking occupancy detection using deep learning.pdf</a></p>
<p><iframe allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="allowfullscreen" frameborder="0" height="315" src="https://www.youtube.com/embed/VMp6pq6_QjI" width="560"></iframe></p>
<p><iframe allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="allowfullscreen" frameborder="0" height="315" src="https://www.youtube.com/embed/MlFZjLkEIEw" width="560"></iframe></p>
<p>以下為 convnet javascript 應用</p>
<!-- import convnetjs library -->
<script src="/downloads/convnet-min.js"></script>
<!-- javascript goes here -->
<script type="text/javascript">
function periodic() {
  var d = document.getElementById('egdiv');
  d.innerHTML = 'Random number: ' + Math.random()
}
 
var net; // declared outside -> global variable in window scope
function start() {
  // this gets executed on startup
  //... 
  net = new convnetjs.Net();
  // ...
 
  // example of running something every 1 second
  setInterval(periodic, 1000);
}
</script>
<script>
window.onload=start();
</script>
<h2>電腦</h2>
<p><a href="https://drive.google.com/file/d/1AaOdJdZPNiD3YE5kgNcIrLK7ic0qsme1/view?usp=sharing">專題可攜 22GB.7z</a></p>
<p>電腦輔助設計室 2016 更換的<a href="http://project.mde.tw/blog/yen-dian-nao-fu-zhu-she-ji-shi-dian-nao-pei-zhi.html">電腦硬體</a>:</p>
<p>2016-2 協同設計室 6 台電腦</p>
<p>Intel Core i7-6700 3.4 GHz Ram 16GB</p>
<p>顯示卡 NVIDIA GeForce GTX 950 2GB 768 CUDA cores version 10.1</p>
<p><a href="https://pytorch.org/get-started/locally/">安裝 Pytorch 指令</a>:</p>
<pre>pip install torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f <a href="https://download.pytorch.org/whl/torch_stable.html">https://download.pytorch.org/whl/torch_stable.html</a><br/><br/><a href="https://github.com/pytorch/examples">https://github.com/pytorch/examples</a><br/><a href="https://drive.google.com/file/d/1ke4bwuKZYeGArfQHwPfwTQSLTL3c-g-i/view?usp=sharing"><br/>Deep learning with python.pdf<br/><br/></a><a href="https://drive.google.com/file/d/1tofwQZBpb-cApownNTREDLgF-nd7WgoU/view?usp=sharing">Deep Learning with Pytorch.pdf</a> (<a href="https://pytorch.org/assets/deep-learning/Deep-Learning-with-PyTorch.pdf">來源</a>)</pre>
<h2>Flask</h2>
<p>Flutter 前端與後端 Flask + Keras 結合應用</p>
<div style="padding-left: 30px;"><a href="https://medium.com/analytics-vidhya/deploy-deep-learning-models-as-rest-apis-using-keras-and-access-from-a-flutter-app-9a6752f0d907">https://medium.com/analytics-vidhya/deploy-deep-learning-models-as-rest-apis-using-keras-and-access-from-a-flutter-app-9a6752f0d907</a></div>
<div></div>
<div>Flutter send image file to backend:</div>
<div>
<pre class="brush:dart;auto-links:false;toolbar:false" contenteditable="false">import 'package:flutter/material.dart';
import 'dart:io';
import 'package:http/http.dart' as http;
import 'package:image_picker/image_picker.dart';
import 'package:mime/mime.dart';
import 'dart:convert';
import 'package:http_parser/http_parser.dart';
import 'package:toast/toast.dart';

void main() =&gt; runApp(MyApp());

class MyApp extends StatelessWidget {
  // This widget is the root of your application.
  @override
  Widget build(BuildContext context) {
    return MaterialApp(
        title: 'Image Upload Demo',
        theme: ThemeData(primarySwatch: Colors.pink),
        home: ImageInput());
  }
}

class ImageInput extends StatefulWidget {
  @override
  State&lt;StatefulWidget&gt; createState() {
    return _ImageInput();
  }
}

class _ImageInput extends State&lt;ImageInput&gt; {
  // To store the file provided by the image_picker
  File _imageFile;

  // To track the file uploading state
  bool _isUploading = false;

  String baseUrl = 'http://YOUR_IPV4_ADDRESS/flutterdemoapi/api.php';

  void _getImage(BuildContext context, ImageSource source) async {
    File image = await ImagePicker.pickImage(source: source);

    setState(() {
      _imageFile = image;
    });

    // Closes the bottom sheet
    Navigator.pop(context);
  }

  Future&lt;Map&lt;String, dynamic&gt;&gt; _uploadImage(File image) async {
    setState(() {
      _isUploading = true;
    });

    // Find the mime type of the selected file by looking at the header bytes of the file
    final mimeTypeData =
        lookupMimeType(image.path, headerBytes: [0xFF, 0xD8]).split('/');

    // Intilize the multipart request
    final imageUploadRequest =
        http.MultipartRequest('POST', Uri.parse(baseUrl));

    // Attach the file in the request
    final file = await http.MultipartFile.fromPath('image', image.path,
        contentType: MediaType(mimeTypeData[0], mimeTypeData[1]));

    // Explicitly pass the extension of the image with request body
    // Since image_picker has some bugs due which it mixes up
    // image extension with file name like this filenamejpge
    // Which creates some problem at the server side to manage
    // or verify the file extension
    imageUploadRequest.fields['ext'] = mimeTypeData[1];

    imageUploadRequest.files.add(file);

    try {
      final streamedResponse = await imageUploadRequest.send();

      final response = await http.Response.fromStream(streamedResponse);

      if (response.statusCode != 200) {
        return null;
      }

      final Map&lt;String, dynamic&gt; responseData = json.decode(response.body);

      _resetState();

      return responseData;
    } catch (e) {
      print(e);
      return null;
    }
  }

  void _startUploading() async {
    final Map&lt;String, dynamic&gt; response = await _uploadImage(_imageFile);
    print(response);
    // Check if any error occured
    if (response == null || response.containsKey("error")) {
      Toast.show("Image Upload Failed!!!", context,
          duration: Toast.LENGTH_LONG, gravity: Toast.BOTTOM);
    } else {
      Toast.show("Image Uploaded Successfully!!!", context,
          duration: Toast.LENGTH_LONG, gravity: Toast.BOTTOM);
    }
  }

  void _resetState() {
    setState(() {
      _isUploading = false;
      _imageFile = null;
    });
  }

  void _openImagePickerModal(BuildContext context) {
    final flatButtonColor = Theme.of(context).primaryColor;
    print('Image Picker Modal Called');
    showModalBottomSheet(
        context: context,
        builder: (BuildContext context) {
          return Container(
            height: 150.0,
            padding: EdgeInsets.all(10.0),
            child: Column(
              children: &lt;Widget&gt;[
                Text(
                  'Pick an image',
                  style: TextStyle(fontWeight: FontWeight.bold),
                ),
                SizedBox(
                  height: 10.0,
                ),
                FlatButton(
                  textColor: flatButtonColor,
                  child: Text('Use Camera'),
                  onPressed: () {
                    _getImage(context, ImageSource.camera);
                  },
                ),
                FlatButton(
                  textColor: flatButtonColor,
                  child: Text('Use Gallery'),
                  onPressed: () {
                    _getImage(context, ImageSource.gallery);
                  },
                ),
              ],
            ),
          );
        });
  }

  Widget _buildUploadBtn() {
    Widget btnWidget = Container();

    if (_isUploading) {
      // File is being uploaded then show a progress indicator
      btnWidget = Container(
          margin: EdgeInsets.only(top: 10.0),
          child: CircularProgressIndicator());
    } else if (!_isUploading &amp;&amp; _imageFile != null) {
      // If image is picked by the user then show a upload btn

      btnWidget = Container(
        margin: EdgeInsets.only(top: 10.0),
        child: RaisedButton(
          child: Text('Upload'),
          onPressed: () {
            _startUploading();
          },
          color: Colors.pinkAccent,
          textColor: Colors.white,
        ),
      );
    }

    return btnWidget;
  }

  @override
  Widget build(BuildContext context) {
    return Scaffold(
      appBar: AppBar(
        title: Text('Image Upload Demo'),
      ),
      body: Column(
        children: &lt;Widget&gt;[
          Padding(
            padding: const EdgeInsets.only(top: 40.0, left: 10.0, right: 10.0),
            child: OutlineButton(
              onPressed: () =&gt; _openImagePickerModal(context),
              borderSide:
                  BorderSide(color: Theme.of(context).accentColor, width: 1.0),
              child: Row(
                mainAxisAlignment: MainAxisAlignment.center,
                children: &lt;Widget&gt;[
                  Icon(Icons.camera_alt),
                  SizedBox(
                    width: 5.0,
                  ),
                  Text('Add Image'),
                ],
              ),
            ),
          ),
          _imageFile == null
              ? Text('Please pick an image')
              : Image.file(
                  _imageFile,
                  fit: BoxFit.cover,
                  height: 300.0,
                  alignment: Alignment.topCenter,
                  width: MediaQuery.of(context).size.width,
                ),
          _buildUploadBtn(),
        ],
      ),
    );
  }
}</pre>
<p>Server 端, 必須將 php 改為 Flask:</p>
<pre class="brush:php;auto-links:false;toolbar:false" contenteditable="false">    &lt;?php
    if(isset($_FILES["image"]["name"])) {
      
        // Make sure you have created this directory already
        $target_dir = "uploads/";
      
        // Generate a random name 
        $target_file = $target_dir . md5(time()) . '.' . $_POST['ext'];
        $check = getimagesize($_FILES["image"]["tmp_name"]);
        if($check !== false) {
            if (move_uploaded_file($_FILES["image"]["tmp_name"], $target_file)) {
          echo json_encode(['response' =&gt; "The image has been uploaded."]);
           }else {
          echo json_encode(["error" =&gt; "Sorry, there was an error uploading your file."]); 
        }
        } else {
            echo json_encode(["error" =&gt; "File is not an image."]);
           
        }
    }
     else {
         echo json_encode(["error" =&gt; "Please provide a image to upload"]);
    }
    ?&gt;</pre>
<p></p>
</div>
<h1>強化學習</h1>
<p><a href="https://github.com/dennybritz/reinforcement-learning">https://github.com/dennybritz/reinforcement-learning</a> </p>
<p><a href="http://incompleteideas.net/book/RLbook2018.pdf">http://incompleteideas.net/book/RLbook2018.pdf</a> </p>
<h4>Artificial Intelligence ( <a href="https://www.youtube.com/watch?v=J8Eh7RqggsU&amp;list=PLoROMvodv4rO1NB9TD4iUZ3qghGEGtqNX">人工智慧系列課程</a>)</h4>
<p><iframe allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="allowfullscreen" frameborder="0" height="315" src="https://www.youtube.com/embed/J8Eh7RqggsU" width="560"></iframe></p>
<h4>Machine Learning (<a href="https://www.youtube.com/watch?v=jGwO_UgTS7I&amp;list=PLoROMvodv4rMiGQp3WXShtMGgzqpfVfbU">機器學習系列課程</a>)</h4>
<p><iframe allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="allowfullscreen" frameborder="0" height="315" src="https://www.youtube.com/embed/jGwO_UgTS7I" width="560"></iframe></p>
<h4>Reinforcement Learning (<a href="https://www.youtube.com/watch?v=FgzM3zpZ55o&amp;list=PLoROMvodv4rOSOPzutgyCTapiGlY2Nd8u">強化學習系列課程</a>)</h4>
<p style="padding-left: 30px;">Learn to make good sequences of decision.</p>
<p><iframe allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="allowfullscreen" frameborder="0" height="315" src="https://www.youtube.com/embed/FgzM3zpZ55o" width="560"></iframe></p>
<p><a href="https://github.com/keras-rl/keras-rl">https://github.com/keras-rl/keras-rl</a></p>
<p><a href="https://towardsdatascience.com/learning-reinforcement-learning-reinforce-with-pytorch-5e8ad7fc7da0">https://towardsdatascience.com/learning-reinforcement-learning-reinforce-with-pytorch-5e8ad7fc7da0</a></p>
<p><a href="https://github.com/astooke/rlpyt">https://github.com/astooke/rlpyt</a> (<a href="https://rlpyt.readthedocs.io/en/latest/">Document</a>) (<a href="https://bair.berkeley.edu/blog/2019/09/24/rlpyt/">Blog</a>)</p>
<p><a href="https://github.com/p-christ/Deep-Reinforcement-Learning-Algorithms-with-PyTorch">https://github.com/p-christ/Deep-Reinforcement-Learning-Algorithms-with-PyTorch</a></p>
<p><a href="https://openai.com/blog/openai-baselines-ppo/">https://openai.com/blog/openai-baselines-ppo/</a> </p>
<p>Deep Q Learning</p>
<p><iframe allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="allowfullscreen" frameborder="0" height="315" src="https://www.youtube.com/embed/UlJzzLYgYoE" width="560"></iframe></p>
<p>Vanilla Policy Gradient Method</p>
<p>Trust Region / Natural Policy Gradient Methods</p>
<p><a href="/downloads/Proximal Policy Optimization Algorithms.pdf">Proximal Policy Optimization Algorithms.pdf</a> ( 近端策略優化原理)</p>
<p><a href="https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html">https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html</a></p>
<p><a href="https://www.mlq.ai/deep-reinforcement-learning-pytorch-implementation/">https://www.mlq.ai/deep-reinforcement-learning-pytorch-implementation/</a></p><h2>2021</h2>
<p>need Python and Node.js and Typescript</p>
<p><a href="https://github.com/Positronic-IO/air-hockey-training-environment">https://github.com/Positronic-IO/air-hockey-training-environment</a> </p>
<p><a href="https://github.com/Positronic-IO/air-hockey-web-ui">https://github.com/Positronic-IO/air-hockey-web-ui</a> </p>
<p><a href="https://jonathan-hui.medium.com/rl-dqn-deep-q-network-e207751f7ae4">https://jonathan-hui.medium.com/rl-dqn-deep-q-network-e207751f7ae4</a> </p>
<p><a href="https://keon.github.io/">https://keon.github.io/</a> </p><h2>Reference</h2>
<p><a href="/downloads/2018_Robotic Harvesting of Fruiting Vegetables-A Simulation Approach in V-REP, ROS and MATLAB.pdf">2018_Robotic Harvesting of Fruiting Vegetables-A Simulation Approach in V-REP, ROS and MATLAB.pdf</a></p>
<p><a href="/downloads/2019_Hovering Control of a Quadrotor.pdf">2019_Hovering Control of a Quadrotor.pdf</a></p>
<p><a href="/downloads/2019_Accelerating Training of Deep Reinforcement Learning-based Autonomous Driving Agents Through Comparative Study of Agent and Environment Designs.pdf">2019_Accelerating Training of Deep Reinforcement Learning-based Autonomous Driving Agents Through Comparative Study of Agent and Environment Designs.pdf</a></p>
<p><a href="/downloads/2018_Curved Path Following with Deep Reinforcement Learning-Results from Three Vessel Models.pdf">2018_Curved Path Following with Deep Reinforcement Learning-Results from Three Vessel Models.pdf</a></p>
<p><a href="/downloads/2019_Application of deep reinforcement learning for control problems.pdf">2019_Application of deep reinforcement learning for control problems.pdf</a></p>
<p><a href="/downloads/2018_Path Following in Simulated Environments using the A3C Reinforcement Learning Method.pdf">2018_Path Following in Simulated Environments using the A3C Reinforcement Learning Method.pdf</a></p>
<p><a href="/downloads/FlashRL_A Reinforcement Learning Platform.pdf">FlashRL_A Reinforcement Learning Platform.pdf</a></p><h2>類神經網路學習</h2>
<p><a href="https://drive.google.com/file/d/1yc0WjEN33IKjgmZZlxO5LcT--qkDRZXu/view">nn_and_air_hockey.7z</a></p>
<p>將 <a href="https://github.com/Purusharth07/Ping-Pong-Neural-Game-">https://github.com/Purusharth07/Ping-Pong-Neural-Game-</a>  改為 <a href="https://drive.google.com/file/d/1ZfkzhZBLRQSuKYsaKO2UPOC3ZvV9KaiC/view">tensorflow 2.0</a> 版本, 使用 Pygame 模擬.</p>
<h3>neural_network_in_python.pdf</h3>
<p>說明前三章的程式碼</p>
<h4>2LayerNeuralNetwork.py</h4>
<p><strong>origin codes:</strong></p>
<pre class="brush:py;auto-links:false;toolbar:false" contenteditable="false"># 2 Layer Neural Network in NumPy
import numpy as np
# X = input of our 3 input XOR gate
# set up the inputs of the neural network (right from the table)
X = np.array(([0,0,0],[0,0,1],[0,1,0], [0,1,1],[1,0,0],[1,0,1],[1,1,0],[1,1,1]), dtype=float)
# y = our output of our neural network
y = np.array(([1], [0], [0], [0], [0], [0], [0], [1]), dtype=float)
# what value we want to predict
xPredicted = np.array(([0,0,1]), dtype=float)
X = X/np.amax(X, axis=0) # maximum of X input array
# maximum of xPredicted (our input data for the prediction)
xPredicted = xPredicted/np.amax(xPredicted, axis=0)
# set up our Loss file for graphing
lossFile = open("SumSquaredLossList.csv", "w")
class Neural_Network (object):
    def __init__(self):
        #parameters
        self.inputLayerSize = 3 # X1,X2,X3
        self.outputLayerSize = 1 # Y1
        self.hiddenLayerSize = 4 # Size of the hidden layer
        # build weights of each layer
        # set to random values
        # look at the interconnection diagram to make sense of this
        # 3x4 matrix for input to hidden
        self.W1 = np.random.randn(self.inputLayerSize, self.hiddenLayerSize)
        # 4x1 matrix for hidden layer to output
        self.W2 = np.random.randn(self.hiddenLayerSize, self.outputLayerSize)
    def feedForward(self, X):
        # feedForward propagation through our network
        # dot product of X (input) and first set of 3x4 weights
        self.z = np.dot(X, self.W1)
        # the activationSigmoid activation function - neural magic
        self.z2 = self.activationSigmoid(self.z)
        # dot product of hidden layer (z2) and second set of 4x1 weights
        self.z3 = np.dot(self.z2, self.W2)
        # final activation function - more neural magic
        o = self.activationSigmoid(self.z3)
        return o
     def backwardPropagate(self, X, y, o):
        # backward propagate through the network
        # calculate the error in output
        self.o_error = y - o
        # apply derivative of activationSigmoid to error
        self.o_delta = self.o_error*self.activationSigmoidPrime(o)
        # z2 error: how much our hidden layer weights contributed to output
        # error
        self.z2_error = self.o_delta.dot(self.W2.T)
        # applying derivative of activationSigmoid to z2 error
        self.z2_delta = self.z2_error*self.activationSigmoidPrime(self.z2)
        # adjusting first set (inputLayer --&gt; hiddenLayer) weights
        self.W1 += X.T.dot(self.z2_delta)
        # adjusting second set (hiddenLayer --&gt; outputLayer) weights
        self.W2 += self.z2.T.dot(self.o_delta)
    def trainNetwork(self, X, y):
        # feed forward the loop
        o = self.feedForward(X)
        # and then back propagate the values (feedback)
        self.backwardPropagate(X, y, o)
    def activationSigmoid(self, s):
        # activation function
        # simple activationSigmoid curve as in the book
        return 1/(1+np.exp(-s))
    def activationSigmoidPrime(self, s):
        # First derivative of activationSigmoid
        # calculus time!
        return s * (1 - s)
    def saveSumSquaredLossList(self,i,error):
        lossFile.write(str(i)+","+str(error.tolist())+'\n')
    def saveWeights(self):
        # save this in order to reproduce our cool network
        np.savetxt("weightsLayer1.txt", self.W1, fmt="%s")
        np.savetxt("weightsLayer2.txt", self.W2, fmt="%s")
    def predictOutput(self):
        print ("Predicted XOR output data based on trained weights: ")
        print ("Expected (X1-X3): \n" + str(xPredicted))
        print ("Output (Y1): \n" + str(self.feedForward(xPredicted)))

myNeuralNetwork = Neural_Network()
trainingEpochs = 1000
#trainingEpochs = 100000

for i in range(trainingEpochs): # train myNeuralNetwork 1,000 times
    print ("Epoch # " + str(i) + "\n")
    print ("Network Input : \n" + str(X))
    print ("Expected Output of XOR Gate Neural Network: \n" + str(y))
    print ("Actual Output from XOR Gate Neural Network: \n" + \
    str(myNeuralNetwork.feedForward(X)))
    # mean sum squared loss
    Loss = np.mean(np.square(y - myNeuralNetwork.feedForward(X)))
    myNeuralNetwork.saveSumSquaredLossList(i,Loss)
    print ("Sum Squared Loss: \n" + str(Loss))
    print ("\n")
    myNeuralNetwork.trainNetwork(X, y)

myNeuralNetwork.saveWeights()
myNeuralNetwork.predictOutput()p</pre>
<p><strong>定義input(X)和output(Y)</strong></p>
<pre class="brush:py;auto-links:false;toolbar:false" contenteditable="false">X = np.array(([0,0,0],[0,0,1],[0,1,0], [0,1,1],[1,0,0],[1,0,1],[1,1,0],[1,1,1]), dtype=float)
y = np.array(([1], [0], [0], [0], [0], [0], [0], [1]), dtype=float)</pre>
<p><strong>設定神經元及權重</strong></p>
<pre class="brush:py;auto-links:false;toolbar:false" contenteditable="false">python
 def __init__(self):
        # X1,X2,X3(自訂義input的神經元數量)
        self.inputLayerSize = 3
        # Y1(自訂義output的神經元數量)   
        self.outputLayerSize = 1
        # Size of the hidden layer(自訂義hiddenLayer的神經元數量)          
        self.hiddenLayerSize = 4 
        
        # 設定第一層權重為隨機數值，input---&gt;hidden
        self.W1 = np.random.randn(self.inputLayerSize, self.hiddenLayerSize)
        
        # 設定第二層權重為隨機數值，hidden---&gt;output
        self.W2 = np.random.randn(self.hiddenLayerSize, self.outputLayerSize)
</pre>
<p><strong>feedForward(前饋)</strong></p>
<p><img alt="" height="361" src="/images/NN_layers.png" width="500"/></p>
<p><a href="https://medium.com/ai-academy-taiwan/back-propagation-3946e8ed8c55">(圖片來源)</a></p>
<pre class="brush:py;auto-links:false;toolbar:false" contenteditable="false"> def feedForward(self, X):
        # 第一層的動態方程式(activation function)輸入(z)
        # z(activation function) = 第一層所有神經元的 input * weights 總和輸入到第二層的其中一個神經元
        self.z = np.dot(X, self.W1)

        # 第一層的動態方程式(activation function)輸出(a)
        # z2(a) = 動態方程式(activation function)用Sigmoid function算法
        self.z2 = self.activationSigmoid(self.z)

        # 第二層的動態方程式(activation function)輸入(z)
        # z3(activation function) = 第二層所有神經元的 input * weights 總和輸入到輸出層的(其中一個)神經元
        self.z3 = np.dot(self.z2, self.W2)

        # 第二層的動態方程式(activation function)輸出(a)
        # o(a) = 動態方程式(activation function)用Sigmoid function算法
        o = self.activationSigmoid(self.z3)

        # 回傳出前饋結果
        return o</pre>
<p><strong>backwardPropagate(反向傳播)</strong></p>
<pre class="brush:py;auto-links:false;toolbar:false" contenteditable="false">def backwardPropagate(self, X, y, o):
        # 計算輸出誤差
        self.o_error = y - o

        # 將Sigmoid function算法用在輸出誤差(錯誤、error)
        self.o_delta = self.o_error*self.activationSigmoidPrime(o)

        # 隱藏層的輸出誤差*權重
        self.z2_error = self.o_delta.dot(self.W2.T)

        # 將Sigmoid function算法用在隱藏層輸出誤差(錯誤、error)
        self.z2_delta = self.z2_error*self.activationSigmoidPrime(self.z2)

        # 糾正第一層權重數值，input---&gt;hidden
        self.W1 += X.T.dot(self.z2_delta)
        # 糾正第二層權重數值，hidden---&gt;output
        self.W2 += self.z2.T.dot(self.o_delta)</pre>
<p><strong>trainNetwork(訓練流程)</strong></p>
<pre class="brush:py;auto-links:false;toolbar:false" contenteditable="false">def trainNetwork(self, X, y):
        # 前饋循環 
        o = self.feedForward(X)
        # 反向傳播值
        self.backwardPropagate(X, y, o)</pre>
<p><strong>activationSigmoid</strong></p>
<pre class="brush:py;auto-links:false;toolbar:false" contenteditable="false">def activationSigmoid(self, s):
        # activation function
        # 使用Sigmoid function算法(S-curve)
        return 1/(1+np.exp(-s))</pre>
<p><img caption="false" height="100" src="/images/Sigmoid_Function.jpg" width="222"/></p>
<p><strong>activationSigmoidPrime</strong></p>
<pre class="brush:py;auto-links:false;toolbar:false" contenteditable="false">def activationSigmoidPrime(self, s):
        # First derivative of activationSigmoid
        # calculus time!
        return s * (1 - s)</pre>
<p><strong><img caption="false" height="100" src="/images/Sigmoid_Function.jpg" width="222"/></strong></p>
<p><strong>saveSumSquaredLossList(儲存損失函數值)</strong></p>
<pre class="brush:py;auto-links:false;toolbar:false" contenteditable="false"> def saveSumSquaredLossList(self,i,error):
        lossFile.write(str(i)+","+str(error.tolist())+'\n')</pre>
<p><strong>saveWeights(儲存權重值)</strong></p>
<pre class="brush:py;auto-links:false;toolbar:false" contenteditable="false"> def saveWeights(self):
        np.savetxt("weightsLayer1.txt", self.W1, fmt="%s")
        np.savetxt("weightsLayer2.txt", self.W2, fmt="%s")</pre>
<p><strong>predictOutput(結果輸出)</strong></p>
<pre class="brush:py;auto-links:false;toolbar:false" contenteditable="false">def predictOutput(self):
        print ("Predicted XOR output data based on trained weights: ")
        print ("Expected (X1-X3): \n" + str(xPredicted))
        print ("Output (Y1): \n" + str(self.feedForward(xPredicted)))</pre>
<p><strong>Epochs(疊代次數，feedForward+backprogation運算完算一次疊代)</strong></p>
<pre class="brush:html;auto-links:false;toolbar:false" contenteditable="false"># 訓練疊代次數
trainingEpochs = 1000</pre>
<h4>TensorFlowKeras.py</h4>
<p><strong>origin codes:</strong></p>
<pre class="brush:py;auto-links:false;toolbar:false" contenteditable="false">import tensorflow as tf
from tensorflow.keras import layers
from tensorflow.keras.layers import Activation, Dense
import numpy as np
# X = input of our 3 input XOR gate
# set up the inputs of the neural network (right from the table)
X = np.array(([0,0,0], [0,0,1], [0,1,0], [0,1,1], [1,0,0], [1,0,1], [1,1,0], [1,1,1]), dtype=float)
# y = our output of our neural network
y = np.array(([1], [0], [0], [0], [0], [0], [0], [1]), dtype=float)
model = tf.keras.Sequential()
model.add(Dense(4, input_dim=3, activation='relu', use_bias=True))
#model.add(Dense(4, activation='relu', use_bias=True))
model.add(Dense(1, activation='sigmoid', use_bias=True))
model.compile(loss='mean_squared_error', optimizer='adam', metrics=['binary_accuracy'])
print (model.get_weights())
history = model.fit(X, y, epochs=2000, validation_data = (X, y))
model.summary()
# printing out to file
loss_history = history.history["loss"]
numpy_loss_history = np.array(loss_history)
np.savetxt("loss_history.txt", numpy_loss_history, delimiter="\n")
binary_accuracy_history = history.history["binary_accuracy"]
numpy_binary_accuracy = np.array(binary_accuracy_history)
np.savetxt("binary_accuracy.txt", numpy_binary_accuracy, delimiter="\n")
print(np.mean(history.history["binary_accuracy"]))
result = model.predict(X ).round()
print (result)</pre>
<p><strong>定義input(X)和output(Y)</strong></p>
<pre class="brush:html;auto-links:false;toolbar:false" contenteditable="false">X = np.array(([0,0,0],[0,0,1],[0,1,0], [0,1,1],[1,0,0],[1,0,1],[1,1,0],[1,1,1]), dtype=float)
# X是三輸入XOR邏輯閘
y = np.array(([1], [0], [0], [0], [0], [0], [0], [1]), dtype=float)
# Y是輸出神經網路</pre>
<p><strong>setting</strong></p>
<pre class="brush:py;auto-links:false;toolbar:false" contenteditable="false">model = tf.keras.Sequential() #sequential定義modle為層狀結構
model.add(Dense(4, input_dim=3, activation='relu', use_bias=True))
'''
add是從最上層開始加入，Dense是密集連線的神經網路，
4:輸出空間(神經元，輸出到4個神經元)，input_dim:輸入神經元個數，activation:定義啟動函數使用的類型，use_bias:使用偏差，True開啟。從inputlayer輸出到hiddenlayer的設定
'''

#model.add(Dense(4, activation='relu', use_bias=True))
model.add(Dense(1, activation='sigmoid', use_bias=True))
# 從hiddenlayer輸出到outputlayer的設定

model.compile(loss='mean_squared_error', optimizer='adam', metrics=['binary_accuracy'])
'''
配置訓練模組，loss funsion:用maen squared error(差平方誤差)，optimizer:優化器，
用adam function，metrics：計算準確率，用binary_accuracy
'''

print (model.get_weights())#印出回傳的正確權重
history = model.fit(X, y, epochs=2000, validation_data = (X, y))
'''
訓練模型給予固定epochs，迭代收集到的資料，validation_data：評估準確率(不包含在訓練裡面)
'''
</pre>
<p><strong>ReLU</strong><br/>max_value：輸出後最大值上限<br/>negative_slope：負斜率係數<br/>threshold：可通過的數值界線</p>
<p>[<a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/ReLU">tf.keras.layers.ReLU | TensorFlow Core v2.4.0</a>]</p>
<p><strong>mean squared error(MSE)</strong></p>
<p><img caption="false" height="500" src="/images/MSE.png" width="508"/></p>
<p>(<a href="https://www.freecodecamp.org/news/machine-learning-mean-squared-error-regression-line-c7dde9a26b93/">圖片來源</a>)</p>
<p><img alt="" height="100" src="/images/MSE_Function.jpg" width="388"/></p>
<p>[<a href="https://www.khanacademy.org/math/statistics-probability/describing-relationships-quantitative-data/more-on-regression/v/proof-part-1-minimizing-squared-error-to-regression-line">Proof (part 1) minimizing squared error to regression line (video) | Khan Academy</a>]</p>
<p>[<a href="https://www.listendata.com/2018/03/regression-analysis.html">15 Types of Regression in Data Science</a>]</p>
<p>[<a href="https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#compile">tf.keras.Sequential | TensorFlow Core v2.4.0</a>]</p>
<p>[<a href="https://www.freecodecamp.org/news/machine-learning-mean-squared-error-regression-line-c7dde9a26b93/">Machine learning: an introduction to mean squared error and regression lines</a>]</p>
<p>[<a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense">tf.keras.layers.Dense | TensorFlow Core v2.4.0</a>]</p>
<p>[<a href="https://www.tensorflow.org/api_docs/python/tf/keras/losses">Module: tf.keras.losses | TensorFlow Core v2.4.0</a>]</p>
<p>[<a href="https://www.tensorflow.org/api_docs/python/tf/keras/optimizers">Module: tf.keras.optimizers | TensorFlow Core v2.4.0</a>]</p>
<p>[<a href="https://www.tensorflow.org/api_docs/python/tf/keras/metrics">Module: tf.keras.metrics | TensorFlow Core v2.4.0</a>]</p>
<p>[<a href="https://www.tensorflow.org/hub/api_docs/python/hub/KerasLayer?hl=fr#get_weights">hub.KerasLayer | TensorFlow Hub</a>]</p>
<p>[<a href="https://www.tensorflow.org/api_docs/python/tf/summary">Module: tf.summary | TensorFlow Core v2.4.0</a>](https://www.tensorflow.org/api_docs/python/tf/summary)</p>
<p>[<a href="https://keras.io/api/layers/activations/">Keras documentation: Layer activation functions</a>]</p>
<p><strong>history</strong></p>
<pre class="brush:py;auto-links:false;toolbar:false" contenteditable="false">model.summary()
# 摘要資料使用在分析和可視化，為了確認訓練架構在符合預期方向

loss_history = history.history["loss"]
#回傳紀錄事件(loss)到history物件，取得fit方法的模組回傳值
numpy_loss_history = np.array(loss_history)
#將loss_history數值存成array
np.savetxt("loss_history.txt", numpy_loss_history, delimiter="\n")
#將numpy_loss_history存成loss_history.txt，並將每筆資料用換行符號隔開

binary_accuracy_history = history.history["binary_accuracy"]
#回傳紀錄事件(binary_accuracy)到history物件
numpy_binary_accuracy = np.array(binary_accuracy_history)
#將binary_accuracy_history數值存成array
np.savetxt("binary_accuracy.txt", numpy_binary_accuracy, delimiter="\n")
#將numpy_binary_accuracy存成binary_accuracy.txt，並將每筆資料用換行符號隔開
</pre>
<p><br/><strong>result</strong></p>
<pre class="brush:py;auto-links:false;toolbar:false" contenteditable="false">print(np.mean(history.history["binary_accuracy"]))
#印出平均binary_accuracy記錄到的數值
result = model.predict(X ).round()
#替輸入樣本產生輸出預測
print (result)
#印出結果</pre>
<p><a href="/downloads/整理資料/neural_network_in_python_summary.pdf">整理好的PDF檔</a><br/><br/></p><h1>Ref</h1><h2>Flutter</h2>
<p>Flutter 與 Android sdk 版本差異問題解決: <a href="https://stackoverflow.com/questions/60440509/android-command-line-tools-sdkmanager-always-shows-warning-could-not-create-se/61613986#61613986">https://stackoverflow.com/questions/60440509/android-command-line-tools-sdkmanager-always-shows-warning-could-not-create-se/61613986#61613986</a></p>
<p>Flask 與 ML 系統在後端, Flutter 作為前端</p>
<p><a href="https://medium.com/analytics-vidhya/deploy-ml-models-using-flask-as-rest-api-and-access-via-flutter-app-7ce63d5c1f3b">https://medium.com/analytics-vidhya/deploy-ml-models-using-flask-as-rest-api-and-access-via-flutter-app-7ce63d5c1f3b</a></p>
<p><a href="https://medium.com/@pyzimos/flutter-chatbot-with-python-flask-backend-heroku-deployment-706baafbb8f1">https://medium.com/@pyzimos/flutter-chatbot-with-python-flask-backend-heroku-deployment-706baafbb8f1</a></p>
<p><a href="https://github.com/SHARONZACHARIA/Deploy-ML-model">https://github.com/SHARONZACHARIA/Deploy-ML-model</a></p>
<p><a href="https://github.com/tonynguyen72/Flask_API_Flutter">https://github.com/tonynguyen72/Flask_API_Flutter</a></p>
<p><a href="https://github.com/mohammedhashim44/Flutter-Flask-Login">https://github.com/mohammedhashim44/Flutter-Flask-Login</a></p><h2>CMSiMDE</h2>
<p><a href="https://websitesetup.org/bootstrap-tutorial-for-beginners/">https://websitesetup.org/bootstrap-tutorial-for-beginners/</a></p>
<p><a href="https://colorlib.com/wp/themes/travelify/">https://colorlib.com/wp/themes/travelify/</a> </p>
<p><a href="https://github.com/puikinsh/travelify">https://github.com/puikinsh/travelify</a></p>
<p></p>
<p></p>